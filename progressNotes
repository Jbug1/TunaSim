
now testing: downsampling of validation set for ensemble layer

tbt: retrain on new val set for ensemble layer
     predict train and validation without downsample for q adjustment layer
     use old tunanetwork sims for msg training

def calculate_learning_rate(self, param, grad):

        if self.learning_rate_scheduler is None:

            return  self.learning_rates[param]

        elif self.learning_rate_scheduler == 'sag':

            #add scale contribution to holdover
            self.scale_holdovers[param].append(abs(grad))

            #use the most recent grad to get exp decaying net gradient
            self.accumulated_gradients[param] = self.learning_beta * self.accumulated_gradients[param] + (1 - self.learning_beta) * grad

            #get accumulated scale with the popped holdover value
            self.accumulated_scales[param] = self.accumulated_scales[param] * self.learning_beta + self.scale_holdovers[param].popleft() * (1 - self.learning_beta)

            #update the learning rate
            self.learning_rates[param] = self.learning_rates[param] * (self.ad_int + self.ad_slope * abs(self.accumulated_gradients[param]) / self.accumulated_scales[param])
            
            return max(1e-7, self.learning_rates[param])


 #set scheduling dictionaries
        self.accumulated_gradients = {key: 0 for key in self.init_vals}
        self.accumulated_scales = {key: 0 for key in self.init_vals}
        self.scale_holdovers = {key: deque([1 for i in range(self.scale_holdover_vals)]) for key in self.init_vals}

        #we will start squared accumulated with large value for small steps
        self.squared_accumulated = {key: 1 for key in self.init_vals.keys()}

        #grad directions begins at zero, signifying a change in neither direction
        self.accumulated_directions = {key: 0 for key in self.init_vals.keys()}



    @staticmethod
    @njit
    def sub_predict_grads(query,
                    target,
                    q_int_a_grad,
                    q_int_b_grad,
                    t_int_a_grad,
                    t_int_b_grad,
                    dif_a,
                    dif_b,
                    mult_a,
                    mult_b,
                    add_norm_b
                    ):
        
        grad_vals = np.zeros(9)
        
        #generate uncollapsed intensity combining functions
        difs = query - target
        difs_abs = np.abs(difs)
        mults = query * target
        add = query + target

        #generate expanded terms
        add_norm = np.power(add, add_norm_b)
        dif_abs_term = np.power(difs_abs, dif_b) / add_norm
        mult_term = np.power(mults, mult_b) / add_norm
        
        #very messy cacluation of terms, going for efficiency with intermediate results here
        #slight adjustment to take care of infinite grads...these result from no difference and therefore will be set to 0 anyways
        #calcualte gradient for similarity score params of dif and mult a(R -> R)

        #calculate sim parameter gradients
        grad_vals[0] = np.sum(dif_abs_term) #dif_a

        #update dif term
        dif_abs_term = dif_a * dif_abs_term

        grad_vals[1] = np.nansum(dif_abs_term * np.log(difs_abs)) #dif_b
            
        grad_vals[2] = np.sum(mult_term) #mult_a

        mult_term = mult_a * mult_term

        grad_vals[3] = np.nansum(mult_term * np.log(mults)) #mult_b

        #since all the add norm gradients build on each other, we can gain a speedup
        #chain rule, exponent rule
        raw_score = dif_abs_term + mult_term
        grad_vals[4] = -np.sum(raw_score * np.log(add)) #add norm b

        #calculate component gradients w.r.t. each side of input
        #chain rule
        #exclude indices where dif is 0 b.c. no grad at these points
        dif_grad_q = dif_a * dif_b * np.power(difs_abs, dif_b-2) * difs
        dif_grad_q[np.isinf(dif_grad_q)] = 0
        dif_grad_t = -dif_grad_q

        mult_grad = mult_a * mult_b * np.power(mults, mult_b - 1)
        mult_grad[np.isinf(mult_grad)] = 0
        mult_grad_q = mult_grad * target
        mult_grad_t = mult_grad * query

        #add grad will be the same for query and target
        #chain rule
        #exclude indices where mult is 0 b.c. no grad at these points
        add_grad = add_norm_b * np.power(add, add_norm_b - 1)
        
        #gradients of score w.r.t. query and target...for passing down reweight param grads
        #quotient rule and combining terms
        second_term = (mult_term + dif_abs_term) * add_grad
        query_grad = (mult_grad_q + dif_grad_q - second_term) / add_norm
        target_grad  = (mult_grad_t + dif_grad_t - second_term) / add_norm

        #get the gradient of score w.r.t reweight params
        #chain rule
        grad_vals[5] = np.nansum(q_int_a_grad * query_grad) #query intensity a
        grad_vals[6] = np.nansum(q_int_b_grad * query_grad) #query intensity b

        grad_vals[7] = np.nansum(t_int_a_grad * target_grad) #target intensity a
        grad_vals[8] = np.nansum(t_int_b_grad * target_grad) #target intensity b

        #finally calculate score
        score = sigmoid(np.sum(raw_score))

        #adjust gradients for final sigmoid layer
        #chain rule
        grad_vals = grad_vals * score * (1 - score)

        return score, grad_vals

    @staticmethod
    @njit
    def sub_predict(query,
                    target,
                    dif_a,
                    dif_b,
                    mult_a,
                    mult_b,
                    add_norm_b
                    ):    

        #generate uncollapsed intensity combining functions
        difs = query - target
        difs_abs = np.abs(difs)
        mults = query * target
        add = query + target

        return sigmoid(np.sum(((dif_a * np.power(difs_abs, dif_b)) + 
                                  (mult_a * np.power(mults, mult_b))) / 
                                  np.power(add, add_norm_b)))
    