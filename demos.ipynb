{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from importlib import reload\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "import copy\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as hgbc\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import TunaSims\n",
    "import func_ob\n",
    "import tools\n",
    "import datasetBuilder\n",
    "import testUtils\n",
    "import spectral_similarity\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for Different Ways of Distributing Interspectral Intensity Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#databases\n",
    "outputs_path='/Users/jonahpoczobutt/projects/TunaRes/test_2'\n",
    "nist14='/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist14_highres.pkl'\n",
    "nist20_prot_deprot = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist20_prot_deprot.pkl'\n",
    "nist23_hr_prot_deprot_only = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist23_prot_deprot_only.pkl'\n",
    "nist23_hr_full ='/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist23_full.pkl'\n",
    "gnps='/Users/jonahpoczobutt/projects/raw_data/db_csvs/gnps_highres.pkl'\n",
    "mona='/Users/jonahpoczobutt/projects/raw_data/db_csvs/mona_highres.pkl'\n",
    "metlin='/Users/jonahpoczobutt/projects/raw_data/db_csvs/metlin_highres_inst.pkl'\n",
    "mona_nist = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/mona_nist_prot_only.pkl'\n",
    "\n",
    "self_search=False\n",
    "query = metlin\n",
    "target = nist23_hr_full\n",
    "if self_search:\n",
    "    target=query\n",
    "    \n",
    "fullRun=False\n",
    "if fullRun:\n",
    "    os.mkdir(outputs_path)\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/datasets')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/gbc_res')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/train_to_func')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/train_to_error')\n",
    "    os.mkdir(f'{outputs_path}/metlin_ce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mat_pos(a,b):\n",
    "\n",
    "    energies = [0,10,20,40]\n",
    "    row = energies.index(a)\n",
    "    col = energies.index(b)\n",
    "\n",
    "    return(row,col)\n",
    "\n",
    "fullRun  = False\n",
    "if fullRun:\n",
    "\n",
    "    metlin='/Users/jonahpoczobutt/projects/raw_data/db_csvs/metlin_highres_inst.pkl'\n",
    "    metlin_ = pd.read_pickle(metlin)\n",
    "    metlin_=metlin_[metlin_['instrument']=='Q-TOF']\n",
    "\n",
    "    ms2_da = 0.05\n",
    "    noise_removal = 0.0\n",
    "    precursor_thresh=3\n",
    "\n",
    "    counts_dict = dict()\n",
    "    sims_dict = dict()\n",
    "\n",
    "    pos = [True,False]\n",
    "\n",
    "    #instantiate all dicts\n",
    "    for i in pos:\n",
    "        for j in pos:\n",
    "            for k in pos:\n",
    "                for l in pos:\n",
    "                    for m in pos:\n",
    "                        counts_dict[(i,j,k,l,m)] = np.zeros((4,4))\n",
    "                        sims_dict[(i,j,k,l,m)] = np.zeros((4,4))\n",
    "\n",
    "\n",
    "    for i in range(len(metlin_)):\n",
    "\n",
    "        core_sub = metlin_[(metlin_['inchi_base']==metlin_.iloc[i]['inchi_base']) | (abs(metlin_.iloc[i][\"precursor\"] - metlin_[\"precursor\"]) < tools.ppm(metlin_.iloc[i][\"precursor\"], precursor_thresh))]\n",
    "        core_sub.sort_values(by = 'collision_energy')\n",
    "\n",
    "        for i in range(len(core_sub)):\n",
    "\n",
    "            spec_i = tools.clean_spectrum(core_sub.iloc[i]['spectrum'], max_mz=core_sub.iloc[i]['precursor'],noise_removal=noise_removal)\n",
    "            spec_i[:,1] = spec_i[:,1]/np.sum(spec_i[:,1])\n",
    "\n",
    "            for j in range(len(core_sub)):\n",
    "\n",
    "                #only want to look at each comparison once\n",
    "                if core_sub.iloc[i]['ID']>=core_sub.iloc[j]['ID']:\n",
    "                    continue\n",
    "\n",
    "                spec_j = tools.clean_spectrum(core_sub.iloc[j]['spectrum'], max_mz=core_sub.iloc[j]['precursor'],noise_removal=noise_removal)\n",
    "                spec_j[:,1] = spec_j[:,1]/np.sum(spec_j[:,1])\n",
    "                same_mode = False\n",
    "                same_precursor_type = False\n",
    "                same_key = False\n",
    "                same_base=False\n",
    "                within_ppm=False\n",
    "\n",
    "                #all possibilities here\n",
    "                if core_sub.iloc[i]['mode'] == core_sub.iloc[j]['mode']:\n",
    "                    same_mode = True \n",
    "\n",
    "                if core_sub.iloc[i]['precursor_type'] == core_sub.iloc[j]['precursor_type']:\n",
    "                    same_precursor_type = True   \n",
    "\n",
    "                if core_sub.iloc[i]['inchi'] == core_sub.iloc[j]['inchi']:\n",
    "                    same_key = True   \n",
    "\n",
    "                if core_sub.iloc[i]['inchi_base'] == core_sub.iloc[j]['inchi_base']:\n",
    "                    same_base=True\n",
    "\n",
    "                if abs(core_sub.iloc[i][\"precursor\"] - core_sub.iloc[j][\"precursor\"]) < tools.ppm(core_sub.iloc[i][\"precursor\"], precursor_thresh):\n",
    "                    within_ppm = True                                                                          \n",
    "\n",
    "                #get key and position within matrix\n",
    "                key = (same_mode, same_precursor_type, same_key, same_base, within_ppm)\n",
    "                \n",
    "\n",
    "                if core_sub.iloc[i]['collision_energy'] < core_sub.iloc[j]['collision_energy']:\n",
    "                    low_spec=spec_i\n",
    "                    high_spec = spec_j\n",
    "                    matrix_pos = get_mat_pos(core_sub.iloc[i]['collision_energy'],core_sub.iloc[j]['collision_energy'])\n",
    "\n",
    "                else:\n",
    "                    low_spec = spec_j\n",
    "                    high_spec=spec_i\n",
    "                    matrix_pos = get_mat_pos(core_sub.iloc[j]['collision_energy'],core_sub.iloc[i]['collision_energy'])\n",
    "                    \n",
    "\n",
    "                matched = tools.match_peaks_in_spectra(low_spec, high_spec, ms2_da=ms2_da)\n",
    "\n",
    "                low_sum = np.sum(matched[:,1][np.where(matched[:,2]>0)])\n",
    "                high_sum = np.sum(matched[:,2][np.where(matched[:,1]>0)])\n",
    "\n",
    "                #add the low collision energy sum on the vertical column\n",
    "                counts_dict[key][matrix_pos[0],matrix_pos[1]]+=1\n",
    "                counts_seen = counts_dict[key][matrix_pos[0],matrix_pos[1]]\n",
    "\n",
    "                #add the lower collision energy data\n",
    "                sims_dict[key][matrix_pos[0],matrix_pos[1]] = (low_sum/(counts_seen)) + sims_dict[key][matrix_pos[0],matrix_pos[1]]*(counts_seen-1)/counts_seen\n",
    "\n",
    "                counts_dict[key][matrix_pos[1],matrix_pos[0]]+=1\n",
    "                counts_seen = counts_dict[key][matrix_pos[1],matrix_pos[0]]\n",
    "\n",
    "                #add the higher collision energy data\n",
    "                sims_dict[key][matrix_pos[1],matrix_pos[0]] = (high_sum/(counts_seen)) + sims_dict[key][matrix_pos[1],matrix_pos[0]]*(counts_seen-1)/counts_seen\n",
    "\n",
    "\n",
    "    with open(f'{outputs_path}/metlin_ce/sims_dict.pkl', 'wb') as handle:\n",
    "\n",
    "                pickle.dump(sims_dict, handle)\n",
    "\n",
    "    with open(f'{outputs_path}/metlin_ce/counts_dict.pkl', 'wb') as handle:\n",
    "\n",
    "                pickle.dump(counts_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullRun=True\n",
    "if fullRun:\n",
    "\n",
    "    #This should be replaced with a function to read in all the databases\n",
    "    query_ = pd.read_pickle(query)\n",
    "    all_bases = list(set(query_['inchi_base']))\n",
    "\n",
    "    if self_search:\n",
    "        query_.insert(0,'queryID', [i for i in range(len(query_))])\n",
    "    else:\n",
    "        query_.insert(0,'queryID', [\"_\" for i in range(len(query_))])\n",
    "\n",
    "    #this method is in place\n",
    "    np.random.shuffle(all_bases)\n",
    "\n",
    "    first_bases = all_bases[:int(len(all_bases)*0.5)]\n",
    "    second_bases = all_bases[int(len(all_bases)*0.5):int(len(all_bases)*0.7)]\n",
    "    third_bases = all_bases[int(len(all_bases)*0.7):]\n",
    "\n",
    "    first_query_ = query_[np.isin(query_['inchi_base'],first_bases)]\n",
    "    first_query_.reset_index(inplace=True)\n",
    "    first_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/first_query.pkl')\n",
    "    del(first_query_)\n",
    "\n",
    "    second_query_ = query_[np.isin(query_['inchi_base'],second_bases)]\n",
    "    second_query_.reset_index(inplace=True)\n",
    "    second_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/second_query.pkl')\n",
    "    del(second_query_)\n",
    "\n",
    "    third_query_ = query_[np.isin(query_['inchi_base'],third_bases)]\n",
    "    third_query_.reset_index(inplace=True)\n",
    "    third_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/third_query.pkl')\n",
    "    del(third_query_)\n",
    "    del(query_)\n",
    "\n",
    "    \n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/first_bases.npy',first_bases)\n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/second_bases.npy',second_bases)\n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/third_bases.npy',third_bases)\n",
    "    del(first_bases)\n",
    "    del(second_bases)\n",
    "    del(third_bases)\n",
    "    del(all_bases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100041 rows created\n",
      "200012 rows created\n",
      "300135 rows created\n",
      "400070 rows created\n",
      "500228 rows created\n",
      "600041 rows created\n",
      "700242 rows created\n",
      "800195 rows created\n",
      "900010 rows created\n",
      "1000024 rows created\n",
      "1100277 rows created\n",
      "1200442 rows created\n",
      "1300010 rows created\n",
      "1400058 rows created\n",
      "1500041 rows created\n",
      "1600028 rows created\n",
      "1700009 rows created\n",
      "1800032 rows created\n",
      "1900006 rows created\n",
      "2000204 rows created\n",
      "2100241 rows created\n",
      "2200003 rows created\n",
      "2300810 rows created\n",
      "2400040 rows created\n",
      "total number of query spectra considered: 35319\n",
      "total number of target spectra considered: 2417268\n",
      "total inchicores seen: 6591\n",
      "10998 queries went unmatched\n",
      "100224 rows created\n",
      "200037 rows created\n",
      "300067 rows created\n",
      "400020 rows created\n",
      "500101 rows created\n",
      "600048 rows created\n",
      "700854 rows created\n",
      "800018 rows created\n",
      "900442 rows created\n",
      "1000117 rows created\n",
      "total number of query spectra considered: 14148\n",
      "total number of target spectra considered: 1011401\n",
      "total inchicores seen: 2637\n",
      "4298 queries went unmatched\n",
      "100908 rows created\n",
      "200555 rows created\n",
      "300272 rows created\n",
      "400023 rows created\n",
      "500318 rows created\n",
      "600452 rows created\n",
      "700383 rows created\n",
      "800090 rows created\n",
      "900480 rows created\n",
      "1000603 rows created\n",
      "1100019 rows created\n",
      "1200033 rows created\n",
      "1300263 rows created\n",
      "1400016 rows created\n",
      "total number of query spectra considered: 21041\n",
      "total number of target spectra considered: 1401969\n",
      "total inchicores seen: 3955\n",
      "6398 queries went unmatched\n"
     ]
    }
   ],
   "source": [
    "#Similarity methods and transformation parameters below. Leave sim methods as None to run all\n",
    "fullRun=True\n",
    "if fullRun:\n",
    "    comparison_metrics = ['entropy',\n",
    "                'manhattan',\n",
    "                'lorentzian',\n",
    "                'dot_product',\n",
    "                'fidelity',\n",
    "                'matusita',\n",
    "                'chi2',\n",
    "                'laplacian',\n",
    "                'harmonic_mean',\n",
    "                'bhattacharya_1',\n",
    "                'squared_chord',\n",
    "                'cross_ent']\n",
    "\n",
    "    ppm_windows = [3]\n",
    "    noise_threshes=[0.01,0.0]\n",
    "    centroid_tolerance_vals = [0.05]\n",
    "    centroid_tolerance_types=['da']\n",
    "    powers=['orig',1]\n",
    "    sim_methods=comparison_metrics\n",
    "    prec_removes=[True]\n",
    "    build_dataset=True\n",
    "\n",
    "\n",
    "    train_size=3e6\n",
    "    test_size=1e6\n",
    "    test_size=2e6\n",
    "\n",
    "    max_matches=None\n",
    "    adduct_match = False\n",
    "\n",
    "    target_=pd.read_pickle(target)\n",
    "\n",
    "    if self_search:\n",
    "        target_.insert(0,'queryID', [i for i in range(len(target_))])\n",
    "    else:\n",
    "        target_.insert(0,'queryID', [\"*\" for i in range(len(target_))])\n",
    "\n",
    "    for i in ppm_windows:\n",
    "\n",
    "        if build_dataset:\n",
    "\n",
    "            #read in first bases and shuffle order\n",
    "            query_train = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/first_query.pkl')\n",
    "            query_train=query_train.sample(frac=1)\n",
    "\n",
    "            #create matches for model to train on\n",
    "            matches = datasetBuilder.create_matches_df(query_train,target_,i,max_matches,train_size, adduct_match)\n",
    "            matches.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_matches_{i}_ppm.pkl')\n",
    "            del(query_train)\n",
    "\n",
    "            matches_same_ce = matches[matches['ceratio']==1]\n",
    "            matches_dif_ce = matches[matches['ceratio']!=1]\n",
    "            \n",
    "            sub_train_same_ce = datasetBuilder.create_cleaned_df(\n",
    "                                                matches_same_ce, \n",
    "                                                sim_methods, \n",
    "                                                noise_threshes, \n",
    "                                                centroid_tolerance_vals, \n",
    "                                                centroid_tolerance_types,\n",
    "                                                powers,\n",
    "                                                prec_removes\n",
    "            )\n",
    "\n",
    "            sub_train_dif_ce = datasetBuilder.create_cleaned_df(\n",
    "                                                matches_dif_ce, \n",
    "                                                sim_methods, \n",
    "                                                noise_threshes, \n",
    "                                                centroid_tolerance_vals, \n",
    "                                                centroid_tolerance_types,\n",
    "                                                powers,\n",
    "                                                prec_removes\n",
    "            )\n",
    "\n",
    "\n",
    "            sub_train_same_ce.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_same_ce_{i}_ppm.pkl')\n",
    "            sub_train_dif_ce.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_dif_ce_{i}_ppm.pkl')\n",
    "\n",
    "            del(sub_train_same_ce)\n",
    "            del(sub_train_dif_ce)\n",
    "            #read in first bases and shuffle order\n",
    "            query_val = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/second_query.pkl')\n",
    "            query_query_val = query_val.sample(frac=1)\n",
    "\n",
    "            #create matches for model to train on\n",
    "            matches = datasetBuilder.create_matches_df(query_val,target_,i,max_matches,test_size, adduct_match)\n",
    "            matches.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/val_matches_{i}_ppm.pkl')\n",
    "            del(query_val)\n",
    "\n",
    "            \n",
    "            matches_same_ce = matches[matches['ceratio']==1]\n",
    "            matches_dif_ce = matches[matches['ceratio']!=1]\n",
    "            \n",
    "            sub_val_same_ce = datasetBuilder.create_cleaned_df(\n",
    "                                                matches_same_ce, \n",
    "                                                sim_methods, \n",
    "                                                noise_threshes, \n",
    "                                                centroid_tolerance_vals, \n",
    "                                                centroid_tolerance_types,\n",
    "                                                powers,\n",
    "                                                prec_removes\n",
    "            )\n",
    "\n",
    "            sub_val_dif_ce = datasetBuilder.create_cleaned_df(\n",
    "                                                matches_dif_ce, \n",
    "                                                sim_methods, \n",
    "                                                noise_threshes, \n",
    "                                                centroid_tolerance_vals, \n",
    "                                                centroid_tolerance_types,\n",
    "                                                powers,\n",
    "                                                prec_removes\n",
    "            )\n",
    "\n",
    "            sub_val_same_ce.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/val_cleaned_matches_same_ce_{i}_ppm.pkl')\n",
    "            sub_val_dif_ce.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/val_cleaned_matches_dif_ce_{i}_ppm.pkl')\n",
    "\n",
    "\n",
    "            del(sub_val_same_ce)\n",
    "            del(sub_val_dif_ce)\n",
    "\n",
    "            #read in first bases and shuffle order\n",
    "            query_test = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/third_query.pkl')\n",
    "            query_test=query_test.sample(frac=1)\n",
    "\n",
    "            #create matches for model to train on\n",
    "            matches = datasetBuilder.create_matches_df(query_test,target_,i,max_matches,test_size, adduct_match)\n",
    "            matches.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test_matches_{i}_ppm.pkl')\n",
    "            del(query_test)\n",
    "\n",
    "            matches_same_ce = matches[matches['ceratio']==1]\n",
    "            matches_dif_ce = matches[matches['ceratio']!=1]\n",
    "            \n",
    "            sub_test_same_ce = datasetBuilder.create_cleaned_df(\n",
    "                                                matches_same_ce, \n",
    "                                                sim_methods, \n",
    "                                                noise_threshes, \n",
    "                                                centroid_tolerance_vals, \n",
    "                                                centroid_tolerance_types,\n",
    "                                                powers,\n",
    "                                                prec_removes\n",
    "            )\n",
    "\n",
    "            sub_test_dif_ce = datasetBuilder.create_cleaned_df(\n",
    "                                                matches_dif_ce, \n",
    "                                                sim_methods, \n",
    "                                                noise_threshes, \n",
    "                                                centroid_tolerance_vals, \n",
    "                                                centroid_tolerance_types,\n",
    "                                                powers,\n",
    "                                                prec_removes\n",
    "            )\n",
    "\n",
    "\n",
    "            sub_test_same_ce.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test_cleaned_matches_same_ce_{i}_ppm.pkl')\n",
    "            sub_test_dif_ce.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test_cleaned_matches_dif_ce_{i}_ppm.pkl')\n",
    "\n",
    "            del(sub_test_same_ce)\n",
    "            del(sub_test_dif_ce)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mzs_True_0.01_orig_0</th>\n",
       "      <th>query_True_0.01_orig_0</th>\n",
       "      <th>target_True_0.01_orig_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[41.0389, 44.0512, 56.0508, 61.0115, 69.0708, ...</td>\n",
       "      <td>[0.053256802574551995, 0.16757917618099427, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[41.0389, 44.0512, 56.0508, 61.0115, 69.0708, ...</td>\n",
       "      <td>[0.053256802574551995, 0.16757917618099427, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.11250624241884778,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[41.0389, 44.0512, 56.0508, 61.0115, 65.0384, ...</td>\n",
       "      <td>[0.053256802574551995, 0.16757917618099427, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0058862886657065, 0.057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[41.0389, 44.0512, 56.0508, 57.0696, 61.0115, ...</td>\n",
       "      <td>[0.053256802574551995, 0.16757917618099427, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.005904047994005843, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>[38.9616, 39.0228, 51.0244, 55.020900000000005...</td>\n",
       "      <td>[0.003620444403156594, 0.015135414363484355, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0103046692995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[110.0399, 128.0506, 176.0619, 189.0662, 190.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.13123784753008844, 0.0, 0.0,...</td>\n",
       "      <td>[0.08974502848695622, 0.08596487624843602, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[67.0177, 109.0448, 121.0448, 162.0715, 189.06...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.13123784753008844, 0.29...</td>\n",
       "      <td>[0.13518272958203145, 0.5228597291126916, 0.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[165.0694, 166.0773, 189.0662, 201.0462, 217.0...</td>\n",
       "      <td>[0.0, 0.0, 0.13123784753008844, 0.0, 0.2909869...</td>\n",
       "      <td>[0.14140015448374113, 0.18347971647748618, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[68.9961, 80.024, 107.05, 108.0197, 113.0483, ...</td>\n",
       "      <td>[0.0052345227738534224, 0.0048955371329840215,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[53.0416, 81.0343, 81.118, 95.0853, 99.0479, 1...</td>\n",
       "      <td>[0.029083116899630047, 0.3014689882049507, 0.0...</td>\n",
       "      <td>[0.02531663138412137, 0.32400562224595714, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29067 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  mzs_True_0.01_orig_0  \\\n",
       "5    [41.0389, 44.0512, 56.0508, 61.0115, 69.0708, ...   \n",
       "26   [41.0389, 44.0512, 56.0508, 61.0115, 69.0708, ...   \n",
       "40   [41.0389, 44.0512, 56.0508, 61.0115, 65.0384, ...   \n",
       "52   [41.0389, 44.0512, 56.0508, 57.0696, 61.0115, ...   \n",
       "129  [38.9616, 39.0228, 51.0244, 55.020900000000005...   \n",
       "..                                                 ...   \n",
       "16   [110.0399, 128.0506, 176.0619, 189.0662, 190.0...   \n",
       "34   [67.0177, 109.0448, 121.0448, 162.0715, 189.06...   \n",
       "45   [165.0694, 166.0773, 189.0662, 201.0462, 217.0...   \n",
       "1    [68.9961, 80.024, 107.05, 108.0197, 113.0483, ...   \n",
       "29   [53.0416, 81.0343, 81.118, 95.0853, 99.0479, 1...   \n",
       "\n",
       "                                query_True_0.01_orig_0  \\\n",
       "5    [0.053256802574551995, 0.16757917618099427, 0....   \n",
       "26   [0.053256802574551995, 0.16757917618099427, 0....   \n",
       "40   [0.053256802574551995, 0.16757917618099427, 0....   \n",
       "52   [0.053256802574551995, 0.16757917618099427, 0....   \n",
       "129  [0.003620444403156594, 0.015135414363484355, 0...   \n",
       "..                                                 ...   \n",
       "16   [0.0, 0.0, 0.0, 0.13123784753008844, 0.0, 0.0,...   \n",
       "34   [0.0, 0.0, 0.0, 0.0, 0.13123784753008844, 0.29...   \n",
       "45   [0.0, 0.0, 0.13123784753008844, 0.0, 0.2909869...   \n",
       "1    [0.0052345227738534224, 0.0048955371329840215,...   \n",
       "29   [0.029083116899630047, 0.3014689882049507, 0.0...   \n",
       "\n",
       "                               target_True_0.01_orig_0  \n",
       "5    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...  \n",
       "26   [0.0, 0.0, 0.0, 0.0, 0.0, 0.11250624241884778,...  \n",
       "40   [0.0, 0.0, 0.0, 0.0, 0.0058862886657065, 0.057...  \n",
       "52   [0.0, 0.0, 0.0, 0.005904047994005843, 0.0, 0.0...  \n",
       "129  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0103046692995...  \n",
       "..                                                 ...  \n",
       "16   [0.08974502848695622, 0.08596487624843602, 0.4...  \n",
       "34   [0.13518272958203145, 0.5228597291126916, 0.18...  \n",
       "45   [0.14140015448374113, 0.18347971647748618, 0.0...  \n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "29   [0.02531663138412137, 0.32400562224595714, 0.0...  \n",
       "\n",
       "[29067 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[0].iloc[:,0:3].iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Train/Val/Test Data & get Individual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "24\n",
      "36\n",
      "48\n",
      "12\n",
      "24\n",
      "36\n",
      "48\n",
      "created train data\n",
      "created val data\n",
      "created test data\n"
     ]
    }
   ],
   "source": [
    "if fullRun:\n",
    "    for i in ppm_windows:\n",
    "\n",
    "        sub_train_same_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_same_ce_{i}_ppm.pkl')\n",
    "        sub_train_dif_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_dif_ce_{i}_ppm.pkl')\n",
    "        \n",
    "        train_datasets = [sub_train_same_ce, sub_train_dif_ce]\n",
    "        dataset_names = ['same_ce','dif_ce']\n",
    "\n",
    "        gbc_train_datasets = list()\n",
    "        train_unnorm_dists_=list()\n",
    "        ind_aucs_full = list()\n",
    "\n",
    "        #create init df\n",
    "        for metric in comparison_metrics:\n",
    "            for j in range(int(train_datasets[0].shape[1]/3)):\n",
    "\n",
    "                ind_aucs_full.append(f'{metric}_{j}')\n",
    "\n",
    "        ind_aucs_full = pd.DataFrame(ind_aucs_full, columns=['metric'])\n",
    "\n",
    "        for _ in range(len(train_datasets)):\n",
    "\n",
    "            ind_aucs_=None\n",
    "            train_data_gbcs = None\n",
    "            train_unnorm_dists = None\n",
    "            for j in range(int(train_datasets[_].shape[1]/3)):\n",
    "\n",
    "                sub = train_datasets[_].iloc[:,(3*j)+1:3*(j+1)]\n",
    "                old_cols = sub.columns\n",
    "                sub.columns=['query','target']\n",
    "                sub['match'] = train_datasets[_]['match'].tolist()\n",
    "\n",
    "                ind_aucs, inds, inds_unnorm = testUtils.orig_metric_to_df(comparison_metrics, sub, unnnormalized=True)\n",
    "                ind_aucs_ = pd.concat((ind_aucs_, ind_aucs))\n",
    "                print(len(ind_aucs_))\n",
    "                sub = sub.iloc[:,:2]\n",
    "                sub.columns=old_cols\n",
    "                train_data_gbcs = pd.concat((train_data_gbcs,inds), axis=1)\n",
    "                train_unnorm_dists = pd.concat((train_unnorm_dists,inds_unnorm), axis=1)\n",
    "\n",
    "            if _ ==0:    \n",
    "                ind_aucs_full['same_train']=ind_aucs_['AUC'].tolist()\n",
    "            else:\n",
    "                ind_aucs_full['dif_train']=ind_aucs_['AUC'].tolist()\n",
    "\n",
    "            train_data_gbcs['match'] = train_datasets[_]['match'].tolist()\n",
    "            gbc_train_datasets.append(train_data_gbcs)\n",
    "            train_unnorm_dists_.append(train_unnorm_dists)\n",
    "\n",
    "        with open(f'{outputs_path}/intermediateOutputs/datasets/gbc_train_{i}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "            pickle.dump(gbc_train_datasets, handle)\n",
    "\n",
    "        with open(f'{outputs_path}/intermediateOutputs/datasets/train_unnorm_dist_{i}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "            pickle.dump(train_unnorm_dists, handle)\n",
    "\n",
    "        del(train_unnorm_dists)\n",
    "        del(gbc_train_datasets)\n",
    "        del(sub_train_same_ce)\n",
    "        del(sub_train_dif_ce)\n",
    "\n",
    "        print('created train data')\n",
    "\n",
    "        sub_val_same_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/val_cleaned_matches_same_ce_{i}_ppm.pkl')\n",
    "        sub_val_dif_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/val_cleaned_matches_dif_ce_{i}_ppm.pkl')\n",
    "        val_datasets = [sub_val_same_ce, sub_val_dif_ce]\n",
    "        \n",
    "        gbc_val_datasets = list()\n",
    "        for _ in range(len(val_datasets)):\n",
    "\n",
    "            val_data_gbcs = None\n",
    "            ind_aucs_=None\n",
    "            for j in range(int(val_datasets[_].shape[1]/3)):\n",
    "\n",
    "                sub = val_datasets[_].iloc[:,(3*j)+1:3*(j+1)]\n",
    "                old_cols = sub.columns\n",
    "                sub.columns=['query','target']\n",
    "                sub['match'] = val_datasets[_]['match'].tolist()\n",
    "\n",
    "                ind_aucs, inds = testUtils.orig_metric_to_df(comparison_metrics, sub)\n",
    "                ind_aucs_ = pd.concat((ind_aucs_, ind_aucs))\n",
    "                sub = sub.iloc[:,:2]\n",
    "                sub.columns=old_cols\n",
    "                val_data_gbcs = pd.concat((val_data_gbcs,inds), axis=1)\n",
    "            \n",
    "            if _ ==0:    \n",
    "                ind_aucs_full['same_val']=ind_aucs_['AUC'].tolist()\n",
    "            else:\n",
    "                ind_aucs_full['dif_val']=ind_aucs_['AUC'].tolist()\n",
    "\n",
    "            val_data_gbcs['match'] = val_datasets[_]['match'].tolist()\n",
    "            gbc_val_datasets.append(val_data_gbcs)\n",
    "\n",
    "        with open(f'{outputs_path}/intermediateOutputs/datasets/gbc_val_{i}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "            pickle.dump(gbc_val_datasets, handle)\n",
    "\n",
    "        del(gbc_val_datasets)\n",
    "        del(sub_val_same_ce)\n",
    "        del(sub_val_dif_ce)\n",
    "        print('created val data')\n",
    "\n",
    "        sub_test_same_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test_cleaned_matches_same_ce_{i}_ppm.pkl')\n",
    "        sub_test_dif_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test_cleaned_matches_dif_ce_{i}_ppm.pkl')\n",
    "        test_datasets = [sub_test_same_ce, sub_test_dif_ce]\n",
    "\n",
    "        gbc_test_datasets = list()\n",
    "        test_unnorm_dists_ = list()\n",
    "        for _ in range(len(test_datasets)):\n",
    "\n",
    "            test_data_gbcs = None\n",
    "            ind_aucs_ = None\n",
    "            test_unnorm_dists=None\n",
    "            for j in range(int(test_datasets[_].shape[1]/3)):\n",
    "\n",
    "                sub = test_datasets[_].iloc[:,(3*j)+1:3*(j+1)]\n",
    "                old_cols = sub.columns\n",
    "                sub.columns=['query','target']\n",
    "                sub['match'] = test_datasets[_]['match'].tolist()\n",
    "\n",
    "                ind_aucs, inds, inds_unnorm = testUtils.orig_metric_to_df(comparison_metrics, sub, unnnormalized=True)\n",
    "                ind_aucs['metric'] = [f'{x}_{j}' for x in ind_aucs['metric']]\n",
    "                ind_aucs_ = pd.concat((ind_aucs_, ind_aucs))\n",
    "                sub = sub.iloc[:,:2]\n",
    "                sub.columns=old_cols\n",
    "                test_data_gbcs = pd.concat((test_data_gbcs,inds), axis=1)\n",
    "                test_unnorm_dists = pd.concat((test_unnorm_dists,inds_unnorm), axis=1)\n",
    "            \n",
    "            if _ ==0:    \n",
    "                ind_aucs_full['same_test']=ind_aucs_['AUC'].tolist()\n",
    "            else:\n",
    "                ind_aucs_full['dif_test']=ind_aucs_['AUC'].tolist()\n",
    "\n",
    "            test_data_gbcs['match'] = test_datasets[_]['match'].tolist()\n",
    "            gbc_test_datasets.append(test_data_gbcs)\n",
    "            test_unnorm_dists_.append(test_unnorm_dists)\n",
    "\n",
    "        with open(f'{outputs_path}/intermediateOutputs/datasets/gbc_test_{i}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "            pickle.dump(gbc_test_datasets, handle)\n",
    "\n",
    "        with open(f'{outputs_path}/intermediateOutputs/datasets/test_unnorm_dist_{i}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "            pickle.dump(test_unnorm_dists, handle)\n",
    "\n",
    "        del(test_unnorm_dists)\n",
    "        del(gbc_test_datasets)\n",
    "        del(sub_test_same_ce)\n",
    "        del(sub_test_dif_ce)\n",
    "        print('created test data')\n",
    "\n",
    "        ind_aucs_full.to_pickle(f'{outputs_path}/intermediateOutputs/gbc_res/ind_aucs_{i}_ppm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>manhattan</th>\n",
       "      <th>lorentzian</th>\n",
       "      <th>dot_product</th>\n",
       "      <th>fidelity</th>\n",
       "      <th>matusita</th>\n",
       "      <th>chi2</th>\n",
       "      <th>laplacian</th>\n",
       "      <th>harmonic_mean</th>\n",
       "      <th>bhattacharya_1</th>\n",
       "      <th>...</th>\n",
       "      <th>dot_product</th>\n",
       "      <th>fidelity</th>\n",
       "      <th>matusita</th>\n",
       "      <th>chi2</th>\n",
       "      <th>laplacian</th>\n",
       "      <th>harmonic_mean</th>\n",
       "      <th>bhattacharya_1</th>\n",
       "      <th>squared_chord</th>\n",
       "      <th>cross_ent</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125551</td>\n",
       "      <td>0.093622</td>\n",
       "      <td>0.370954</td>\n",
       "      <td>0.086474</td>\n",
       "      <td>0.151423</td>\n",
       "      <td>0.078818</td>\n",
       "      <td>0.169604</td>\n",
       "      <td>0.091515</td>\n",
       "      <td>0.112856</td>\n",
       "      <td>0.184178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052856</td>\n",
       "      <td>0.143840</td>\n",
       "      <td>0.074711</td>\n",
       "      <td>0.165045</td>\n",
       "      <td>0.088443</td>\n",
       "      <td>0.099232</td>\n",
       "      <td>0.175337</td>\n",
       "      <td>0.143840</td>\n",
       "      <td>0.013044</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.168332</td>\n",
       "      <td>0.125618</td>\n",
       "      <td>0.379524</td>\n",
       "      <td>0.090341</td>\n",
       "      <td>0.197026</td>\n",
       "      <td>0.103912</td>\n",
       "      <td>0.183771</td>\n",
       "      <td>0.122956</td>\n",
       "      <td>0.152969</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.168658</td>\n",
       "      <td>0.088220</td>\n",
       "      <td>0.170550</td>\n",
       "      <td>0.094352</td>\n",
       "      <td>0.115637</td>\n",
       "      <td>0.204134</td>\n",
       "      <td>0.168658</td>\n",
       "      <td>0.014004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128659</td>\n",
       "      <td>0.101849</td>\n",
       "      <td>0.373313</td>\n",
       "      <td>0.073692</td>\n",
       "      <td>0.156728</td>\n",
       "      <td>0.081701</td>\n",
       "      <td>0.170197</td>\n",
       "      <td>0.099685</td>\n",
       "      <td>0.114601</td>\n",
       "      <td>0.190340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037381</td>\n",
       "      <td>0.157818</td>\n",
       "      <td>0.082295</td>\n",
       "      <td>0.165717</td>\n",
       "      <td>0.075324</td>\n",
       "      <td>0.101263</td>\n",
       "      <td>0.191605</td>\n",
       "      <td>0.157818</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.133108</td>\n",
       "      <td>0.101928</td>\n",
       "      <td>0.374750</td>\n",
       "      <td>0.072925</td>\n",
       "      <td>0.164239</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.171144</td>\n",
       "      <td>0.099597</td>\n",
       "      <td>0.117376</td>\n",
       "      <td>0.199035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030515</td>\n",
       "      <td>0.154458</td>\n",
       "      <td>0.080467</td>\n",
       "      <td>0.162546</td>\n",
       "      <td>0.063365</td>\n",
       "      <td>0.091603</td>\n",
       "      <td>0.187706</td>\n",
       "      <td>0.154458</td>\n",
       "      <td>0.014927</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120788</td>\n",
       "      <td>0.079952</td>\n",
       "      <td>0.369003</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.153874</td>\n",
       "      <td>0.080149</td>\n",
       "      <td>0.166487</td>\n",
       "      <td>0.078080</td>\n",
       "      <td>0.103582</td>\n",
       "      <td>0.187027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021845</td>\n",
       "      <td>0.123632</td>\n",
       "      <td>0.063855</td>\n",
       "      <td>0.151993</td>\n",
       "      <td>0.036211</td>\n",
       "      <td>0.058038</td>\n",
       "      <td>0.151590</td>\n",
       "      <td>0.123632</td>\n",
       "      <td>0.014859</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388196</th>\n",
       "      <td>0.445975</td>\n",
       "      <td>0.330552</td>\n",
       "      <td>0.442858</td>\n",
       "      <td>0.669376</td>\n",
       "      <td>0.470719</td>\n",
       "      <td>0.272483</td>\n",
       "      <td>0.315860</td>\n",
       "      <td>0.319552</td>\n",
       "      <td>0.423772</td>\n",
       "      <td>0.526671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813939</td>\n",
       "      <td>0.622539</td>\n",
       "      <td>0.385621</td>\n",
       "      <td>0.429135</td>\n",
       "      <td>0.443850</td>\n",
       "      <td>0.577008</td>\n",
       "      <td>0.672584</td>\n",
       "      <td>0.622539</td>\n",
       "      <td>0.026969</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388197</th>\n",
       "      <td>0.411661</td>\n",
       "      <td>0.330552</td>\n",
       "      <td>0.441044</td>\n",
       "      <td>0.626439</td>\n",
       "      <td>0.434144</td>\n",
       "      <td>0.247766</td>\n",
       "      <td>0.296963</td>\n",
       "      <td>0.320979</td>\n",
       "      <td>0.392925</td>\n",
       "      <td>0.490058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748138</td>\n",
       "      <td>0.575634</td>\n",
       "      <td>0.348566</td>\n",
       "      <td>0.391033</td>\n",
       "      <td>0.445979</td>\n",
       "      <td>0.530518</td>\n",
       "      <td>0.628497</td>\n",
       "      <td>0.575634</td>\n",
       "      <td>0.025588</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388198</th>\n",
       "      <td>0.380878</td>\n",
       "      <td>0.324131</td>\n",
       "      <td>0.438586</td>\n",
       "      <td>0.537711</td>\n",
       "      <td>0.404189</td>\n",
       "      <td>0.228112</td>\n",
       "      <td>0.279296</td>\n",
       "      <td>0.316053</td>\n",
       "      <td>0.362258</td>\n",
       "      <td>0.459617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563425</td>\n",
       "      <td>0.494987</td>\n",
       "      <td>0.289358</td>\n",
       "      <td>0.327805</td>\n",
       "      <td>0.399459</td>\n",
       "      <td>0.442332</td>\n",
       "      <td>0.550637</td>\n",
       "      <td>0.494987</td>\n",
       "      <td>0.023250</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388199</th>\n",
       "      <td>0.345830</td>\n",
       "      <td>0.263280</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.463389</td>\n",
       "      <td>0.370949</td>\n",
       "      <td>0.206872</td>\n",
       "      <td>0.259408</td>\n",
       "      <td>0.256628</td>\n",
       "      <td>0.325324</td>\n",
       "      <td>0.425337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442278</td>\n",
       "      <td>0.429231</td>\n",
       "      <td>0.244508</td>\n",
       "      <td>0.281771</td>\n",
       "      <td>0.283444</td>\n",
       "      <td>0.366669</td>\n",
       "      <td>0.485095</td>\n",
       "      <td>0.429231</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388200</th>\n",
       "      <td>0.673201</td>\n",
       "      <td>0.432191</td>\n",
       "      <td>0.488226</td>\n",
       "      <td>0.664563</td>\n",
       "      <td>0.718184</td>\n",
       "      <td>0.469137</td>\n",
       "      <td>0.472176</td>\n",
       "      <td>0.417798</td>\n",
       "      <td>0.624798</td>\n",
       "      <td>0.759952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534288</td>\n",
       "      <td>0.676430</td>\n",
       "      <td>0.431168</td>\n",
       "      <td>0.410509</td>\n",
       "      <td>0.372463</td>\n",
       "      <td>0.554822</td>\n",
       "      <td>0.722216</td>\n",
       "      <td>0.676430</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2388201 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          entropy  manhattan  lorentzian  dot_product  fidelity  matusita  \\\n",
       "0        0.125551   0.093622    0.370954     0.086474  0.151423  0.078818   \n",
       "1        0.168332   0.125618    0.379524     0.090341  0.197026  0.103912   \n",
       "2        0.128659   0.101849    0.373313     0.073692  0.156728  0.081701   \n",
       "3        0.133108   0.101928    0.374750     0.072925  0.164239  0.085800   \n",
       "4        0.120788   0.079952    0.369003     0.059616  0.153874  0.080149   \n",
       "...           ...        ...         ...          ...       ...       ...   \n",
       "2388196  0.445975   0.330552    0.442858     0.669376  0.470719  0.272483   \n",
       "2388197  0.411661   0.330552    0.441044     0.626439  0.434144  0.247766   \n",
       "2388198  0.380878   0.324131    0.438586     0.537711  0.404189  0.228112   \n",
       "2388199  0.345830   0.263280    0.417355     0.463389  0.370949  0.206872   \n",
       "2388200  0.673201   0.432191    0.488226     0.664563  0.718184  0.469137   \n",
       "\n",
       "             chi2  laplacian  harmonic_mean  bhattacharya_1  ...  dot_product  \\\n",
       "0        0.169604   0.091515       0.112856        0.184178  ...     0.052856   \n",
       "1        0.183771   0.122956       0.152969        0.236573  ...     0.046512   \n",
       "2        0.170197   0.099685       0.114601        0.190340  ...     0.037381   \n",
       "3        0.171144   0.099597       0.117376        0.199035  ...     0.030515   \n",
       "4        0.166487   0.078080       0.103582        0.187027  ...     0.021845   \n",
       "...           ...        ...            ...             ...  ...          ...   \n",
       "2388196  0.315860   0.319552       0.423772        0.526671  ...     0.813939   \n",
       "2388197  0.296963   0.320979       0.392925        0.490058  ...     0.748138   \n",
       "2388198  0.279296   0.316053       0.362258        0.459617  ...     0.563425   \n",
       "2388199  0.259408   0.256628       0.325324        0.425337  ...     0.442278   \n",
       "2388200  0.472176   0.417798       0.624798        0.759952  ...     0.534288   \n",
       "\n",
       "         fidelity  matusita      chi2  laplacian  harmonic_mean  \\\n",
       "0        0.143840  0.074711  0.165045   0.088443       0.099232   \n",
       "1        0.168658  0.088220  0.170550   0.094352       0.115637   \n",
       "2        0.157818  0.082295  0.165717   0.075324       0.101263   \n",
       "3        0.154458  0.080467  0.162546   0.063365       0.091603   \n",
       "4        0.123632  0.063855  0.151993   0.036211       0.058038   \n",
       "...           ...       ...       ...        ...            ...   \n",
       "2388196  0.622539  0.385621  0.429135   0.443850       0.577008   \n",
       "2388197  0.575634  0.348566  0.391033   0.445979       0.530518   \n",
       "2388198  0.494987  0.289358  0.327805   0.399459       0.442332   \n",
       "2388199  0.429231  0.244508  0.281771   0.283444       0.366669   \n",
       "2388200  0.676430  0.431168  0.410509   0.372463       0.554822   \n",
       "\n",
       "         bhattacharya_1  squared_chord  cross_ent  match  \n",
       "0              0.175337       0.143840   0.013044  False  \n",
       "1              0.204134       0.168658   0.014004  False  \n",
       "2              0.191605       0.157818   0.014187  False  \n",
       "3              0.187706       0.154458   0.014927  False  \n",
       "4              0.151590       0.123632   0.014859  False  \n",
       "...                 ...            ...        ...    ...  \n",
       "2388196        0.672584       0.622539   0.026969   True  \n",
       "2388197        0.628497       0.575634   0.025588   True  \n",
       "2388198        0.550637       0.494987   0.023250   True  \n",
       "2388199        0.485095       0.429231   0.020348   True  \n",
       "2388200        0.722216       0.676430   0.090500   True  \n",
       "\n",
       "[2388201 rows x 49 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_train_datasets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create indices to pull for each metric and those with same components, specify GBC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low 3: 0.5223916221608054, rand 3: 0.9738640808314247\n",
      "low 5: 0.5865247370213909, rand 5: 0.8270788387338057\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m corr_indices\u001b[38;5;241m.\u001b[39mappend((low_corr_5,rand_corr_5))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow 5: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlow_corr_5[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, rand 5: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrand_corr_5[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m low_corr_10,rand_corr_10 \u001b[38;5;241m=\u001b[39m testUtils\u001b[38;5;241m.\u001b[39mget_least_corr_and_control(gbc_train_datasets[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     43\u001b[0m corr_indices\u001b[38;5;241m.\u001b[39mappend((low_corr_10,rand_corr_10))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow 10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlow_corr_10[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, rand 10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrand_corr_10[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/TunaSim/testUtils.py:29\u001b[0m, in \u001b[0;36mget_least_corr_and_control\u001b[0;34m(dataset, num)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m combo:\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m>\u001b[39mj:\n\u001b[0;32m---> 29\u001b[0m             corr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m corrs\u001b[38;5;241m.\u001b[39miloc[i,j]\u001b[38;5;241m/\u001b[39mmath\u001b[38;5;241m.\u001b[39mcomb(num,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corr \u001b[38;5;241m<\u001b[39m lowest_seen:\n\u001b[1;32m     32\u001b[0m     lowest_seen \u001b[38;5;241m=\u001b[39m corr\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1146\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4002\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   3983\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3984\u001b[0m \u001b[38;5;124;03mQuickly retrieve single value at passed column and index.\u001b[39;00m\n\u001b[1;32m   3985\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[38;5;124;03m`self.columns._index_as_unique`; Caller is responsible for checking.\u001b[39;00m\n\u001b[1;32m   4000\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m takeable:\n\u001b[0;32m-> 4002\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[1;32m   4005\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(col)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3803\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;66;03m# icol\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3801\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[i]\n\u001b[0;32m-> 3803\u001b[0m     col_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39miget(i)\n\u001b[1;32m   3804\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_col_values(col_mgr, i)\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# this is a cached value, mark it so\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:996\u001b[0m, in \u001b[0;36mBlockManager.iget\u001b[0;34m(self, i, track_ref)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;124;03mReturn the data as a SingleBlockManager.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    995\u001b[0m block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos[i]]\n\u001b[0;32m--> 996\u001b[0m values \u001b[38;5;241m=\u001b[39m block\u001b[38;5;241m.\u001b[39miget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs[i])\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# shortcut for select a single-dim from a 2-dim BM\u001b[39;00m\n\u001b[1;32m    999\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(values)))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:1007\u001b[0m, in \u001b[0;36mBlock.iget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshape\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Shape:\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m-> 1007\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miget\u001b[39m(\u001b[38;5;28mself\u001b[39m, i: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;66;03m# In the case where we have a tuple[slice, int], the slice will always\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;66;03m#  be slice(None)\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Note: only reached with self.ndim == 2\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Invalid index type \"Union[int, Tuple[int, int], Tuple[slice, int]]\"\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     \u001b[38;5;66;03m# for \"Union[ndarray[Any, Any], ExtensionArray]\"; expected type\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;66;03m# \"Union[int, integer[Any]]\"\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues[i]  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_slice\u001b[39m(\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28mself\u001b[39m, slicer: \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]\n\u001b[1;32m   1018\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(testUtils)\n",
    "comparison_metrics = ['entropy',\n",
    "             'manhattan',\n",
    "             'lorentzian',\n",
    "             'dot_product',\n",
    "             'fidelity',\n",
    "             'matusita',\n",
    "             'chi2',\n",
    "             'laplacian',\n",
    "             'harmonic_mean',\n",
    "             'bhattacharya_1',\n",
    "             'squared_chord',\n",
    "             'cross_ent'\n",
    "    ]\n",
    "\n",
    "with open(f'{outputs_path}/intermediateOutputs/datasets/gbc_train_{ppm_windows[0]}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "    gbc_train_datasets = pickle.load(handle)\n",
    "\n",
    "models = [\n",
    "                hgbc(),\n",
    "                hgbc(learning_rate=0.5),\n",
    "                hgbc(max_iter=200),\n",
    "                hgbc(learning_rate=0.01,min_samples_leaf=10),\n",
    "                hgbc(max_iter=200,min_samples_leaf=10),\n",
    "                hgbc(learning_rate=0.5, max_iter=200,min_samples_leaf=10),\n",
    "                ]\n",
    "\n",
    "indices = dict()\n",
    "corr_indices = list()\n",
    "indices['all-sims'] = list(range(gbc_train_datasets[0].shape[1]-1))\n",
    "indices['all-mults'] = list()\n",
    "indices['all-ents'] = list()\n",
    "indices['all-difs'] = list()\n",
    "\n",
    "low_corr_3,rand_corr_3 = testUtils.get_least_corr_and_control(gbc_train_datasets[1].iloc[:,:-1],3)\n",
    "corr_indices.append((low_corr_3,rand_corr_3))\n",
    "print(f'low 3: {low_corr_3[1]}, rand 3: {rand_corr_3[1]}')\n",
    "low_corr_5,rand_corr_5= testUtils.get_least_corr_and_control(gbc_train_datasets[1].iloc[:,:-1],5)\n",
    "corr_indices.append((low_corr_5,rand_corr_5))\n",
    "print(f'low 5: {low_corr_5[1]}, rand 5: {rand_corr_5[1]}')\n",
    "low_corr_10,rand_corr_10 = testUtils.get_least_corr_and_control(gbc_train_datasets[1].iloc[:,:-1],10)\n",
    "corr_indices.append((low_corr_10,rand_corr_10))\n",
    "print(f'low 10: {low_corr_10[1]}, rand 10: {rand_corr_10[1]}')\n",
    "low_corr_15,rand_corr_15 = testUtils.get_least_corr_and_control(gbc_train_datasets[1].iloc[:,:-1],15)\n",
    "corr_indices.append((low_corr_15,rand_corr_15))\n",
    "print(f'low 15: {low_corr_15[1]}, rand 15: {rand_corr_15[1]}')\n",
    "low_corr_20,rand_corr_20 = testUtils.get_least_corr_and_control(gbc_train_datasets[1].iloc[:,:-1],20)\n",
    "corr_indices.append((low_corr_20,rand_corr_20))\n",
    "print(f'low 20: {low_corr_20[1]}, rand 20: {rand_corr_20[1]}')\n",
    "\n",
    "for i in range(int((gbc_train_datasets[1].shape[1]-1)/len(comparison_metrics))):\n",
    "\n",
    "    low_corr_3,rand_corr_3 = testUtils.get_least_corr_and_control(gbc_train_datasets[1].iloc[:,i:(i+1)*len(comparison_metrics)],3)\n",
    "    corr_indices.append((low_corr_3,rand_corr_3))\n",
    "    low_corr_5,rand_corr_5= testUtils.get_least_corr_and_control(gbc_train_datasets[1].iloc[:,i:(i+1)*len(comparison_metrics)],5)\n",
    "    corr_indices.append((low_corr_5,rand_corr_5))\n",
    "\n",
    "    print(f'low 3 {i}: {low_corr_3[1]}, rand 3 {i}: {rand_corr_3[1]}')\n",
    "    print(f'low 5 {i}: {low_corr_5[1]}, rand 5 {i}: {rand_corr_5[1]}')\n",
    "\n",
    "    indices[f'all_setting-{i}'] = list(np.array(range(len(comparison_metrics)))+(i*len(comparison_metrics)))\n",
    "    indices[f'mults-{i}'] = list(np.array([3,4,9,11])+(i*len(comparison_metrics)))\n",
    "    indices[f'difs-{i}'] = list(np.array([1,2,5,7,10])+(i*len(comparison_metrics)))\n",
    "    indices[f'low_corr_3-{i}'] = list(np.array(low_corr_3[0])+(i*len(comparison_metrics)))\n",
    "    indices[f'low_corr_5-{i}'] = list(np.array(low_corr_5[0])+(i*len(comparison_metrics)))\n",
    "    indices[f'rand_3-{i}'] = list(np.array(rand_corr_3[0])+(i*len(comparison_metrics)))\n",
    "    indices[f'rand_5-{i}'] = list(np.array(rand_corr_5[0])+(i*len(comparison_metrics)))\n",
    "\n",
    "    indices[f'all-mults'] = indices['all-mults'] +list(np.array([3,4,9,11])+(i*len(comparison_metrics)))\n",
    "    indices[f'all-ents'] =  indices['all-ents'] + list(np.array([0])+(i*len(comparison_metrics)))\n",
    "    indices[f'all-difs'] =  indices['all-difs'] + list(np.array([1,2,5,7,10])+(i*len(comparison_metrics)))\n",
    "\n",
    "\n",
    "with open(f'{outputs_path}/intermediateOutputs/gbc_res/custom_indices_{ppm_windows[0]}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "    pickle.dump(corr_indices,handle)\n",
    "    del(corr_indices)\n",
    "\n",
    "print(f' total number of models for each: {len(models) * len(indices)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Models and Collect Train Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in ppm_windows:\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/datasets/gbc_train_{window}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "        gbc_train_datasets = pickle.load(handle)\n",
    "     \n",
    "    same_train_model_aucs = list()\n",
    "    model_names = list()\n",
    "    dif_train_model_aucs = list()\n",
    "    trained_models = dict()\n",
    "\n",
    "    for key, value in indices.items():\n",
    "\n",
    "        sub = gbc_train_datasets[0].iloc[:,value]\n",
    "        models_ = copy.deepcopy(models)\n",
    "\n",
    "        for i in range(len(models_)):\n",
    "\n",
    "            models_[i].fit(sub,gbc_train_datasets[0]['match'])\n",
    "            pos_ind = np.where(models_[i].classes_==1)[0][0]\n",
    "            same_train_model_aucs.append(auc(gbc_train_datasets[0]['match'],models_[i].predict_proba(sub)[:,pos_ind]))\n",
    "            model_names.append(f'{key}_{i}')\n",
    "            trained_models[f'same_{key}_{i}'] = models_[i]\n",
    "\n",
    "        sub = gbc_train_datasets[1].iloc[:,value]\n",
    "        models_ = copy.deepcopy(models)\n",
    "\n",
    "        for i in range(len(models_)):\n",
    "\n",
    "            models_[i].fit(sub,gbc_train_datasets[1]['match'])\n",
    "            pos_ind = np.where(models_[i].classes_==1)[0][0]\n",
    "            dif_train_model_aucs.append(auc(gbc_train_datasets[1]['match'],models_[i].predict_proba(sub)[:,pos_ind]))\n",
    "            trained_models[f'dif_{key}_{i}'] = models_[i]\n",
    "\n",
    "    model_aucs = pd.DataFrame([model_names, same_train_model_aucs, dif_train_model_aucs]).transpose()\n",
    "    model_aucs.columns = ['name','same_train','dif_train']\n",
    "\n",
    "    del(gbc_train_datasets)\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/datasets/gbc_val_{window}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "        gbc_val_datasets = pickle.load(handle)\n",
    "\n",
    "    same_val = list()\n",
    "    dif_val = list()\n",
    "    same_test = list()\n",
    "    dif_test = list()\n",
    "\n",
    "    for name in model_aucs['name'].tolist():\n",
    "\n",
    "        subset_name = name.split('_')[0]\n",
    "\n",
    "        sub = gbc_val_datasets[0].iloc[:,indices[subset_name]]\n",
    "        model = trained_models[f'same_{name}']\n",
    "        pos_ind = np.where(model.classes_==1)[0][0]\n",
    "        same_val.append(auc(gbc_val_datasets[0]['match'],model.predict_proba(sub)[:,pos_ind]))\n",
    "\n",
    "        sub = gbc_val_datasets[1].iloc[:,indices[subset_name]]\n",
    "        model = trained_models[f'dif_{name}']\n",
    "        pos_ind = np.where(model.classes_==1)[0][0]\n",
    "        dif_val.append(auc(gbc_val_datasets[1]['match'],model.predict_proba(sub)[:,pos_ind]))\n",
    "\n",
    "    del(gbc_val_datasets)\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/datasets/gbc_test_{window}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "        gbc_test_datasets = pickle.load(handle)\n",
    "\n",
    "    for name in model_aucs['name'].tolist():\n",
    "\n",
    "        subset_name = name.split('_')[0]\n",
    "\n",
    "        sub = gbc_test_datasets[0].iloc[:,indices[subset_name]]\n",
    "        model = trained_models[f'same_{name}']\n",
    "        pos_ind = np.where(model.classes_==1)[0][0]\n",
    "        same_test.append(auc(gbc_test_datasets[0]['match'],model.predict_proba(sub)[:,pos_ind]))\n",
    "\n",
    "        sub = gbc_test_datasets[1].iloc[:,indices[subset_name]]\n",
    "        model = trained_models[f'dif_{name}']\n",
    "        pos_ind = np.where(model.classes_==1)[0][0]\n",
    "        dif_test.append(auc(gbc_test_datasets[1]['match'],model.predict_proba(sub)[:,pos_ind]))\n",
    "\n",
    "    del(gbc_test_datasets)\n",
    "\n",
    "    model_aucs['same_val'] = same_val\n",
    "    model_aucs['dif_val'] = dif_val\n",
    "    model_aucs['same_test'] = same_test\n",
    "    model_aucs['dif_test'] = dif_test\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/gbc_res/model_aucs_{window}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "        pickle.dump(model_aucs,handle)\n",
    "        del(model_aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Functions to original metrics, evaluate how far off we are on test data with original normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inits = {'a' : 1,\n",
    "        'b': 1,\n",
    "        'c' : 1,\n",
    "        'd' : -1,\n",
    "        'e' : 1,\n",
    "        'f' : 1,\n",
    "        'g' :1,\n",
    "        'h' :0,\n",
    "        'i' : -1,\n",
    "        'j' :1,\n",
    "        'k' : 1,\n",
    "        'l' : 1,\n",
    "        'm' : 1,\n",
    "        'n' : -1,\n",
    "        'o' : 1,\n",
    "        'p' : 1,\n",
    "        'q' : 1,\n",
    "        'r' : 0,\n",
    "        's' : 1,\n",
    "        't' : -1,\n",
    "        'u' : 1,\n",
    "        'v' : -1,\n",
    "        'w' : 1,\n",
    "        'x' : 1,\n",
    "        'y' : 1,\n",
    "        'z' : 1,\n",
    "        'a_' : 1,\n",
    "        'b_' : -1,\n",
    "        'c_' : 1,\n",
    "        'd_' : -1,\n",
    "        'e_' : 1,\n",
    "        'f_' : 1,\n",
    "        'g_' : 1,\n",
    "        'h_' : 1,\n",
    "        'i_' : 1,\n",
    "        'j_' : -1,\n",
    "        'k_' : 1,\n",
    "        'l_': -1,\n",
    "        'm_' : 1,\n",
    "        'n_' : 1,\n",
    "        'o_' : 1,\n",
    "        'p_' : 1,\n",
    "        'q_' : -1,\n",
    "        'r_' : 1,\n",
    "        's_' : -1,\n",
    "        't_' : 1,\n",
    "        'u_' : 1,\n",
    "        'v_' : 1,\n",
    "        'w_' : -1,\n",
    "        'x_' : 1,\n",
    "        'y_' : -1,\n",
    "        'z_':1}\n",
    "\n",
    "\n",
    "fit_funcs = {\n",
    "    'entropy-1':(['f','g','i','n_','p_'],None),\n",
    "    'entropy-2':(['f','g','h','i','j','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'entropy-3':(['f','g','h','i','j','n_','o_','p_','q_','r_','s_','b','l','x','y','z','a_','b_','c_','d_','e_'],None),\n",
    "    'lorentzian-1':(['a','b'],None),\n",
    "    'lorentzian-2':(['a','b','c','d','e'],None),\n",
    "    'lorentzian-3':(['a','b','c','d','e','f','g','h','i','j','k','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'dot_product-1':(['k','l','t_','u_'],None),\n",
    "    'dot_product-2':(['k','l','m','n','o','t_','u_','v_','w_','x_','y_'],None),\n",
    "    'dot_product-3':(['k','l','m','n','o','t_','u_','v_','w_','x_','y_','k','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'harmonic_mean-1':(['x','y','z','a_','b_','c_'],None),\n",
    "    'harmonic_mean-2':(['b','l','x','y','z','a_','b_','c_','d_','e_','b','l'],None),\n",
    "    'harmonic_mean-3':(['b','l','x','y','z','a_','b_','c_','d_','e_','b','l','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'fidelity-1':(['k','l','m'],None),\n",
    "    'fidelity-2':(['k','l','m','n','o',],None),\n",
    "    'fidelity-3':(['k','l','m','n','o','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'squared_chord-1':(['a','b'],None),\n",
    "    'squared_chord-2':(['a','b','c','d','e'],None),\n",
    "    'squared_chord-3':(['a','b','c','d','e','f','g','h','i','j','k','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'bhattacharya_1-1':(['a','b'],None),\n",
    "    'bhattacharya_1-2':(['a','b','c','d','e'],None),\n",
    "    'bhattacharya_1-3':(['a','b','c','d','e','f','g','h','i','j','k','n_','o_','p_','q_','r_','s_'],None),\n",
    "}\n",
    "\n",
    "reload(testUtils)\n",
    "reload(func_ob)\n",
    "reload(TunaSims)\n",
    "\n",
    "train_reses = list()\n",
    "test_reses = list()\n",
    "for i in ppm_windows:\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/datasets/train_unnorm_dist_{i}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "        train_labels = pickle.load(handle)\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/datasets/test_unnorm_dist_{i}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "        test_labels = pickle.load(handle)\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_dif_ce_{i}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "        train_specs = pickle.load(handle)\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/splitMatches/test_cleaned_matches_dif_ce_{i}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "        test_specs = pickle.load(handle)\n",
    "\n",
    "    #just focus on first setting for now\n",
    "    train_labels = train_labels.iloc[:,:len(comparison_metrics)]\n",
    "    train_specs = train_specs.iloc[:,:2]\n",
    "    train_specs.columns=['query','target']\n",
    "\n",
    "    test_labels = test_labels.iloc[:,:len(comparison_metrics)]\n",
    "    test_specs = test_specs.iloc[:,:2]\n",
    "    test_specs.columns=['query','target']\n",
    "\n",
    "    squared_loss = lambda x: (x)**2\n",
    "    lin_loss = lambda x: np.abs(x)\n",
    "    l1_reg = lambda l,x: l*np.sum(np.abs(x))\n",
    "    l2_reg = lambda l,x: l*np.sqrt(np.sum(x**2))\n",
    "    no_reg = lambda x: 0\n",
    "\n",
    "    reg_funcs = [no_reg,partial(l2_reg,0.01),partial(l1_reg,0.01)]\n",
    "    reg_names = ['none','l2_0.01','l1_0.01']\n",
    "    losses = [squared_loss]\n",
    "    loss_names = ['squared']\n",
    "    momentums = ['none','simple','jonie']\n",
    "    mom_weights = [[0.2,0.8],[0.8,0.2]]\n",
    "    lambdas = [0.01]\n",
    "    max_iters = [1e4]\n",
    "\n",
    "    funcs = testUtils.create_all_funcs_stoch(reg_funcs=reg_funcs,\n",
    "                                        reg_names=reg_names,\n",
    "                                        losses=losses,\n",
    "                                        loss_names=loss_names,\n",
    "                                        momentums=momentums,\n",
    "                                        inits = inits,\n",
    "                                        params=fit_funcs,\n",
    "                                        mom_weights=mom_weights,\n",
    "                                        lambdas=lambdas,\n",
    "                                        max_iters=max_iters,\n",
    "                                        func = TunaSims.tuna_combo_distance_demo)\n",
    "    \n",
    "    print(f'total number of functions : {len(funcs)}')\n",
    "    trained=list()\n",
    "    for func in funcs:\n",
    "\n",
    "        name = func.name.split('-')[0]\n",
    "        train_specs['match'] = train_labels[name]\n",
    "\n",
    "        func.fit(train_specs)\n",
    "        trained.append(func)\n",
    "        print(func.name)\n",
    "\n",
    "    #get train and test errors under proper normalization protocol\n",
    "    trained_res=list()\n",
    "    test_res=list()\n",
    "    names=list()\n",
    "    for func in trained:\n",
    "\n",
    "        #generate proper train and test datasets\n",
    "        name = func.name.split('-')[0]\n",
    "        train_specs['match'] = train_labels[name]\n",
    "        test_specs['match'] = test_labels[name]\n",
    "\n",
    "        #get trained_func\n",
    "        pred_func = func.trained_func()\n",
    "\n",
    "        trained_res.append(testUtils.get_func_dist(train_specs, pred_func, name))\n",
    "        test_res.append(testUtils.get_func_dist(test_specs, pred_func, name))\n",
    "        names.append(f'{name}_{func.regularization_func}_{func.momentum}_{func.mom_weights}')\n",
    "        \n",
    "\n",
    "    trained_res = pd.DataFrame(trained_res).transpose()\n",
    "    trained_res.columns  = names\n",
    "\n",
    "    test_res = pd.DataFrame(test_res).transpose()\n",
    "    test_res.columns  = names\n",
    "\n",
    "    train_reses.append(trained_res)\n",
    "    test_reses.append(test_res)\n",
    "\n",
    "with open(f'{outputs_path}/intermediateOutputs/train_to_func/trained_reses_{i}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "    pickle.dump(train_reses, handle)\n",
    "\n",
    "with open(f'{outputs_path}/intermediateOutputs/train_to_func/test_reses_{i}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "    pickle.dump(test_reses, handle)\n",
    "\n",
    "del(train_reses)\n",
    "del(test_reses)\n",
    "del(train_labels)\n",
    "del(test_labels)\n",
    "del(train_specs)\n",
    "del(test_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Distance Functions by Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadk = False\n",
    "if quadk:\n",
    "    flats = {\n",
    "            'fdif_quadk':(['a','b','c','d','e'],None),\n",
    "            'fadd_quadk':(['f','g','h','i','j'],None),\n",
    "            'fmult_quadk':(['k','l','m','n','o'],None),\n",
    "    }\n",
    "\n",
    "    exts = {'edif_add':(['b','g','p','q','r','s','t','u','v','w'],None),\n",
    "            'edif_mult':(['b','l','x','y','z','a_','b_','c_','d_','e_'],None),\n",
    "            'emult_add':(['l','g','f_','g_','h_','i_','j_','k_','l_','m_'],None),      \n",
    "    }\n",
    "\n",
    "    params = dict()\n",
    "    seen =set()\n",
    "    for key in flats.keys():\n",
    "        for key_ in flats.keys():\n",
    "\n",
    "            feature_type = key.split('_')[0]\n",
    "            feature_type_ = key_.split('_')[0]\n",
    "\n",
    "            func_type = key.split('_')[1]\n",
    "            func_type_ = key_.split('_')[1]\n",
    "\n",
    "            try:\n",
    "                bounds_type = key.split('_')[2]\n",
    "                bounds_type_ = key_.split('_')[2]\n",
    "            except:\n",
    "                bounds_type = ''\n",
    "                bounds_type_ = ''\n",
    "\n",
    "            if f'{key_}_{key}' in params.keys():\n",
    "                continue\n",
    "            params[f'{key}_{key_}']=(sorted(list(set(flats[key][0]+flats[key_][0]))),testUtils.dict_combine(flats[key][1],flats[key_][1]))\n",
    "            \n",
    "    params_ = dict()\n",
    "    seen =set()\n",
    "    for key in exts.keys():\n",
    "        for key_ in exts.keys():\n",
    "\n",
    "            feature_type = key.split('_')[0]\n",
    "            feature_type_ = key_.split('_')[0]\n",
    "\n",
    "            func_type = key.split('_')[1]\n",
    "            func_type_ = key_.split('_')[1]\n",
    "\n",
    "            try:\n",
    "                bounds_type = key.split('_')[2]\n",
    "                bounds_type_ = key_.split('_')[2]\n",
    "            except:\n",
    "                bounds_type = ''\n",
    "                bounds_type_ = ''\n",
    "\n",
    "            if f'{key_}_{key}' in params_.keys():\n",
    "                continue\n",
    "            params_[f'{key}_{key_}']=(sorted(list(set(exts[key][0]+exts[key_][0]))),testUtils.dict_combine(exts[key][1],exts[key_][1]))\n",
    "\n",
    "    params.update(params_)   \n",
    "\n",
    "    params['all_flat_quadk']= (['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o'],None)\n",
    "    params['all_ext_quadk'] = (['b','l','g','p','q','r','s','t','u','v','w','x','y','z','a_','b_','c_','d_','e_','f_','g_','h_','i_','j_','k_','l_','m_','t_','u_','v_','w_','x_','y_'],None)\n",
    "\n",
    "    for key in list(params_.keys())[:5]:\n",
    "        params[f'{key}_normed_add']=(sorted(list(set(params_[key][0]+['n_','o_','p_','q_','r_','s_']))),testUtils.dict_combine(params_[key][1],None))\n",
    "        params[f'{key}_normed_mult']=(sorted(list(set(params_[key][0]+['t_','u_','v_','w_','x_','y_']))),testUtils.dict_combine(params_[key][1],None))\n",
    "\n",
    "    params['norm_only_add']=(['n_','o_','p_','q_','r_','s_'],None)\n",
    "    params['norm_only_mult']=(['t_','u_','v_','w_','x_','y_'],None)\n",
    "\n",
    "quad=True\n",
    "if quad:\n",
    "    flats = {\n",
    "            'fdif_quad':(['a','b','c'],None),\n",
    "            'fadd_quad':(['f','g','h'],None),\n",
    "            'fmult_quad':(['k','l','m'],None),\n",
    "    }\n",
    "\n",
    "    exts = {'edif_add_quad':(['b','g','p','q','r','s','t','u'],None),\n",
    "            'edif_mult_quad':(['b','l','x','y','z','a_','b_','c_'],None),\n",
    "            'emult_add_quad':(['l','g','f_','g_','h_','i_','j_','k_'],None),      \n",
    "    }\n",
    "\n",
    "    params2 = dict()\n",
    "    seen =set()\n",
    "    for key in flats.keys():\n",
    "        for key_ in flats.keys():\n",
    "\n",
    "            feature_type = key.split('_')[0]\n",
    "            feature_type_ = key_.split('_')[0]\n",
    "\n",
    "            func_type = key.split('_')[1]\n",
    "            func_type_ = key_.split('_')[1]\n",
    "\n",
    "            try:\n",
    "                bounds_type = key.split('_')[2]\n",
    "                bounds_type_ = key_.split('_')[2]\n",
    "            except:\n",
    "                bounds_type = ''\n",
    "                bounds_type_ = ''\n",
    "\n",
    "            if f'{key_}_{key}' in params2.keys():\n",
    "                continue\n",
    "            params2[f'{key}_{key_}']=(sorted(list(set(flats[key][0]+flats[key_][0]))),testUtils.dict_combine(flats[key][1],flats[key_][1]))\n",
    "            \n",
    "    params2_ = dict()\n",
    "    seen =set()\n",
    "    for key in exts.keys():\n",
    "        for key_ in exts.keys():\n",
    "\n",
    "            feature_type = key.split('_')[0]\n",
    "            feature_type_ = key_.split('_')[0]\n",
    "\n",
    "            func_type = key.split('_')[1]\n",
    "            func_type_ = key_.split('_')[1]\n",
    "\n",
    "            try:\n",
    "                bounds_type = key.split('_')[2]\n",
    "                bounds_type_ = key_.split('_')[2]\n",
    "            except:\n",
    "                bounds_type = ''\n",
    "                bounds_type_ = ''\n",
    "\n",
    "            if f'{key_}_{key}' in params2_.keys():\n",
    "                continue\n",
    "            params2_[f'{key}_{key_}']=(sorted(list(set(exts[key][0]+exts[key_][0]))),testUtils.dict_combine(exts[key][1],exts[key_][1]))\n",
    "\n",
    "    params2['all_flat_quad']= (['a','b','c','f','g','h','k','l','m'],None)\n",
    "    params2['all_ext_quad'] = (['b','l','g','p','q','r','s','t','u','x','y','z','a_','b_','c_','f_','g_','h_','i_','j_','k_'],None)\n",
    "\n",
    "\n",
    "    for key in list(params2_.keys())[:5]:\n",
    "        params2[f'{key}_normed_add']=(sorted(list(set(params2_[key][0]+['n_','o_','p_','s_']))),testUtils.dict_combine(params2_[key][1],None))\n",
    "        params2[f'{key}_normed_mult']=(sorted(list(set(params2_[key][0]+['t_','u_','v_','w_','x_','y_']))),testUtils.dict_combine(params2_[key][1],None))\n",
    "\n",
    "    params2.update(params2_) \n",
    "    #params.update(params2)  \n",
    "\n",
    "    for key in list(params2.keys())[:10]:\n",
    "        params[f'{key}_sigtune']=(params[key][0]+['z_'],None)\n",
    "\n",
    "    # for key in list(params2.keys())[:10]:\n",
    "    #     params[f'{key}_with_mz']=(params[key][0]+['z_'],None)\n",
    "\n",
    "    reload(func_ob)\n",
    "    reload(TunaSims)\n",
    "    reload(testUtils)\n",
    "    #helper lambda funcs\n",
    "    squared_loss = lambda x: (1-x)**2\n",
    "    lin_loss = lambda x: np.abs(1-x)\n",
    "    l1_reg = lambda l,x: l*np.sum(np.abs(x))\n",
    "    l2_reg = lambda l,x: l*np.sqrt(np.sum(x**2))\n",
    "    no_reg = lambda x: 0\n",
    "\n",
    "    reg_funcs = [no_reg,partial(l2_reg,0.01),partial(l2_reg,0.1)]\n",
    "    reg_names = ['none_none','l2_0.01','l2_0.1']\n",
    "    losses = [squared_loss]\n",
    "    loss_names = ['squared']\n",
    "    momentums = ['none']\n",
    "    mom_weights = [[0.2,0.8]]\n",
    "    lambdas = [0.01]\n",
    "    max_iters = [1e4]\n",
    "\n",
    "    funcs_same = testUtils.create_all_funcs_stoch(reg_funcs=reg_funcs,\n",
    "                                        reg_names=reg_names,\n",
    "                                        losses=losses,\n",
    "                                        loss_names=loss_names,\n",
    "                                        momentums=momentums,\n",
    "                                        params=params2,\n",
    "                                        inits=inits,\n",
    "                                        mom_weights=mom_weights,\n",
    "                                        lambdas=lambdas,\n",
    "                                        max_iters=max_iters,\n",
    "                                        func = TunaSims.tuna_combo_distance)\n",
    "\n",
    "    funcs_dif = testUtils.create_all_funcs_stoch(reg_funcs=reg_funcs,\n",
    "                                        reg_names=reg_names,\n",
    "                                        losses=losses,\n",
    "                                        loss_names=loss_names,\n",
    "                                        momentums=momentums,\n",
    "                                        params=params2,\n",
    "                                        inits=inits,\n",
    "                                        mom_weights=mom_weights,\n",
    "                                        lambdas=lambdas,\n",
    "                                        max_iters=max_iters,\n",
    "                                        func = TunaSims.tuna_combo_distance)\n",
    "\n",
    "    all_funcs_ = [funcs_same, funcs_dif]\n",
    "\n",
    "    print(f'number of specifications: {len(funcs_same)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in ppm_windows:\n",
    "\n",
    "    trained_dict = dict()\n",
    "    all_funcs = copy.deepcopy(all_funcs_)\n",
    "\n",
    "    sub_train_same_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_same_ce_{window}_ppm.pkl')\n",
    "    sub_train_dif_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_dif_ce_{window}_ppm.pkl')\n",
    "    \n",
    "    train_datasets = [sub_train_same_ce, sub_train_dif_ce]\n",
    "    dataset_names = ['same_ce','dif_ce']\n",
    "\n",
    "    settings = 1\n",
    "\n",
    "    for _ in range(len(train_datasets)):\n",
    "        \n",
    "        for j in range(settings):\n",
    "\n",
    "            sub = train_datasets[_].iloc[:,3*j:3*(j+1)]\n",
    "            sub.columns=['mzs','query','target']\n",
    "            sub['precursor'] = train_datasets[_]['precursor']\n",
    "            sub['match'] = train_datasets[_]['match']\n",
    "        \n",
    "            trained=list()\n",
    "            for i in range(len(all_funcs[_])):\n",
    "                \n",
    "                all_funcs[_][i].fit(sub)\n",
    "                trained.append(all_funcs[_][i])\n",
    "                if (i+1)%10==0:\n",
    "                    print(f'trained {i+1} functions on {dataset_names[_]}_{j}')\n",
    "\n",
    "\n",
    "            trained_dict[f'{dataset_names[_]}_{j}'] = trained\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/train_to_error/trained_dict_{window}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "        pickle.dump(trained_dict, handle)\n",
    "        del(trained_dict)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in ppm_windows:\n",
    "    \n",
    "    sub_train_same_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_same_ce_{window}_ppm.pkl')\n",
    "    sub_train_dif_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_dif_ce_{window}_ppm.pkl')\n",
    "    \n",
    "    train_datasets = [sub_train_same_ce, sub_train_dif_ce]\n",
    "    dataset_names = ['same_ce','dif_ce']\n",
    "\n",
    "    settings=1\n",
    "\n",
    "    trained_res=None\n",
    "    for _ in range(len(train_datasets)):\n",
    "        for j in range(settings):\n",
    "\n",
    "            #grab trained models for this portion of dataframe\n",
    "            sub = train_datasets[_].iloc[:,3*j:3*(j+1)]\n",
    "            sub.columns=['mzs','query','target']\n",
    "            sub['precursor'] = train_datasets[_]['precursor']\n",
    "            sub['match'] = train_datasets[_]['match']\n",
    "\n",
    "            small = testUtils.trained_res_to_df(models,sub)\n",
    "            small.insert(1,'settings', f'{dataset_names[_]}_{j}')\n",
    "            trained_res=pd.concat((trained_res,small))\n",
    "            print(f'completed {dataset_names[_]}_{j}')\n",
    "\n",
    "    print('generated train results')\n",
    "    del(sub_train_dif_ce)\n",
    "    del(sub_train_same_ce)\n",
    "\n",
    "    sub_val_same_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/val_cleaned_matches_same_ce_{window}_ppm.pkl')\n",
    "    sub_val_dif_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/val_cleaned_matches_dif_ce_{window}_ppm.pkl')\n",
    "    val_datasets = [sub_val_same_ce, sub_val_dif_ce]\n",
    "\n",
    "    val_aucs=list()\n",
    "    for _ in range(len(val_datasets)):\n",
    "        for j in range(settings):\n",
    "\n",
    "            #grab trained models for this portion of dataframe\n",
    "            models = trained_dict[f'{dataset_names[_]}_{j}']\n",
    "            sub = val_datasets[_].iloc[:,3*j:3*(j+1)]\n",
    "            sub.columns=['mzs','query','target']\n",
    "            sub['precursor'] = val_datasets[_]['precursor']\n",
    "            sub['match'] = val_datasets[_]['match']\n",
    "            val_aucs = val_aucs + testUtils.trained_res_to_df(models,sub)['auc'].tolist()\n",
    "            print(f'completed {dataset_names[_]}_{j}')\n",
    "\n",
    "    trained_res['val']=val_aucs\n",
    "    print('generated val results')\n",
    "\n",
    "    del(sub_val_dif_ce)\n",
    "    del(sub_val_same_ce)\n",
    "\n",
    "    sub_test_same_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test_cleaned_matches_same_ce_{window}_ppm.pkl')\n",
    "    sub_test_dif_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test_cleaned_matches_dif_ce_{window}_ppm.pkl')\n",
    "    test_datasets = [sub_test_same_ce, sub_test_dif_ce]\n",
    "    \n",
    "    test_aucs=list()\n",
    "    for _ in range(len(test_datasets)):\n",
    "        for j in range(settings):\n",
    "\n",
    "            #grab trained models for this portion of dataframe\n",
    "            models = trained_dict[f'{dataset_names[_]}_{j}']\n",
    "            sub = test_datasets[_].iloc[:,3*j:3*(j+1)]\n",
    "            sub.columns=['mzs','query','target']\n",
    "            sub['precursor'] = test_datasets[_]['precursor']\n",
    "            sub['match'] = test_datasets[_]['match'].tolist()\n",
    "            test_aucs = test_aucs + testUtils.trained_res_to_df(models,sub)['auc'].tolist()\n",
    "            print(f'completed {dataset_names[_]}_{j}')\n",
    "\n",
    "    trained_res['test']=test_aucs\n",
    "    print('generated test results')\n",
    "\n",
    "    del(sub_test_dif_ce)\n",
    "    del(sub_test_same_ce)\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/train_to_error/trained_res_{window}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "        pickle.dump(trained_res, handle)\n",
    "        del(trained_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions: \n",
    "\n",
    "add offsets for terms\n",
    "\n",
    "num of params not appearing to change train time much\n",
    "\n",
    "consider replacing knockouts with sigmoids\n",
    "\n",
    "consider tuning final sigmoid\n",
    "\n",
    "should features like length,entropy be included in the similarity, or be used outside as extra feature in learned mod.both? neither?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Ideas:\n",
    "\n",
    "Accuracy (In order of increasing difficulty):\n",
    "\n",
    "-Incorporate as feature how many possible chem structures (can also restrict to NPS) exist within a certain precursor distance. (violating golden rules or not)\n",
    "\n",
    "-include original NIST version or theoretical res as feature\n",
    "\n",
    "-Weight different ranges of spec differently for matches (more diversity/greater accuracy)\n",
    "\n",
    "-smush together top n results over different inchicores and come up with combined model predicting over individual inchicores\n",
    "\n",
    "-diagnostic ion/loss classing as a feature...do they match\n",
    "\n",
    "-kernelized smooth match\n",
    "\n",
    "-3d struct guesses...do they match (cores, but can generalize to 3d)\n",
    "\n",
    "Speed(In order of increasing difficulty):\n",
    "\n",
    "-combine sim metrics and expand(apply func to df)\n",
    "\n",
    "-exclude matches based on non-similarity features to cut down on needed comparisons\n",
    "\n",
    "-ion tables to upper bound similarity\n",
    "\n",
    "-only use one peak consolidation and matching protocol...then only do reweight transformations on already matched peaks for spec and sim features\n",
    "\n",
    "-can missing peaks in lower energy be explained by frags and losses from higher energy? incorporate into model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order to proceed:\n",
    "\n",
    "-recreate databases with coll energy included (standardized format across DBs)\n",
    "\n",
    "-what proportion of matches are the same coll energy?\n",
    "\n",
    "-quantify variability in peak appearance vs peak intensity across collision energies\n",
    "    -does this relate in a predictable way to fragment mass\n",
    "\n",
    "-test sim metrics for same coll energy vs not same col energy (is the same inductive bias useful)\n",
    "\n",
    "-Show that regular funcs are in the space of combo distance\n",
    "\n",
    "-test combining individual metrics that use different components of the 2 vectors (add, mult, dif)\n",
    "\n",
    "-range over individual metrics in combined score in attempt to explain why combining them is successful\n",
    "\n",
    "-train combo metrics with flattened components and individual (should these sims be broken out?)\n",
    "    -should we do this for same coll energy vs dif energies\n",
    "\n",
    "-are different combo metrics put into larger model more successful than the combined individual metrics\n",
    "\n",
    "-can tunasims be fit with nonlinearities between the components (flattened or not?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
