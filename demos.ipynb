{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from importlib import reload\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "import copy\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as hgbc\n",
    "import pickle\n",
    "import warnings\n",
    "import math\n",
    "import copy\n",
    "import tests\n",
    "import figures\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import TunaSims\n",
    "import func_ob\n",
    "import tools\n",
    "import datasetBuilder\n",
    "import testUtils\n",
    "import spectral_similarity\n",
    "import itertools\n",
    "import reweightFuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nist14='/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist14_highres.pkl'\n",
    "nist20_prot = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist20_prot_fiehn_.pkl'\n",
    "nist20 = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist20.pkl'\n",
    "nist23_prot = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist23_prot_deprot_only.pkl'\n",
    "nist23='/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist23_full.pkl'\n",
    "gnps='/Users/jonahpoczobutt/projects/raw_data/db_csvs/gnps_highres.pkl'\n",
    "mona='/Users/jonahpoczobutt/projects/raw_data/db_csvs/mona_highres.pkl'\n",
    "metlin='/Users/jonahpoczobutt/projects/raw_data/db_csvs/metlin.pkl'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion Points\n",
    "\n",
    "Should we look at inchiKey for match rather than inchiCore\n",
    "\n",
    "does spectral entropy relate to precursor m/z - yes\n",
    "\n",
    "does spectral entropy relate to CE - yes\n",
    "\n",
    "does peak intensity relate to m/z - meh\n",
    "\n",
    "does peak intensity relate to CE\n",
    "\n",
    "What factors should play into reweighting\n",
    "\n",
    "    -for quality measure: precursor mz\n",
    "    -for reducing corr: fragment mz\n",
    "\n",
    "does having lower correlated similarity measures produce better results\n",
    "\n",
    "can we obtain lower correlation with the same cleaning procedure in order to be memory efficient (ie thru sim measures)\n",
    "\n",
    "Should we try sequential fitting on residuals?\n",
    "\n",
    "incorporate into model as feature the cleanliness of spectra by comparing the entropy of spectra from entire experiment vs their expectation from combined database. Higher entropy -> lower quality when adjusted properly. Inputs could be m/z as well as CE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all Necessary Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#databases\n",
    "outputs_path='/Users/jonahpoczobutt/projects/TunaRes/test'\n",
    "\n",
    "self_search=True\n",
    "query = nist20\n",
    "target = nist20\n",
    "\n",
    "if query == target:\n",
    "    self_search = True\n",
    "    \n",
    "fullRun=True\n",
    "if fullRun:\n",
    "    os.mkdir(outputs_path)\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/gbcIndices')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/train')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/val')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/test')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/port')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/datasets')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/train')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/val')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/test')\n",
    "    os.mkdir(f'{outputs_path}/gbc_res')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/train_to_func')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/train_to_error')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splt Queries into Train, Val, Test by Core or Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullRun=True\n",
    "match_category = 'inchi_base'\n",
    "if fullRun:\n",
    "\n",
    "    #This should be replaced with a function to read in all the databases\n",
    "    query_ = pd.read_pickle(query)\n",
    "\n",
    "    #jonah edit here\n",
    "    all_bases = list(set(query_[match_category]))\n",
    "\n",
    "    if self_search:\n",
    "        query_.insert(0,'queryID', [i for i in range(len(query_))])\n",
    "    else:\n",
    "        query_.insert(0,'queryID', [\"_\" for i in range(len(query_))])\n",
    "\n",
    "    #this method is in place\n",
    "    np.random.shuffle(all_bases)\n",
    "\n",
    "    first_bases = all_bases[:int(len(all_bases)*0.5)]\n",
    "    second_bases = all_bases[int(len(all_bases)*0.5):int(len(all_bases)*0.7)]\n",
    "    third_bases = all_bases[int(len(all_bases)*0.7):]\n",
    "\n",
    "    first_query_ = query_[np.isin(query_[match_category],first_bases)]\n",
    "    first_query_.reset_index(inplace=True)\n",
    "    first_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/first_query.pkl')\n",
    "    del(first_query_)\n",
    "\n",
    "    second_query_ = query_[np.isin(query_[match_category],second_bases)]\n",
    "    second_query_.reset_index(inplace=True)\n",
    "    second_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/second_query.pkl')\n",
    "    del(second_query_)\n",
    "\n",
    "    third_query_ = query_[np.isin(query_[match_category],third_bases)]\n",
    "    third_query_.reset_index(inplace=True)\n",
    "    third_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/third_query.pkl')\n",
    "    del(third_query_)\n",
    "    del(query_)\n",
    "\n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/first_bases.npy',first_bases)\n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/second_bases.npy',second_bases)\n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/third_bases.npy',third_bases)\n",
    "    del(first_bases)\n",
    "    del(second_bases)\n",
    "    del(third_bases)\n",
    "    del(all_bases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Parameters Here!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1e5\n",
    "adduct_match = False\n",
    "strong_self_separation = True\n",
    "\n",
    "num_chunks=int(1e6) #number of chunks to be combined for calculating correlations and collecting testable indices\n",
    "\n",
    "label_field = 'InchiCoreMatch' # should be either inchicore or inchi\n",
    "\n",
    "comparison_metrics = ['entropy',\n",
    "                'manhattan',\n",
    "                'lorentzian',\n",
    "                'dot_product',\n",
    "                'fidelity',\n",
    "                'matusita',\n",
    "                'chi2',\n",
    "                'laplacian',\n",
    "                'harmonic_mean',\n",
    "                'bhattacharya_2',\n",
    "                'squared_chord',\n",
    "                'cross_ent'\n",
    "                ]\n",
    "\n",
    "ppm_windows = [3]\n",
    "noise_threshes=[partial(reweightFuncs.noise_clip, perc_thresh = 0.0),\n",
    "                partial(reweightFuncs.noise_clip, perc_thresh = 0.05),\n",
    "                partial(reweightFuncs.noise_clip, fixed_thresh = 10)]\n",
    "\n",
    "noise_names = ['None','5%','10']\n",
    "centroid_tolerance_vals = [0.05,0.01]\n",
    "centroid_tolerance_types=['da','da']\n",
    "reweight_methods = [partial(reweightFuncs.logent,intercept = 0.25), reweightFuncs.weight_intensity_by_entropy, partial(reweightFuncs.fixed_power,power=1)]\n",
    "reweight_names = ['logent','fiehn','1']\n",
    "sim_methods=comparison_metrics\n",
    "prec_removes=[lambda x: x-1.6, lambda x: None]\n",
    "prec_remove_names = ['fiehn', 'none']\n",
    "train_size=3e6\n",
    "val_size=1e6\n",
    "test_size=2e6\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ppm_windows:\n",
    "    try:\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/train/{i}_ppm')\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/train/{i}_ppm')\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/val/{i}_ppm')\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/val/{i}_ppm')\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/test/{i}_ppm')\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/test/{i}_ppm')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#read in first bases and shuffle order\n",
    "query_ = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/first_query.pkl')\n",
    "query_ = query_.sample(frac=1)\n",
    " \n",
    "if self_search:\n",
    "\n",
    "    if strong_self_separation:\n",
    "        target_ = query_\n",
    "    else:\n",
    "        target_=pd.read_pickle(target)\n",
    "        target_.insert(0,'queryID', [i for i in range(len(target_))])\n",
    "\n",
    "else:\n",
    "    target_=pd.read_pickle(target)\n",
    "    target_.insert(0,'queryID', [\"*\" for i in range(len(target_))])\n",
    "    \n",
    "\n",
    "datasetBuilder.create_matches_and_model_data(query_,\n",
    "                              target_,\n",
    "                            matchesOutputPath = f'{outputs_path}/intermediateOutputs/splitMatches/train',\n",
    "                            modelDataOutputPath = f'{outputs_path}/intermediateOutputs/datasets/train',\n",
    "                            chunk_size = chunk_size,\n",
    "                            max_size = train_size,\n",
    "                            ppm_windows = ppm_windows,\n",
    "                            noise_threshes = noise_threshes,\n",
    "                            noise_names = noise_names,\n",
    "                            centroid_tolerance_vals = centroid_tolerance_vals,\n",
    "                            centroid_tolerance_types = centroid_tolerance_types,\n",
    "                            reweight_methods = reweight_methods,\n",
    "                            reweight_names = reweight_names,\n",
    "                            sim_methods = comparison_metrics,\n",
    "                            prec_removes = prec_removes,\n",
    "                            prec_remove_names = prec_remove_names\n",
    "                            )\n",
    "\n",
    "del(query_)\n",
    "del(target_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual Scores Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hit_sanity_check = True\n",
    "if top_hit_sanity_check:\n",
    "\n",
    "    for window in ppm_windows:\n",
    "        try:\n",
    "            os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/checks')\n",
    "            os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/checks/{window}_ppm')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        tests.create_variable_comparisons_chunk(\n",
    "                                        noise_threshes = [lambda x: x * 0.01], \n",
    "                                        centroid_threshes = [0.05],\n",
    "                                        centroid_types = ['da'],\n",
    "                                        reweight_names = ['fiehn','none'], \n",
    "                                        reweight_funcs = [reweightFuncs.weight_intensity_by_entropy, partial(reweightFuncs.fixed_power,power=1)], \n",
    "                                        sim_methods = ['entropy','dot_product','cross_ent'], \n",
    "                                        prec_funcs = [lambda x: x-1.6],\n",
    "                                        prec_names = ['fiehn'],\n",
    "                                        matches_folder = f'{outputs_path}/intermediateOutputs/splitMatches/train/{window}_ppm', \n",
    "                                        top_hit_only = True,  \n",
    "                                        match_field = 'InchiCoreMatch',\n",
    "                                        outpath = f'{outputs_path}/intermediateOutputs/datasets/checks/{window}_ppm/res.csv',\n",
    "                                        logpath = f'{outputs_path}/intermediateOutputs/datasets/checks/{window}_ppm/log.txt'\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "sim_indices = datasetBuilder.generate_keep_indices(noise_threshes=[True for i in range(len(noise_threshes))],\n",
    "                                                centroid_tolerance_vals = [True for i in range(len(centroid_tolerance_vals))],\n",
    "                                                reweight_methods = [True for i in range(len(reweight_methods))],\n",
    "                                                sim_methods = [True for i in range(len(sim_methods))],\n",
    "                                                prec_removes = [True for i in range(len(prec_removes))],\n",
    "                                                spec_features=[False for i in range(6)])\n",
    "for window in ppm_windows:\n",
    "\n",
    "    chunks=list()\n",
    "    #catch case where we run out of chunks to combine\n",
    "    labels = list()\n",
    "    for j in range(num_chunks):\n",
    "        try:\n",
    "            chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/train/{window}_ppm/chunk_{j+1}.pkl')\n",
    "            labels = labels + chunk[label_field].tolist()\n",
    "            chunk = chunk.iloc[:,sim_indices]\n",
    "            chunks.append(chunk)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    print('created train')\n",
    "    train = pd.concat(chunks)\n",
    "    del(chunk)\n",
    "    del(chunks)\n",
    "\n",
    "individual_scores = list()\n",
    "for i in range(train.shape[1]):\n",
    "    individual_scores.append(auc(labels, train.iloc[:,i].tolist()))\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "\n",
    "individual_results = pd.DataFrame(train.columns, individual_scores)\n",
    "individual_results.reset_index(inplace=True, drop=False)\n",
    "individual_results.columns = ['auc','name']\n",
    "individual_results.sort_values(by='auc', inplace=True)\n",
    "\n",
    "individual_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all Val Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = False\n",
    "if val:\n",
    "    #read in second bases and shuffle order\n",
    "    query_ = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/second_query.pkl')\n",
    "    query_ = query_.sample(frac=1)\n",
    "\n",
    "    if self_search:\n",
    "\n",
    "        if strong_self_separation:\n",
    "            target_ = query_\n",
    "        else:\n",
    "            target_=pd.read_pickle(target)\n",
    "            target_.insert(0,'queryID', [i for i in range(len(target_))])\n",
    "\n",
    "    else:\n",
    "        target_=pd.read_pickle(target)\n",
    "        target_.insert(0,'queryID', [\"*\" for i in range(len(target_))])\n",
    "\n",
    "    datasetBuilder.create_matches_and_model_data(query_,\n",
    "                                target_,\n",
    "                                matchesOutputPath = f'{outputs_path}/intermediateOutputs/splitMatches/val',\n",
    "                                modelDataOutputPath = f'{outputs_path}/intermediateOutputs/datasets/val',\n",
    "                                chunk_size = chunk_size,\n",
    "                                max_size = val_size,\n",
    "                                ppm_windows = ppm_windows,\n",
    "                                noise_threshes = noise_threshes,\n",
    "                                noise_names = noise_names,\n",
    "                                centroid_tolerance_vals = centroid_tolerance_vals,\n",
    "                                centroid_tolerance_types = centroid_tolerance_types,\n",
    "                                reweight_methods = reweight_methods,\n",
    "                                reweight_names = reweight_names,\n",
    "                                sim_methods = comparison_metrics,\n",
    "                                prec_removes = prec_removes,\n",
    "                                prec_remove_names = prec_remove_names\n",
    "                                )\n",
    "\n",
    "    del(query_)\n",
    "    del(target_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in second bases and shuffle order\n",
    "query_ = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/third_query.pkl')\n",
    "query_ = query_.sample(frac=1)\n",
    "\n",
    "if self_search:\n",
    "\n",
    "    if strong_self_separation:\n",
    "        target_ = query_\n",
    "    else:\n",
    "        target_=pd.read_pickle(target)\n",
    "        target_.insert(0,'queryID', [i for i in range(len(target_))])\n",
    "\n",
    "else:\n",
    "    target_=pd.read_pickle(target)\n",
    "    target_.insert(0,'queryID', [\"*\" for i in range(len(target_))])\n",
    "\n",
    "datasetBuilder.create_matches_and_model_data(query_,\n",
    "                              target_,\n",
    "                            matchesOutputPath = f'{outputs_path}/intermediateOutputs/splitMatches/test',\n",
    "                            modelDataOutputPath = f'{outputs_path}/intermediateOutputs/datasets/test',\n",
    "                            chunk_size = chunk_size,\n",
    "                            max_size = test_size,\n",
    "                            ppm_windows = ppm_windows,\n",
    "                            noise_threshes = noise_threshes,\n",
    "                            noise_names = noise_names,\n",
    "                            centroid_tolerance_vals = centroid_tolerance_vals,\n",
    "                            centroid_tolerance_types = centroid_tolerance_types,\n",
    "                            reweight_methods = reweight_methods,\n",
    "                            reweight_names = reweight_names,\n",
    "                            sim_methods = comparison_metrics,\n",
    "                            prec_removes = prec_removes,\n",
    "                            prec_remove_names = prec_remove_names\n",
    "                            )\n",
    "\n",
    "del(query_)\n",
    "del(target_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create indices to pull for interesting metric combos, instantiate GBC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_indices = datasetBuilder.generate_keep_indices(noise_threshes=[True for i in range(len(noise_threshes))],\n",
    "                                                centroid_tolerance_vals = [True for i in range(len(centroid_tolerance_vals))],\n",
    "                                                reweight_methods = [True for i in range(len(reweight_methods))],\n",
    "                                                sim_methods = [True for i in range(len(sim_methods))],\n",
    "                                                prec_removes = [True for i in range(len(prec_removes))],\n",
    "                                                spec_features=[False for i in range(6)])\n",
    "\n",
    "\n",
    "#get n unique pairs and unique triplets by metric\n",
    "lim_pairs = 10\n",
    "unique_pairs = list()\n",
    "indices_array = list(range(len(comparison_metrics)))\n",
    "np.random.shuffle(indices_array)\n",
    "for j in indices_array:\n",
    "    for k in range(len(comparison_metrics)):\n",
    "\n",
    "        if j>k:\n",
    "            unique_pairs.append([j,k])\n",
    "            lim_pairs -= 1\n",
    "\n",
    "            if lim_pairs == 0:\n",
    "                break\n",
    "\n",
    "    if lim_pairs == 0:\n",
    "        break\n",
    "\n",
    "lim_trips = 10\n",
    "np.random.shuffle(indices_array)\n",
    "unique_triplets = list()\n",
    "for j in indices_array:\n",
    "    for k in unique_pairs:\n",
    "\n",
    "        if j not in k:\n",
    "            unique_triplets.append([j]+k)   \n",
    "            lim_trips -= 1\n",
    "\n",
    "            if lim_trips == 0:\n",
    "                break\n",
    "\n",
    "    if lim_trips == 0:\n",
    "        break             \n",
    "\n",
    "for i in ppm_windows:\n",
    "\n",
    "    chunks=list()\n",
    "    #catch case where we run out of chunks to combine\n",
    "    for j in range(num_chunks):\n",
    "        try:\n",
    "            chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/train/{i}_ppm/chunk_{j+1}.pkl')\n",
    "            chunk = chunk.iloc[:,sim_indices]\n",
    "            chunks.append(chunk)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    train = pd.concat(chunks)\n",
    "    del(chunk)\n",
    "    del(chunks)\n",
    "\n",
    "    train = train.corr()\n",
    "    train.to_csv(f'{outputs_path}/intermediateOutputs/datasets/train/{i}_ppm/corrs.csv')\n",
    "\n",
    "    models = [\n",
    "            hgbc(),\n",
    "            # hgbc(learning_rate=0.5),\n",
    "            # hgbc(max_iter=200),\n",
    "            # hgbc(learning_rate=0.01,min_samples_leaf=10),\n",
    "            # hgbc(max_iter=200,min_samples_leaf=10),\n",
    "            # hgbc(learning_rate=0.5, max_iter=200,min_samples_leaf=10),\n",
    "            ]\n",
    "    \n",
    "    num_condition = 10\n",
    "    num_control = 10\n",
    "\n",
    "    indices = dict()\n",
    "    corrs = dict()\n",
    "    indices['all-sims'] = list(range(train.shape[1]-1))\n",
    "\n",
    "    low_corr_3, rand_corr_3 = testUtils.get_least_corr_and_control(train,\n",
    "                                                                   3, \n",
    "                                                                   num_condition = num_condition,\n",
    "                                                                   num_control = num_control)\n",
    "    \n",
    "    for _ in range(num_condition):\n",
    "        indices[f'low-corr-3-all_{_}'] = low_corr_3[0][_]\n",
    "        corrs[f'low-corr-3-all_{_}'] = low_corr_3[1][_]\n",
    "    for _ in range(num_control):\n",
    "        indices[f'rand-3-all_{_}'] = rand_corr_3[0][_]\n",
    "        corrs[f'rand-3-all_{_}'] = rand_corr_3[1][_]\n",
    "    print('generated 3')\n",
    "\n",
    "    low_corr_5, rand_corr_5 = testUtils.get_least_corr_and_control(train,\n",
    "                                                                   5, \n",
    "                                                                   num_condition = num_condition,\n",
    "                                                                   num_control = num_control)\n",
    "    \n",
    "    for _ in range(num_condition):\n",
    "        indices[f'low-corr-5-all_{_}'] = low_corr_5[0][_]\n",
    "        corrs[f'low-corr-5-all_{_}'] = low_corr_5[1][_]\n",
    "    for _ in range(num_control):\n",
    "        indices[f'rand-5-all_{_}'] = rand_corr_5[0][_]\n",
    "        corrs[f'rand-5-all_{_}'] = rand_corr_5[1][_]\n",
    "    print('generated 5')\n",
    "\n",
    "    low_corr_10, rand_corr_10 = testUtils.get_least_corr_and_control(train,\n",
    "                                                                   10, \n",
    "                                                                   num_condition = num_condition,\n",
    "                                                                   num_control = num_control)\n",
    "    \n",
    "    for _ in range(num_condition):\n",
    "        indices[f'low-corr-10-all_{_}'] = low_corr_10[0][_]\n",
    "        corrs[f'low-corr-10-all_{_}'] = low_corr_10[1][_]\n",
    "    for _ in range(num_control):\n",
    "        indices[f'rand-10-all_{_}'] = rand_corr_10[0][_]\n",
    "        corrs[f'rand-10-all_{_}'] = rand_corr_10[1][_]\n",
    "    print('generated 10')\n",
    "\n",
    "    low_corr_15, rand_corr_15 = testUtils.get_least_corr_and_control(train,\n",
    "                                                                   15, \n",
    "                                                                   num_condition = num_condition,\n",
    "                                                                   num_control = num_control)\n",
    "    \n",
    "    for _ in range(num_condition):\n",
    "        indices[f'low-corr-15-all_{_}'] = low_corr_15[0][_]\n",
    "        corrs[f'low-corr-15-all_{_}'] = low_corr_15[1][_]\n",
    "    for _ in range(num_control):\n",
    "        indices[f'rand-15-all_{_}'] = rand_corr_15[0][_]\n",
    "        corrs[f'rand-15-all_{_}'] = rand_corr_15[1][_]\n",
    "    print('generated 15')\n",
    "\n",
    "    low_corr_20, rand_corr_20 = testUtils.get_least_corr_and_control(train,\n",
    "                                                                   20, \n",
    "                                                                   num_condition = num_condition,\n",
    "                                                                   num_control = num_control)\n",
    "    for _ in range(num_condition):\n",
    "        indices[f'low-corr-20-all_{_}'] = low_corr_20[0][_]\n",
    "        corrs[f'low-corr-20-all_{_}'] = low_corr_20[1][_]\n",
    "    for _ in range(num_control):\n",
    "        indices[f'rand-20-all_{_}'] = rand_corr_20[0][_]\n",
    "        corrs[f'rand-20-all_{_}'] = rand_corr_20[1][_]\n",
    "    print('generated 20')\n",
    "\n",
    "    num_condition = 3\n",
    "    num_control = 3\n",
    "    for i in range(int((train.shape[1])/len(comparison_metrics))):\n",
    "\n",
    "        low_corr_3,rand_corr_3 = testUtils.get_least_corr_and_control(train.iloc[i*len(comparison_metrics):(i+1)*len(comparison_metrics),i*len(comparison_metrics):(i+1)*len(comparison_metrics)],3, num_condition=num_condition, num_control=num_control)\n",
    "        for _ in range(num_condition):\n",
    "            indices[f'low-corr-3-{i}_{_}'] = low_corr_3[0][_]+(i*len(comparison_metrics))\n",
    "            corrs[f'low-corr-3-{i}_{_}'] = low_corr_3[1][_]+(i*len(comparison_metrics))\n",
    "        for _ in range(num_control):\n",
    "            indices[f'rand-3-{i}_{_}'] = rand_corr_3[0][_]+(i*len(comparison_metrics))\n",
    "            corrs[f'rand-3-{i}_{_}'] = rand_corr_3[1][_]+(i*len(comparison_metrics))\n",
    "\n",
    "        low_corr_5,rand_corr_5= testUtils.get_least_corr_and_control(train.iloc[i*len(comparison_metrics):(i+1)*len(comparison_metrics),i*len(comparison_metrics):(i+1)*len(comparison_metrics)],5, num_condition=num_condition, num_control=num_control)\n",
    "        \n",
    "        for _ in range(num_condition):\n",
    "            indices[f'low-corr-5-{i}_{_}'] = low_corr_5[0][_]+(i*len(comparison_metrics))\n",
    "            corrs[f'low-corr-5-{i}_{_}'] = low_corr_5[1][_]+(i*len(comparison_metrics))\n",
    "        for _ in range(num_control):\n",
    "            indices[f'rand-5-{i}_{_}'] = rand_corr_5[0][_]+(i*len(comparison_metrics))\n",
    "            corrs[f'rand-5-{i}_{_}'] = rand_corr_5[1][_]+(i*len(comparison_metrics))\n",
    "\n",
    "        for _ in range(len(unique_pairs)):\n",
    "            indices[f'pair_{i}_{_}'] = np.array(unique_pairs[_])+(i*len(comparison_metrics))\n",
    "\n",
    "        for _ in range(len(unique_triplets)):\n",
    "            indices[f'triplet_{i}_{_}'] = np.array(unique_triplets[_])+(i*len(comparison_metrics))\n",
    "\n",
    "    print('finished creating indices')\n",
    "    \n",
    "    #now populate correlation dictionary with anything we don't already have\n",
    "    corr_matrix = train.corr()\n",
    "    for key, value in indices.items():\n",
    "\n",
    "        if key not in corrs:\n",
    "            \n",
    "            corr = 0\n",
    "            for i in value:\n",
    "                for j in value:\n",
    "\n",
    "                    if i>j:\n",
    "                        corr += corr_matrix.iloc[i,j]/math.comb(len(value),2)\n",
    "\n",
    "            corrs[key] = corr\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/gbcIndices/custom_indices_{ppm_windows[0]}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "        pickle.dump(indices,handle)\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/gbcIndices/mean_correlations_{ppm_windows[0]}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "        pickle.dump(corrs,handle)\n",
    "\n",
    "    print(f' total number of models: {len(models) * len(indices)}')\n",
    "    del(indices)\n",
    "    del(corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train all models, collecting input aucs, their correlations, and their train,val,test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(testUtils)\n",
    "with open(f'{outputs_path}/intermediateOutputs/gbcIndices/custom_indices_{ppm_windows[0]}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "       indices = pickle.load(handle)\n",
    "   \n",
    "for window in ppm_windows:\n",
    "\n",
    "    chunks=list()\n",
    "    #catch case where we run out of chunks to combine\n",
    "    labels = list()\n",
    "    for j in range(num_chunks):\n",
    "        try:\n",
    "            chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/train/{window}_ppm/chunk_{j+1}.pkl')\n",
    "            labels = labels + chunk[label_field].tolist()\n",
    "            chunk = chunk.iloc[:,sim_indices]\n",
    "            chunks.append(chunk)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    print('created train')\n",
    "    train = pd.concat(chunks)\n",
    "    train['match'] = labels\n",
    "    del(chunk)\n",
    "    del(chunks)\n",
    "    \n",
    "    logpath = f'{outputs_path}/gbc_res/trainlog.txt'\n",
    "    trained_models = testUtils.train_and_name_models(train, models, indices, logpath = logpath)\n",
    "    names = sorted(list(trained_models.keys()))\n",
    "    logpath = f'{outputs_path}/gbc_res/evallog.txt'\n",
    "    train_aucs = testUtils.evaluate_models_by_subset(trained_models, indices, train, logpath = logpath)\n",
    "    del(train)\n",
    "\n",
    "    print('finished train')\n",
    "\n",
    "    # chunks=list()\n",
    "    # #catch case where we run out of chunks to combine\n",
    "    # labels = list()\n",
    "    # for j in range(num_chunks):\n",
    "    #     try:\n",
    "    #         chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/val/{window}_ppm/chunk_{j+1}.pkl')\n",
    "    #         labels = labels + chunk[label_field].tolist()\n",
    "    #         chunk = chunk.iloc[:,sim_indices]\n",
    "    #         chunks.append(chunk)\n",
    "    #     except:\n",
    "    #         break\n",
    "\n",
    "    # val = pd.concat(chunks)\n",
    "    # val['match'] = labels\n",
    "    # del(chunk)\n",
    "    # del(chunks)\n",
    "\n",
    "    # val_aucs = testUtils.evaluate_models_by_subset(trained_models, indices, val, logpath = logpath)\n",
    "    # del(val)\n",
    "\n",
    "    print('finished val')\n",
    "\n",
    "    chunks=list()\n",
    "    #catch case where we run out of chunks to combine\n",
    "    labels = list()\n",
    "    for j in range(num_chunks):\n",
    "        try:\n",
    "            chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/test/{window}_ppm/chunk_{j+1}.pkl')\n",
    "            labels = labels + chunk[label_field].tolist()\n",
    "            chunk = chunk.iloc[:,sim_indices]\n",
    "            chunks.append(chunk)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    test = pd.concat(chunks)\n",
    "    test['match'] = labels\n",
    "    del(chunk)\n",
    "    del(chunks)\n",
    "\n",
    "    test_aucs = testUtils.evaluate_models_by_subset(trained_models, indices, test, logpath = logpath)\n",
    "    del(test)\n",
    "\n",
    "    print('finished test')\n",
    "\n",
    "    model_aucs = pd.DataFrame([names, train_aucs, test_aucs]).transpose()\n",
    "    model_aucs.columns=['name','train','test']\n",
    "\n",
    "    model_aucs.to_csv(f'{outputs_path}/gbc_res/model_aucs_{window}_ppm.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recreate training data\n",
    "for window in ppm_windows:\n",
    "\n",
    "    chunks=list()\n",
    "    #catch case where we run out of chunks to combine\n",
    "    labels = list()\n",
    "    for j in range(num_chunks):\n",
    "        try:\n",
    "            chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/train/{window}_ppm/chunk_{j+1}.pkl')\n",
    "            labels = labels + chunk[label_field].tolist()\n",
    "            chunk = chunk.iloc[:,sim_indices]\n",
    "            chunks.append(chunk)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    train = pd.concat(chunks)\n",
    "    del(chunk)\n",
    "    del(chunks)\n",
    "\n",
    "    #create df for correlation and aucs on training data\n",
    "\n",
    "    individual_aucs = np.zeros(len(train.columns))\n",
    "\n",
    "    for i in range(train.shape[1]):\n",
    "\n",
    "        individual_aucs[i] = auc(labels, train.iloc[:,i].to_numpy())\n",
    "\n",
    "    train = pd.read_csv(f'{outputs_path}/intermediateOutputs/datasets/train/{window}_ppm/corrs.csv')\n",
    "\n",
    "    max_aucs, mean_aucs = testUtils.auc_data(model_aucs['name'].tolist(), indices, individual_aucs)\n",
    "    min_corrs, mean_corrs = testUtils.corr_data(model_aucs['name'].tolist(), indices, train)\n",
    "\n",
    "    num_features=list()\n",
    "    for name in model_aucs['name'].tolist():\n",
    "\n",
    "        num_features.append(len(indices[name]))\n",
    "\n",
    "    feature_attributes = pd.DataFrame([model_aucs['name'].tolist(), max_aucs, mean_aucs, min_corrs, mean_corrs, num_features]).transpose()\n",
    "    feature_attributes.columns = ['name', 'max_auc', 'mean_auc', 'min_corr', 'mean_corr', 'num_features']\n",
    "    feature_attributes.to_csv(f'{outputs_path}/gbc_res/feature_attributes_{window}_ppm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Linear Models of Performance by Feature Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all Models, Generate Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No regularization\n",
    "figures.performace_attribution(model_aucs, feature_attributes, [['_']], ['all'], model = lr())\n",
    "\n",
    "#regularization\n",
    "figures.performace_attribution(model_aucs, feature_attributes, [['_']], ['all'], model = lr(C=0.5, penalty = 'l2'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance as we vary the number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures.performace_attribution(model_aucs, feature_attributes, [['all']], ['all'], feature_indices = [5], model = lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['max_auc'], dtype='object')\n",
      "yool\n",
      "\n",
      "max_auc: 10.0\n",
      "\n",
      "Index(['max_auc'], dtype='object')\n",
      "bool\n",
      "\n",
      "max_auc: 5.0\n",
      "\n",
      "max_auc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonah\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonah\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature_attributes.columns = ['name', 'max_auc', 'mean_auc', 'min_corr', 'mean_corr', 'num_features']\n",
    "figures.performance_attribution(test_aucs, test_attributes,[['yool'],['yarl']],['yool','bool'],feature_indices=[0], model = lr(), figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_auc</th>\n",
       "      <th>mean_auc</th>\n",
       "      <th>min_corr</th>\n",
       "      <th>mean_corr</th>\n",
       "      <th>num_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_auc  mean_auc  min_corr  mean_corr  num_features\n",
       "0     0.50      0.49      0.80       0.90             2\n",
       "1     0.51      0.40      0.85       0.92             2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Functions to original metrics, evaluate how far off we are on test data with original normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inits = {'a' : 1,\n",
    "        'b': 1,\n",
    "        'c' : 1,\n",
    "        'd' : -1,\n",
    "        'e' : 1,\n",
    "        'f' : 1,\n",
    "        'g' :1,\n",
    "        'h' :0,\n",
    "        'i' : -1,\n",
    "        'j' :1,\n",
    "        'k' : 1,\n",
    "        'l' : 1,\n",
    "        'm' : 1,\n",
    "        'n' : -1,\n",
    "        'o' : 1,\n",
    "        'p' : 1,\n",
    "        'q' : 1,\n",
    "        'r' : 0,\n",
    "        's' : 1,\n",
    "        't' : -1,\n",
    "        'u' : 1,\n",
    "        'v' : -1,\n",
    "        'w' : 1,\n",
    "        'x' : 1,\n",
    "        'y' : 1,\n",
    "        'z' : 1,\n",
    "        'a_' : 1,\n",
    "        'b_' : -1,\n",
    "        'c_' : 1,\n",
    "        'd_' : -1,\n",
    "        'e_' : 1,\n",
    "        'f_' : 1,\n",
    "        'g_' : 1,\n",
    "        'h_' : 1,\n",
    "        'i_' : 1,\n",
    "        'j_' : -1,\n",
    "        'k_' : 1,\n",
    "        'l_': -1,\n",
    "        'm_' : 1,\n",
    "        'n_' : 1,\n",
    "        'o_' : 1,\n",
    "        'p_' : 1,\n",
    "        'q_' : -1,\n",
    "        'r_' : 1,\n",
    "        's_' : -1,\n",
    "        't_' : 1,\n",
    "        'u_' : 1,\n",
    "        'v_' : 1,\n",
    "        'w_' : -1,\n",
    "        'x_' : 1,\n",
    "        'y_' : -1,\n",
    "        'z_':1}\n",
    "\n",
    "\n",
    "fit_funcs = {\n",
    "    'entropy-1':(['f','g','i','n_','p_'],None),\n",
    "    'entropy-2':(['f','g','h','i','j','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'entropy-3':(['f','g','h','i','j','n_','o_','p_','q_','r_','s_','b','l','x','y','z','a_','b_','c_','d_','e_'],None),\n",
    "    'lorentzian-1':(['a','b'],None),\n",
    "    'lorentzian-2':(['a','b','c','d','e'],None),\n",
    "    'lorentzian-3':(['a','b','c','d','e','f','g','h','i','j','k','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'dot_product-1':(['k','l','t_','u_'],None),\n",
    "    'dot_product-2':(['k','l','m','n','o','t_','u_','v_','w_','x_','y_'],None),\n",
    "    'dot_product-3':(['k','l','m','n','o','t_','u_','v_','w_','x_','y_','k','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'harmonic_mean-1':(['x','y','z','a_','b_','c_'],None),\n",
    "    'harmonic_mean-2':(['b','l','x','y','z','a_','b_','c_','d_','e_','b','l'],None),\n",
    "    'harmonic_mean-3':(['b','l','x','y','z','a_','b_','c_','d_','e_','b','l','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'fidelity-1':(['k','l','m'],None),\n",
    "    'fidelity-2':(['k','l','m','n','o',],None),\n",
    "    'fidelity-3':(['k','l','m','n','o','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'squared_chord-1':(['a','b'],None),\n",
    "    'squared_chord-2':(['a','b','c','d','e'],None),\n",
    "    'squared_chord-3':(['a','b','c','d','e','f','g','h','i','j','k','n_','o_','p_','q_','r_','s_'],None),\n",
    "    'bhattacharya_1-1':(['a','b'],None),\n",
    "    'bhattacharya_1-2':(['a','b','c','d','e'],None),\n",
    "    'bhattacharya_1-3':(['a','b','c','d','e','f','g','h','i','j','k','n_','o_','p_','q_','r_','s_'],None),\n",
    "}\n",
    "\n",
    "reload(testUtils)\n",
    "reload(func_ob)\n",
    "reload(TunaSims)\n",
    "\n",
    "train_reses = list()\n",
    "test_reses = list()\n",
    "for i in ppm_windows:\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/datasets/train_unnorm_dist_{i}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "        train_labels = pickle.load(handle)\n",
    "\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_dif_ce_{i}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "        train_specs = pickle.load(handle)\n",
    "\n",
    "    #just focus on first setting for now\n",
    "    train_labels = train_labels.iloc[:,:len(comparison_metrics)]\n",
    "    train_specs = train_specs.iloc[:,[0,1,2,-2]]\n",
    "    train_specs.columns=['mzs','query','target','precursor']\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/datasets/test_unnorm_dist_{i}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "        test_labels = pickle.load(handle)\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/splitMatches/test_cleaned_matches_dif_ce_{i}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "        test_specs = pickle.load(handle)\n",
    "\n",
    "    test_labels = test_labels.iloc[:,:len(comparison_metrics)]\n",
    "    test_specs = test_specs.iloc[:,[0,1,2,-2]]\n",
    "    test_specs.columns=['mzs','query','target','precursor']\n",
    "\n",
    "    squared_loss = lambda x: (x)**2\n",
    "    lin_loss = lambda x: np.abs(x)\n",
    "    l1_reg = lambda l,x: l*np.sum(np.abs(x))\n",
    "    l2_reg = lambda l,x: l*np.sqrt(np.sum(x**2))\n",
    "    no_reg = lambda x: 0\n",
    "\n",
    "    reg_funcs = [no_reg,partial(l2_reg,0.01),partial(l1_reg,0.01)]\n",
    "    reg_names = ['none','l2_0.01','l1_0.01']\n",
    "    losses = [squared_loss]\n",
    "    loss_names = ['squared']\n",
    "    momentums = ['none','simple']\n",
    "    mom_weights = [[0.2,0.8]]\n",
    "    lambdas = [0.01,0.001]\n",
    "    max_iters = [1e5]\n",
    "\n",
    "    funcs = testUtils.create_all_funcs_stoch(reg_funcs=reg_funcs,\n",
    "                                        reg_names=reg_names,\n",
    "                                        losses=losses,\n",
    "                                        loss_names=loss_names,\n",
    "                                        momentums=momentums,\n",
    "                                        inits = inits,\n",
    "                                        params=fit_funcs,\n",
    "                                        mom_weights=mom_weights,\n",
    "                                        lambdas=lambdas,\n",
    "                                        max_iters=max_iters,\n",
    "                                        func = TunaSims.tuna_combo_distance_demo)\n",
    "    \n",
    "    print(f'total number of functions : {len(funcs)}')\n",
    "    trained=list()\n",
    "    for func in funcs:\n",
    "\n",
    "        name = func.name.split('-')[0]\n",
    "        train_specs['match'] = train_labels[name]\n",
    "\n",
    "        func.fit(train_specs)\n",
    "        trained.append(func)\n",
    "        print(func.name)\n",
    "\n",
    "    #get train and test errors under proper normalization protocol\n",
    "    trained_res=list()\n",
    "    test_res=list()\n",
    "    names=list()\n",
    "reload(testUtils)\n",
    "for i in ppm_windows:\n",
    "    for func in trained:\n",
    "\n",
    "        #generate proper train and test datasets\n",
    "        name = func.name.split('-')[0]\n",
    "        train_specs['match'] = train_labels[name]\n",
    "        test_specs['match'] = test_labels[name]\n",
    "\n",
    "        #get trained_func\n",
    "        pred_func = func.trained_func()\n",
    "\n",
    "        trained_res.append(testUtils.get_func_dist(train_specs, pred_func, name))\n",
    "        test_res.append(testUtils.get_func_dist(test_specs, pred_func, name))\n",
    "        names.append(f'{name}_{func.regularization_name}_{func.momentum_type}_{func.momentum_weights}')\n",
    "        print(f'{name}_{func.regularization_name}_{func.momentum_type}_{func.momentum_weights}')\n",
    "        \n",
    "\n",
    "    trained_res = pd.DataFrame(trained_res).transpose()\n",
    "    trained_res.columns  = names\n",
    "\n",
    "    test_res = pd.DataFrame(test_res).transpose()\n",
    "    test_res.columns  = names\n",
    "\n",
    "    train_reses.append(trained_res)\n",
    "    test_reses.append(test_res)\n",
    "\n",
    "with open(f'{outputs_path}/intermediateOutputs/train_to_func/trained_reses_{i}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "    pickle.dump(train_reses, handle)\n",
    "\n",
    "with open(f'{outputs_path}/intermediateOutputs/train_to_func/test_reses_{i}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "    pickle.dump(test_reses, handle)\n",
    "\n",
    "del(train_reses)\n",
    "del(test_reses)\n",
    "del(train_labels)\n",
    "del(test_labels)\n",
    "del(train_specs)\n",
    "del(test_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{outputs_path}/intermediateOutputs/datasets/train_unnorm_dist_3_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "    train_labels = pickle.load(handle)\n",
    "\n",
    "with open(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_dif_ce_3_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "    train_specs = pickle.load(handle)\n",
    "\n",
    "comparison_metrics = ['entropy',\n",
    "                'manhattan',\n",
    "                'lorentzian',\n",
    "                'dot_product',\n",
    "                'fidelity',\n",
    "                'matusita',\n",
    "                'chi2',\n",
    "                'laplacian',\n",
    "                'harmonic_mean',\n",
    "                'bhattacharya_1',\n",
    "                'squared_chord',\n",
    "                'cross_ent']\n",
    "\n",
    "#just focus on first setting for now\n",
    "train_labels = train_labels.iloc[:,:len(comparison_metrics)]\n",
    "train_specs = train_specs.iloc[:,[0,1,2,-2]]\n",
    "train_specs.columns=['mzs','query','target','precursor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Distance Functions by Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadk = False\n",
    "if quadk:\n",
    "    flats = {\n",
    "            'fdif_quadk':(['a','b','c','d','e'],None),\n",
    "            'fadd_quadk':(['f','g','h','i','j'],None),\n",
    "            'fmult_quadk':(['k','l','m','n','o'],None),\n",
    "    }\n",
    "\n",
    "    exts = {'edif_add':(['b','g','p','q','r','s','t','u','v','w'],None),\n",
    "            'edif_mult':(['b','l','x','y','z','a_','b_','c_','d_','e_'],None),\n",
    "            'emult_add':(['l','g','f_','g_','h_','i_','j_','k_','l_','m_'],None),      \n",
    "    }\n",
    "\n",
    "    params = dict()\n",
    "    seen =set()\n",
    "    for key in flats.keys():\n",
    "        for key_ in flats.keys():\n",
    "\n",
    "            feature_type = key.split('_')[0]\n",
    "            feature_type_ = key_.split('_')[0]\n",
    "\n",
    "            func_type = key.split('_')[1]\n",
    "            func_type_ = key_.split('_')[1]\n",
    "\n",
    "            try:\n",
    "                bounds_type = key.split('_')[2]\n",
    "                bounds_type_ = key_.split('_')[2]\n",
    "            except:\n",
    "                bounds_type = ''\n",
    "                bounds_type_ = ''\n",
    "\n",
    "            if f'{key_}_{key}' in params.keys():\n",
    "                continue\n",
    "            params[f'{key}_{key_}']=(sorted(list(set(flats[key][0]+flats[key_][0]))),testUtils.dict_combine(flats[key][1],flats[key_][1]))\n",
    "            \n",
    "    params_ = dict()\n",
    "    seen =set()\n",
    "    for key in exts.keys():\n",
    "        for key_ in exts.keys():\n",
    "\n",
    "            feature_type = key.split('_')[0]\n",
    "            feature_type_ = key_.split('_')[0]\n",
    "\n",
    "            func_type = key.split('_')[1]\n",
    "            func_type_ = key_.split('_')[1]\n",
    "\n",
    "            try:\n",
    "                bounds_type = key.split('_')[2]\n",
    "                bounds_type_ = key_.split('_')[2]\n",
    "            except:\n",
    "                bounds_type = ''\n",
    "                bounds_type_ = ''\n",
    "\n",
    "            if f'{key_}_{key}' in params_.keys():\n",
    "                continue\n",
    "            params_[f'{key}_{key_}']=(sorted(list(set(exts[key][0]+exts[key_][0]))),testUtils.dict_combine(exts[key][1],exts[key_][1]))\n",
    "\n",
    "    params.update(params_)   \n",
    "\n",
    "    params['all_flat_quadk']= (['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o'],None)\n",
    "    params['all_ext_quadk'] = (['b','l','g','p','q','r','s','t','u','v','w','x','y','z','a_','b_','c_','d_','e_','f_','g_','h_','i_','j_','k_','l_','m_','t_','u_','v_','w_','x_','y_'],None)\n",
    "\n",
    "    for key in list(params_.keys())[:5]:\n",
    "        params[f'{key}_normed_add']=(sorted(list(set(params_[key][0]+['n_','o_','p_','q_','r_','s_']))),testUtils.dict_combine(params_[key][1],None))\n",
    "        params[f'{key}_normed_mult']=(sorted(list(set(params_[key][0]+['t_','u_','v_','w_','x_','y_']))),testUtils.dict_combine(params_[key][1],None))\n",
    "\n",
    "    params['norm_only_add']=(['n_','o_','p_','q_','r_','s_'],None)\n",
    "    params['norm_only_mult']=(['t_','u_','v_','w_','x_','y_'],None)\n",
    "\n",
    "quad=True\n",
    "if quad:\n",
    "    flats = {\n",
    "            'fdif_quad':(['a','b','c'],None),\n",
    "            'fadd_quad':(['f','g','h'],None),\n",
    "            'fmult_quad':(['k','l','m'],None),\n",
    "    }\n",
    "\n",
    "    exts = {'edif_add_quad':(['b','g','p','q','r','s','t','u'],None),\n",
    "            'edif_mult_quad':(['b','l','x','y','z','a_','b_','c_'],None),\n",
    "            'emult_add_quad':(['l','g','f_','g_','h_','i_','j_','k_'],None),      \n",
    "    }\n",
    "\n",
    "    params2 = dict()\n",
    "    seen =set()\n",
    "    for key in flats.keys():\n",
    "        for key_ in flats.keys():\n",
    "\n",
    "            feature_type = key.split('_')[0]\n",
    "            feature_type_ = key_.split('_')[0]\n",
    "\n",
    "            func_type = key.split('_')[1]\n",
    "            func_type_ = key_.split('_')[1]\n",
    "\n",
    "            try:\n",
    "                bounds_type = key.split('_')[2]\n",
    "                bounds_type_ = key_.split('_')[2]\n",
    "            except:\n",
    "                bounds_type = ''\n",
    "                bounds_type_ = ''\n",
    "\n",
    "            if f'{key_}_{key}' in params2.keys():\n",
    "                continue\n",
    "            params2[f'{key}_{key_}']=(sorted(list(set(flats[key][0]+flats[key_][0]))),testUtils.dict_combine(flats[key][1],flats[key_][1]))\n",
    "            \n",
    "    params2_ = dict()\n",
    "    seen =set()\n",
    "    for key in exts.keys():\n",
    "        for key_ in exts.keys():\n",
    "\n",
    "            feature_type = key.split('_')[0]\n",
    "            feature_type_ = key_.split('_')[0]\n",
    "\n",
    "            func_type = key.split('_')[1]\n",
    "            func_type_ = key_.split('_')[1]\n",
    "\n",
    "            try:\n",
    "                bounds_type = key.split('_')[2]\n",
    "                bounds_type_ = key_.split('_')[2]\n",
    "            except:\n",
    "                bounds_type = ''\n",
    "                bounds_type_ = ''\n",
    "\n",
    "            if f'{key_}_{key}' in params2_.keys():\n",
    "                continue\n",
    "            params2_[f'{key}_{key_}']=(sorted(list(set(exts[key][0]+exts[key_][0]))),testUtils.dict_combine(exts[key][1],exts[key_][1]))\n",
    "\n",
    "    params2['all_flat_quad']= (['a','b','c','f','g','h','k','l','m'],None)\n",
    "    params2['all_ext_quad'] = (['b','l','g','p','q','r','s','t','u','x','y','z','a_','b_','c_','f_','g_','h_','i_','j_','k_'],None)\n",
    "\n",
    "\n",
    "    for key in list(params2_.keys())[:5]:\n",
    "        params2[f'{key}_normed_add']=(sorted(list(set(params2_[key][0]+['n_','o_','p_','s_']))),testUtils.dict_combine(params2_[key][1],None))\n",
    "        params2[f'{key}_normed_mult']=(sorted(list(set(params2_[key][0]+['t_','u_','v_','w_','x_','y_']))),testUtils.dict_combine(params2_[key][1],None))\n",
    "\n",
    "    params2.update(params2_) \n",
    "    #params.update(params2)  \n",
    "\n",
    "    for key in list(params2.keys())[:10]:\n",
    "        params[f'{key}_sigtune']=(params[key][0]+['z_'],None)\n",
    "\n",
    "    # for key in list(params2.keys())[:10]:\n",
    "    #     params[f'{key}_with_mz']=(params[key][0]+['z_'],None)\n",
    "\n",
    "    reload(func_ob)\n",
    "    reload(TunaSims)\n",
    "    reload(testUtils)\n",
    "    #helper lambda funcs\n",
    "    squared_loss = lambda x: (1-x)**2\n",
    "    lin_loss = lambda x: np.abs(1-x)\n",
    "    l1_reg = lambda l,x: l*np.sum(np.abs(x))\n",
    "    l2_reg = lambda l,x: l*np.sqrt(np.sum(x**2))\n",
    "    no_reg = lambda x: 0\n",
    "\n",
    "    reg_funcs = [no_reg,partial(l2_reg,0.01),partial(l2_reg,0.1)]\n",
    "    reg_names = ['none_none','l2_0.01','l2_0.1']\n",
    "    losses = [squared_loss]\n",
    "    loss_names = ['squared']\n",
    "    momentums = ['none']\n",
    "    mom_weights = [[0.2,0.8]]\n",
    "    lambdas = [0.01]\n",
    "    max_iters = [1e4]\n",
    "\n",
    "    funcs_same = testUtils.create_all_funcs_stoch(reg_funcs=reg_funcs,\n",
    "                                        reg_names=reg_names,\n",
    "                                        losses=losses,\n",
    "                                        loss_names=loss_names,\n",
    "                                        momentums=momentums,\n",
    "                                        params=params2,\n",
    "                                        inits=inits,\n",
    "                                        mom_weights=mom_weights,\n",
    "                                        lambdas=lambdas,\n",
    "                                        max_iters=max_iters,\n",
    "                                        func = TunaSims.tuna_combo_distance)\n",
    "\n",
    "    funcs_dif = testUtils.create_all_funcs_stoch(reg_funcs=reg_funcs,\n",
    "                                        reg_names=reg_names,\n",
    "                                        losses=losses,\n",
    "                                        loss_names=loss_names,\n",
    "                                        momentums=momentums,\n",
    "                                        params=params2,\n",
    "                                        inits=inits,\n",
    "                                        mom_weights=mom_weights,\n",
    "                                        lambdas=lambdas,\n",
    "                                        max_iters=max_iters,\n",
    "                                        func = TunaSims.tuna_combo_distance)\n",
    "\n",
    "    all_funcs_ = [funcs_same, funcs_dif]\n",
    "\n",
    "    print(f'number of specifications: {len(funcs_same)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in ppm_windows:\n",
    "\n",
    "    trained_dict = dict()\n",
    "    all_funcs = copy.deepcopy(all_funcs_)\n",
    "\n",
    "    sub_train_same_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_same_ce_{window}_ppm.pkl')\n",
    "    sub_train_dif_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_dif_ce_{window}_ppm.pkl')\n",
    "    \n",
    "    train_datasets = [sub_train_same_ce, sub_train_dif_ce]\n",
    "    dataset_names = ['same_ce','dif_ce']\n",
    "\n",
    "    settings = 1\n",
    "\n",
    "    for _ in range(len(train_datasets)):\n",
    "        \n",
    "        for j in range(settings):\n",
    "\n",
    "            sub = train_datasets[_].iloc[:,3*j:3*(j+1)]\n",
    "            sub.columns=['mzs','query','target']\n",
    "            sub['precursor'] = train_datasets[_]['precursor']\n",
    "            sub['match'] = train_datasets[_]['match']\n",
    "        \n",
    "            trained=list()\n",
    "            for i in range(len(all_funcs[_])):\n",
    "                \n",
    "                all_funcs[_][i].fit(sub)\n",
    "                trained.append(all_funcs[_][i])\n",
    "                if (i+1)%10==0:\n",
    "                    print(f'trained {i+1} functions on {dataset_names[_]}_{j}')\n",
    "\n",
    "\n",
    "            trained_dict[f'{dataset_names[_]}_{j}'] = trained\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/train_to_error/trained_dict_{window}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "        pickle.dump(trained_dict, handle)\n",
    "        del(trained_dict)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in ppm_windows:\n",
    "    \n",
    "    sub_train_same_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_same_ce_{window}_ppm.pkl')\n",
    "    sub_train_dif_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_dif_ce_{window}_ppm.pkl')\n",
    "    \n",
    "    train_datasets = [sub_train_same_ce, sub_train_dif_ce]\n",
    "    dataset_names = ['same_ce','dif_ce']\n",
    "\n",
    "    settings=1\n",
    "\n",
    "    trained_res=None\n",
    "    for _ in range(len(train_datasets)):\n",
    "        for j in range(settings):\n",
    "\n",
    "            #grab trained models for this portion of dataframe\n",
    "            sub = train_datasets[_].iloc[:,3*j:3*(j+1)]\n",
    "            sub.columns=['mzs','query','target']\n",
    "            sub['precursor'] = train_datasets[_]['precursor']\n",
    "            sub['match'] = train_datasets[_]['match']\n",
    "\n",
    "            small = testUtils.trained_res_to_df(models,sub)\n",
    "            small.insert(1,'settings', f'{dataset_names[_]}_{j}')\n",
    "            trained_res=pd.concat((trained_res,small))\n",
    "            print(f'completed {dataset_names[_]}_{j}')\n",
    "\n",
    "    print('generated train results')\n",
    "    del(sub_train_dif_ce)\n",
    "    del(sub_train_same_ce)\n",
    "\n",
    "    sub_val_same_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/val_cleaned_matches_same_ce_{window}_ppm.pkl')\n",
    "    sub_val_dif_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/val_cleaned_matches_dif_ce_{window}_ppm.pkl')\n",
    "    val_datasets = [sub_val_same_ce, sub_val_dif_ce]\n",
    "\n",
    "    val_aucs=list()\n",
    "    for _ in range(len(val_datasets)):\n",
    "        for j in range(settings):\n",
    "\n",
    "            #grab trained models for this portion of dataframe\n",
    "            models = trained_dict[f'{dataset_names[_]}_{j}']\n",
    "            sub = val_datasets[_].iloc[:,3*j:3*(j+1)]\n",
    "            sub.columns=['mzs','query','target']\n",
    "            sub['precursor'] = val_datasets[_]['precursor']\n",
    "            sub['match'] = val_datasets[_]['match']\n",
    "            val_aucs = val_aucs + testUtils.trained_res_to_df(models,sub)['auc'].tolist()\n",
    "            print(f'completed {dataset_names[_]}_{j}')\n",
    "\n",
    "    trained_res['val']=val_aucs\n",
    "    print('generated val results')\n",
    "\n",
    "    del(sub_val_dif_ce)\n",
    "    del(sub_val_same_ce)\n",
    "\n",
    "    sub_test_same_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test_cleaned_matches_same_ce_{window}_ppm.pkl')\n",
    "    sub_test_dif_ce = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test_cleaned_matches_dif_ce_{window}_ppm.pkl')\n",
    "    test_datasets = [sub_test_same_ce, sub_test_dif_ce]\n",
    "    \n",
    "    test_aucs=list()\n",
    "    for _ in range(len(test_datasets)):\n",
    "        for j in range(settings):\n",
    "\n",
    "            #grab trained models for this portion of dataframe\n",
    "            models = trained_dict[f'{dataset_names[_]}_{j}']\n",
    "            sub = test_datasets[_].iloc[:,3*j:3*(j+1)]\n",
    "            sub.columns=['mzs','query','target']\n",
    "            sub['precursor'] = test_datasets[_]['precursor']\n",
    "            sub['match'] = test_datasets[_]['match'].tolist()\n",
    "            test_aucs = test_aucs + testUtils.trained_res_to_df(models,sub)['auc'].tolist()\n",
    "            print(f'completed {dataset_names[_]}_{j}')\n",
    "\n",
    "    trained_res['test']=test_aucs\n",
    "    print('generated test results')\n",
    "\n",
    "    del(sub_test_dif_ce)\n",
    "    del(sub_test_same_ce)\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/train_to_error/trained_res_{window}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "        pickle.dump(trained_res, handle)\n",
    "        del(trained_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions: \n",
    "\n",
    "add offsets for terms\n",
    "\n",
    "num of params not appearing to change train time much\n",
    "\n",
    "consider replacing knockouts with sigmoids\n",
    "\n",
    "consider tuning final sigmoid\n",
    "\n",
    "should features like length,entropy be included in the similarity, or be used outside as extra feature in learned mod.both? neither?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Ideas:\n",
    "\n",
    "Accuracy (In order of increasing difficulty):\n",
    "\n",
    "-Incorporate as feature how many possible chem structures (can also restrict to NPS) exist within a certain precursor distance. (violating golden rules or not)\n",
    "\n",
    "-include original NIST version or theoretical res as feature\n",
    "\n",
    "-Weight different ranges of spec differently for matches (more diversity/greater accuracy)\n",
    "\n",
    "-smush together top n results over different inchicores and come up with combined model predicting over individual inchicores\n",
    "\n",
    "-diagnostic ion/loss classing as a feature...do they match\n",
    "\n",
    "-kernelized smooth match\n",
    "\n",
    "-3d struct guesses...do they match (cores, but can generalize to 3d)\n",
    "\n",
    "Speed(In order of increasing difficulty):\n",
    "\n",
    "-combine sim metrics and expand(apply func to df)\n",
    "\n",
    "-exclude matches based on non-similarity features to cut down on needed comparisons\n",
    "\n",
    "-ion tables to upper bound similarity\n",
    "\n",
    "-only use one peak consolidation and matching protocol...then only do reweight transformations on already matched peaks for spec and sim features\n",
    "\n",
    "-can missing peaks in lower energy be explained by frags and losses from higher energy? incorporate into model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order to proceed:\n",
    "\n",
    "-recreate databases with coll energy included (standardized format across DBs)\n",
    "\n",
    "-what proportion of matches are the same coll energy?\n",
    "\n",
    "-quantify variability in peak appearance vs peak intensity across collision energies\n",
    "    -does this relate in a predictable way to fragment mass\n",
    "\n",
    "-test sim metrics for same coll energy vs not same col energy (is the same inductive bias useful)\n",
    "\n",
    "-Show that regular funcs are in the space of combo distance\n",
    "\n",
    "-test combining individual metrics that use different components of the 2 vectors (add, mult, dif)\n",
    "\n",
    "-range over individual metrics in combined score in attempt to explain why combining them is successful\n",
    "\n",
    "-train combo metrics with flattened components and individual (should these sims be broken out?)\n",
    "    -should we do this for same coll energy vs dif energies\n",
    "\n",
    "-are different combo metrics put into larger model more successful than the combined individual metrics\n",
    "\n",
    "-can tunasims be fit with nonlinearities between the components (flattened or not?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
