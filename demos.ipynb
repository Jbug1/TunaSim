{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from importlib import reload\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "import copy\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as hgbc\n",
    "import pickle\n",
    "import warnings\n",
    "import math\n",
    "import copy\n",
    "import tests\n",
    "import figures\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "from sklearn.linear_model import Ridge\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import TunaSims\n",
    "import func_ob\n",
    "import tools\n",
    "import datasetBuilder\n",
    "import testUtils\n",
    "import spectral_similarity\n",
    "import itertools\n",
    "import reweightFuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nist14='/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist14_highres.pkl'\n",
    "nist20_prot = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist20_prot_fiehn_.pkl'\n",
    "nist20 = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist20.pkl'\n",
    "nist23_prot = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist23_prot_deprot_only.pkl'\n",
    "nist23='/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist23_full.pkl'\n",
    "gnps='/Users/jonahpoczobutt/projects/raw_data/db_csvs/gnps_highres.pkl'\n",
    "mona='/Users/jonahpoczobutt/projects/raw_data/db_csvs/mona_highres.pkl'\n",
    "metlin='/Users/jonahpoczobutt/projects/raw_data/db_csvs/metlin.pkl'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion Points\n",
    "\n",
    "Should we look at inchiKey for match rather than inchiCore\n",
    "\n",
    "does spectral entropy relate to precursor m/z - yes\n",
    "\n",
    "does spectral entropy relate to CE - yes\n",
    "\n",
    "does peak intensity relate to m/z - meh\n",
    "\n",
    "does peak intensity relate to CE\n",
    "\n",
    "What factors should play into reweighting\n",
    "\n",
    "    -for quality measure: precursor mz\n",
    "    -for reducing corr: fragment mz\n",
    "\n",
    "does having lower correlated similarity measures produce better results\n",
    "\n",
    "can we obtain lower correlation with the same cleaning procedure in order to be memory efficient (ie thru sim measures)\n",
    "\n",
    "Should we try sequential fitting on residuals?\n",
    "\n",
    "incorporate into model as feature the cleanliness of spectra by comparing the entropy of spectra from entire experiment vs their expectation from combined database. Higher entropy -> lower quality when adjusted properly. Inputs could be m/z as well as CE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all Necessary Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#databases\n",
    "outputs_path='/Users/jonahpoczobutt/projects/TunaRes/test'\n",
    "\n",
    "self_search=True\n",
    "query = nist20\n",
    "target = nist20\n",
    "\n",
    "if query == target:\n",
    "    self_search = True\n",
    "    \n",
    "fullRun=False\n",
    "if fullRun:\n",
    "    os.mkdir(outputs_path)\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/gbcIndices')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/train')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/val')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/test')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/port')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/datasets')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/train')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/val')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/test')\n",
    "    os.mkdir(f'{outputs_path}/gbc_res')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/train_to_func')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/train_to_error')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splt Queries into Train, Val, Test by Core or Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullRun=True\n",
    "match_category = 'inchi_base'\n",
    "if fullRun:\n",
    "\n",
    "    #This should be replaced with a function to read in all the databases\n",
    "    query_ = pd.read_pickle(query)\n",
    "\n",
    "    #jonah edit here\n",
    "    all_bases = list(set(query_[match_category]))\n",
    "\n",
    "    if self_search:\n",
    "        query_.insert(0,'queryID', [i for i in range(len(query_))])\n",
    "    else:\n",
    "        query_.insert(0,'queryID', [\"_\" for i in range(len(query_))])\n",
    "\n",
    "    #this method is in place\n",
    "    np.random.shuffle(all_bases)\n",
    "\n",
    "    first_bases = all_bases[:int(len(all_bases)*0.5)]\n",
    "    second_bases = all_bases[int(len(all_bases)*0.5):int(len(all_bases)*0.7)]\n",
    "    third_bases = all_bases[int(len(all_bases)*0.7):]\n",
    "\n",
    "    first_query_ = query_[np.isin(query_[match_category],first_bases)]\n",
    "    first_query_.reset_index(inplace=True)\n",
    "    first_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/first_query.pkl')\n",
    "    del(first_query_)\n",
    "\n",
    "    second_query_ = query_[np.isin(query_[match_category],second_bases)]\n",
    "    second_query_.reset_index(inplace=True)\n",
    "    second_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/second_query.pkl')\n",
    "    del(second_query_)\n",
    "\n",
    "    third_query_ = query_[np.isin(query_[match_category],third_bases)]\n",
    "    third_query_.reset_index(inplace=True)\n",
    "    third_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/third_query.pkl')\n",
    "    del(third_query_)\n",
    "    del(query_)\n",
    "\n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/first_bases.npy',first_bases)\n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/second_bases.npy',second_bases)\n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/third_bases.npy',third_bases)\n",
    "    del(first_bases)\n",
    "    del(second_bases)\n",
    "    del(third_bases)\n",
    "    del(all_bases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Parameters Here!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1e5\n",
    "adduct_match = False\n",
    "strong_self_separation = True\n",
    "\n",
    "num_chunks=int(1e6) #number of chunks to be combined for calculating correlations and collecting testable indices\n",
    "\n",
    "label_field = 'InchiCoreMatch' # should be either inchicore or inchi\n",
    "\n",
    "comparison_metrics = ['entropy',\n",
    "                'manhattan',\n",
    "                'lorentzian',\n",
    "                'dot_product',\n",
    "                'fidelity',\n",
    "                'matusita',\n",
    "                'chi2',\n",
    "                'laplacian',\n",
    "                'harmonic_mean',\n",
    "                'bhattacharya_2',\n",
    "                'squared_chord',\n",
    "                'cross_ent'\n",
    "                ]\n",
    "\n",
    "ppm_windows = [3]\n",
    "noise_threshes=[partial(reweightFuncs.noise_clip, perc_thresh = 0.0),\n",
    "                partial(reweightFuncs.noise_clip, perc_thresh = 0.05),\n",
    "                partial(reweightFuncs.noise_clip, fixed_thresh = 10)]\n",
    "\n",
    "noise_names = ['None','5%','10']\n",
    "centroid_tolerance_vals = [0.05,0.01]\n",
    "centroid_tolerance_types=['da','da']\n",
    "reweight_methods = [partial(reweightFuncs.logent,intercept = 0.25), reweightFuncs.weight_intensity_by_entropy, partial(reweightFuncs.fixed_power,power=1)]\n",
    "reweight_names = ['logent','fiehn','1']\n",
    "sim_methods=comparison_metrics\n",
    "prec_removes=[lambda x: x-1.6, lambda x: None]\n",
    "prec_remove_names = ['fiehn', 'none']\n",
    "train_size=3e6\n",
    "val_size=1e6\n",
    "test_size=2e6\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ppm_windows:\n",
    "    try:\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/train/{i}_ppm')\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/train/{i}_ppm')\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/val/{i}_ppm')\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/val/{i}_ppm')\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches/test/{i}_ppm')\n",
    "        os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/test/{i}_ppm')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#read in first bases and shuffle order\n",
    "query_ = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/first_query.pkl')\n",
    "query_ = query_.sample(frac=1)\n",
    " \n",
    "if self_search:\n",
    "\n",
    "    if strong_self_separation:\n",
    "        target_ = query_\n",
    "    else:\n",
    "        target_=pd.read_pickle(target)\n",
    "        target_.insert(0,'queryID', [i for i in range(len(target_))])\n",
    "\n",
    "else:\n",
    "    target_=pd.read_pickle(target)\n",
    "    target_.insert(0,'queryID', [\"*\" for i in range(len(target_))])\n",
    "    \n",
    "\n",
    "datasetBuilder.create_matches_and_model_data(query_,\n",
    "                              target_,\n",
    "                            matchesOutputPath = f'{outputs_path}/intermediateOutputs/splitMatches/train',\n",
    "                            modelDataOutputPath = f'{outputs_path}/intermediateOutputs/datasets/train',\n",
    "                            chunk_size = chunk_size,\n",
    "                            max_size = train_size,\n",
    "                            ppm_windows = ppm_windows,\n",
    "                            noise_threshes = noise_threshes,\n",
    "                            noise_names = noise_names,\n",
    "                            centroid_tolerance_vals = centroid_tolerance_vals,\n",
    "                            centroid_tolerance_types = centroid_tolerance_types,\n",
    "                            reweight_methods = reweight_methods,\n",
    "                            reweight_names = reweight_names,\n",
    "                            sim_methods = comparison_metrics,\n",
    "                            prec_removes = prec_removes,\n",
    "                            prec_remove_names = prec_remove_names\n",
    "                            )\n",
    "\n",
    "del(query_)\n",
    "del(target_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual Scores Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hit_sanity_check = True\n",
    "if top_hit_sanity_check:\n",
    "\n",
    "    for window in ppm_windows:\n",
    "        try:\n",
    "            os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/checks')\n",
    "            os.mkdir(f'{outputs_path}/intermediateOutputs/datasets/checks/{window}_ppm')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        tests.create_variable_comparisons_chunk(\n",
    "                                        noise_threshes = [lambda x: x * 0.01], \n",
    "                                        centroid_threshes = [0.05],\n",
    "                                        centroid_types = ['da'],\n",
    "                                        reweight_names = ['fiehn','none'], \n",
    "                                        reweight_funcs = [reweightFuncs.weight_intensity_by_entropy, partial(reweightFuncs.fixed_power,power=1)], \n",
    "                                        sim_methods = ['entropy','dot_product','cross_ent'], \n",
    "                                        prec_funcs = [lambda x: x-1.6],\n",
    "                                        prec_names = ['fiehn'],\n",
    "                                        matches_folder = f'{outputs_path}/intermediateOutputs/splitMatches/train/{window}_ppm', \n",
    "                                        top_hit_only = True,  \n",
    "                                        match_field = 'InchiCoreMatch',\n",
    "                                        outpath = f'{outputs_path}/intermediateOutputs/datasets/checks/{window}_ppm/res.csv',\n",
    "                                        logpath = f'{outputs_path}/intermediateOutputs/datasets/checks/{window}_ppm/log.txt'\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "sim_indices = datasetBuilder.generate_keep_indices(noise_threshes=[True for i in range(len(noise_threshes))],\n",
    "                                                centroid_tolerance_vals = [True for i in range(len(centroid_tolerance_vals))],\n",
    "                                                reweight_methods = [True for i in range(len(reweight_methods))],\n",
    "                                                sim_methods = [True for i in range(len(sim_methods))],\n",
    "                                                prec_removes = [True for i in range(len(prec_removes))],\n",
    "                                                spec_features=[False for i in range(6)])\n",
    "for window in ppm_windows:\n",
    "\n",
    "    chunks=list()\n",
    "    #catch case where we run out of chunks to combine\n",
    "    labels = list()\n",
    "    for j in range(num_chunks):\n",
    "        try:\n",
    "            chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/train/{window}_ppm/chunk_{j+1}.pkl')\n",
    "            labels = labels + chunk[label_field].tolist()\n",
    "            chunk = chunk.iloc[:,sim_indices]\n",
    "            chunks.append(chunk)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    print('created train')\n",
    "    train = pd.concat(chunks)\n",
    "    del(chunk)\n",
    "    del(chunks)\n",
    "\n",
    "individual_scores = list()\n",
    "for i in range(train.shape[1]):\n",
    "    individual_scores.append(auc(labels, train.iloc[:,i].tolist()))\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "\n",
    "individual_results = pd.DataFrame(train.columns, individual_scores)\n",
    "individual_results.reset_index(inplace=True, drop=False)\n",
    "individual_results.columns = ['auc','name']\n",
    "individual_results.sort_values(by='auc', inplace=True)\n",
    "\n",
    "individual_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all Val Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = False\n",
    "if val:\n",
    "    #read in second bases and shuffle order\n",
    "    query_ = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/second_query.pkl')\n",
    "    query_ = query_.sample(frac=1)\n",
    "\n",
    "    if self_search:\n",
    "\n",
    "        if strong_self_separation:\n",
    "            target_ = query_\n",
    "        else:\n",
    "            target_=pd.read_pickle(target)\n",
    "            target_.insert(0,'queryID', [i for i in range(len(target_))])\n",
    "\n",
    "    else:\n",
    "        target_=pd.read_pickle(target)\n",
    "        target_.insert(0,'queryID', [\"*\" for i in range(len(target_))])\n",
    "\n",
    "    datasetBuilder.create_matches_and_model_data(query_,\n",
    "                                target_,\n",
    "                                matchesOutputPath = f'{outputs_path}/intermediateOutputs/splitMatches/val',\n",
    "                                modelDataOutputPath = f'{outputs_path}/intermediateOutputs/datasets/val',\n",
    "                                chunk_size = chunk_size,\n",
    "                                max_size = val_size,\n",
    "                                ppm_windows = ppm_windows,\n",
    "                                noise_threshes = noise_threshes,\n",
    "                                noise_names = noise_names,\n",
    "                                centroid_tolerance_vals = centroid_tolerance_vals,\n",
    "                                centroid_tolerance_types = centroid_tolerance_types,\n",
    "                                reweight_methods = reweight_methods,\n",
    "                                reweight_names = reweight_names,\n",
    "                                sim_methods = comparison_metrics,\n",
    "                                prec_removes = prec_removes,\n",
    "                                prec_remove_names = prec_remove_names\n",
    "                                )\n",
    "\n",
    "    del(query_)\n",
    "    del(target_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in second bases and shuffle order\n",
    "query_ = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/inchisBySet/third_query.pkl')\n",
    "query_ = query_.sample(frac=1)\n",
    "\n",
    "if self_search:\n",
    "\n",
    "    if strong_self_separation:\n",
    "        target_ = query_\n",
    "    else:\n",
    "        target_=pd.read_pickle(target)\n",
    "        target_.insert(0,'queryID', [i for i in range(len(target_))])\n",
    "\n",
    "else:\n",
    "    target_=pd.read_pickle(target)\n",
    "    target_.insert(0,'queryID', [\"*\" for i in range(len(target_))])\n",
    "\n",
    "datasetBuilder.create_matches_and_model_data(query_,\n",
    "                              target_,\n",
    "                            matchesOutputPath = f'{outputs_path}/intermediateOutputs/splitMatches/test',\n",
    "                            modelDataOutputPath = f'{outputs_path}/intermediateOutputs/datasets/test',\n",
    "                            chunk_size = chunk_size,\n",
    "                            max_size = test_size,\n",
    "                            ppm_windows = ppm_windows,\n",
    "                            noise_threshes = noise_threshes,\n",
    "                            noise_names = noise_names,\n",
    "                            centroid_tolerance_vals = centroid_tolerance_vals,\n",
    "                            centroid_tolerance_types = centroid_tolerance_types,\n",
    "                            reweight_methods = reweight_methods,\n",
    "                            reweight_names = reweight_names,\n",
    "                            sim_methods = comparison_metrics,\n",
    "                            prec_removes = prec_removes,\n",
    "                            prec_remove_names = prec_remove_names\n",
    "                            )\n",
    "\n",
    "del(query_)\n",
    "del(target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [-0.6,-0.5,0]\n",
    "bisect_left(a,-0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create indices to pull for interesting metric combos, instantiate GBC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_indices = datasetBuilder.generate_keep_indices(noise_threshes=[True for i in range(len(noise_threshes))],\n",
    "                                                centroid_tolerance_vals = [True for i in range(len(centroid_tolerance_vals))],\n",
    "                                                reweight_methods = [True for i in range(len(reweight_methods))],\n",
    "                                                sim_methods = [True for i in range(len(sim_methods))],\n",
    "                                                prec_removes = [True for i in range(len(prec_removes))],\n",
    "                                                spec_features=[False for i in range(6)])\n",
    "\n",
    "\n",
    "#get n unique pairs and unique triplets by metric\n",
    "lim_3_metrics = 10\n",
    "combos_added = 0\n",
    "threes = list()\n",
    "for combo in itertools.combinations(range(len(sim_methods)),r=3):\n",
    "\n",
    "    threes.append(list(combo))\n",
    "    combos_added+=1\n",
    "\n",
    "    if combos_added == lim_3_metrics:\n",
    "        break\n",
    "\n",
    "\n",
    "lim_5_metrics = 10\n",
    "combos_added = 0\n",
    "fives = list()\n",
    "for combo in itertools.combinations(range(len(sim_methods)),r=5):\n",
    "\n",
    "    fives.append(list(combo))\n",
    "    combos_added+=1\n",
    "\n",
    "    if combos_added == lim_5_metrics:\n",
    "        break\n",
    "\n",
    "for i in ppm_windows:\n",
    "\n",
    "    chunks=list()\n",
    "    #catch case where we run out of chunks to combine\n",
    "    for j in range(num_chunks):\n",
    "        try:\n",
    "            chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/train/{i}_ppm/chunk_{j+1}.pkl')\n",
    "            chunk = chunk.iloc[:,sim_indices]\n",
    "            chunks.append(chunk)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    train = pd.concat(chunks)\n",
    "    del(chunk)\n",
    "    del(chunks)\n",
    "\n",
    "    train = train.corr()\n",
    "    train.to_csv(f'{outputs_path}/intermediateOutputs/datasets/train/{i}_ppm/corrs.csv')\n",
    "\n",
    "    models = [\n",
    "            hgbc(),\n",
    "            # hgbc(learning_rate=0.5),\n",
    "            # hgbc(max_iter=200),\n",
    "            # hgbc(learning_rate=0.01,min_samples_leaf=10),\n",
    "            # hgbc(max_iter=200,min_samples_leaf=10),\n",
    "            # hgbc(learning_rate=0.5, max_iter=200,min_samples_leaf=10),\n",
    "            ]\n",
    "    \n",
    "    num_condition = 10\n",
    "    num_control = 10\n",
    "\n",
    "    indices = dict()\n",
    "    corrs = dict()\n",
    "    indices['all-sims'] = list(range(train.shape[1]))\n",
    "\n",
    "    low_corr_3, rand_corr_3, high_corr_3 = testUtils.get_corr_and_control(train,\n",
    "                                                                   3, \n",
    "                                                                   num_condition = num_condition,\n",
    "                                                                   num_control = num_control)\n",
    "    \n",
    "    for _ in range(num_condition):\n",
    "        indices[f'low-corr-3-all_{_}'] = low_corr_3[0][_]\n",
    "        corrs[f'low-corr-3-all_{_}'] = low_corr_3[1][_]\n",
    "    for _ in range(num_control):\n",
    "        indices[f'rand-3-all_{_}'] = rand_corr_3[0][_]\n",
    "        corrs[f'rand-3-all_{_}'] = rand_corr_3[1][_]\n",
    "    for _ in range(num_condition):\n",
    "        indices[f'high-3-all_{_}'] = high_corr_3[0][_]\n",
    "        corrs[f'high-3-all_{_}'] = high_corr_3[1][_]\n",
    "    \n",
    "    print('generated 3')\n",
    "\n",
    "    low_corr_5, rand_corr_5, high_corr_5 = testUtils.get_corr_and_control(train,\n",
    "                                                                   5, \n",
    "                                                                   num_condition = num_condition,\n",
    "                                                                   num_control = num_control)\n",
    "    \n",
    "    for _ in range(num_condition):\n",
    "        indices[f'low-corr-5-all_{_}'] = low_corr_5[0][_]\n",
    "        corrs[f'low-corr-5-all_{_}'] = low_corr_5[1][_]\n",
    "    for _ in range(num_control):\n",
    "        indices[f'rand-5-all_{_}'] = rand_corr_5[0][_]\n",
    "        corrs[f'rand-5-all_{_}'] = rand_corr_5[1][_]\n",
    "    for _ in range(num_condition):\n",
    "        indices[f'high-5-all_{_}'] = high_corr_5[0][_]\n",
    "        corrs[f'high-5-all_{_}'] = high_corr_5[1][_]\n",
    "    print('generated 5')\n",
    "\n",
    "    low_corr_10, rand_corr_10, high_corr_10 = testUtils.get_corr_and_control(train,\n",
    "                                                                   10, \n",
    "                                                                   num_condition = num_condition,\n",
    "                                                                   num_control = num_control)\n",
    "    \n",
    "    for _ in range(num_condition):\n",
    "        indices[f'low-corr-10-all_{_}'] = low_corr_10[0][_]\n",
    "        corrs[f'low-corr-10-all_{_}'] = low_corr_10[1][_]\n",
    "    for _ in range(num_control):\n",
    "        indices[f'rand-10-all_{_}'] = rand_corr_10[0][_]\n",
    "        corrs[f'rand-10-all_{_}'] = rand_corr_10[1][_]\n",
    "    for _ in range(num_condition):\n",
    "        indices[f'high-10-all_{_}'] = high_corr_10[0][_]\n",
    "        corrs[f'high-10-all_{_}'] = high_corr_10[1][_]\n",
    "    print('generated 10')\n",
    "\n",
    "    low_corr_15, rand_corr_15, high_corr_15 = testUtils.get_corr_and_control(train,\n",
    "                                                                   15, \n",
    "                                                                   num_condition = num_condition,\n",
    "                                                                   num_control = num_control)\n",
    "    \n",
    "    for _ in range(num_condition):\n",
    "        indices[f'low-corr-15-all_{_}'] = low_corr_15[0][_]\n",
    "        corrs[f'low-corr-15-all_{_}'] = low_corr_15[1][_]\n",
    "    for _ in range(num_control):\n",
    "        indices[f'rand-15-all_{_}'] = rand_corr_15[0][_]\n",
    "        corrs[f'rand-15-all_{_}'] = rand_corr_15[1][_]\n",
    "    for _ in range(num_condition):\n",
    "        indices[f'high-15-all_{_}'] = high_corr_15[0][_]\n",
    "        corrs[f'high-15-all_{_}'] = high_corr_15[1][_]\n",
    "    print('generated 15')\n",
    "\n",
    "    low_corr_20, rand_corr_20, high_corr_20 = testUtils.get_corr_and_control(train,\n",
    "                                                                   20, \n",
    "                                                                   num_condition = num_condition,\n",
    "                                                                   num_control = num_control)\n",
    "    for _ in range(num_condition):\n",
    "        indices[f'low-corr-20-all_{_}'] = low_corr_20[0][_]\n",
    "        corrs[f'low-corr-20-all_{_}'] = low_corr_20[1][_]\n",
    "    for _ in range(num_control):\n",
    "        indices[f'rand-20-all_{_}'] = rand_corr_20[0][_]\n",
    "        corrs[f'rand-20-all_{_}'] = rand_corr_20[1][_]\n",
    "    for _ in range(num_condition):\n",
    "        indices[f'high-20-all_{_}'] = high_corr_20[0][_]\n",
    "        corrs[f'high-20-all_{_}'] = high_corr_20[1][_]\n",
    "    print('generated 20')\n",
    "\n",
    "    num_condition = 3\n",
    "    num_control = 3\n",
    "    for i in range(int((train.shape[1])/len(comparison_metrics))):\n",
    "\n",
    "        low_corr_3,rand_corr_3, high_corr_3 = testUtils.get_corr_and_control(train.iloc[i*len(comparison_metrics):(i+1)*len(comparison_metrics),i*len(comparison_metrics):(i+1)*len(comparison_metrics)],3, num_condition=num_condition, num_control=num_control)\n",
    "        for _ in range(num_condition):\n",
    "            indices[f'low-corr-3-{i}_{_}'] = low_corr_3[0][_]+(i*len(comparison_metrics))\n",
    "            corrs[f'low-corr-3-{i}_{_}'] = low_corr_3[1][_]+(i*len(comparison_metrics))\n",
    "        for _ in range(num_control):\n",
    "            indices[f'rand-3-{i}_{_}'] = rand_corr_3[0][_]+(i*len(comparison_metrics))\n",
    "            corrs[f'rand-3-{i}_{_}'] = rand_corr_3[1][_]+(i*len(comparison_metrics))\n",
    "        for _ in range(num_control):\n",
    "            indices[f'high-3-{i}_{_}'] = high_corr_3[0][_]+(i*len(comparison_metrics))\n",
    "            corrs[f'high-3-{i}_{_}'] = high_corr_3[1][_]+(i*len(comparison_metrics))\n",
    "\n",
    "        low_corr_5,rand_corr_5, high_corr_5 = testUtils.get_corr_and_control(train.iloc[i*len(comparison_metrics):(i+1)*len(comparison_metrics),i*len(comparison_metrics):(i+1)*len(comparison_metrics)],5, num_condition=num_condition, num_control=num_control)\n",
    "        \n",
    "        for _ in range(num_condition):\n",
    "            indices[f'low-corr-5-{i}_{_}'] = low_corr_5[0][_]+(i*len(comparison_metrics))\n",
    "            corrs[f'low-corr-5-{i}_{_}'] = low_corr_5[1][_]+(i*len(comparison_metrics))\n",
    "        for _ in range(num_control):\n",
    "            indices[f'rand-5-{i}_{_}'] = rand_corr_5[0][_]+(i*len(comparison_metrics))\n",
    "            corrs[f'rand-5-{i}_{_}'] = rand_corr_5[1][_]+(i*len(comparison_metrics))\n",
    "        for _ in range(num_control):\n",
    "            indices[f'high-5-{i}_{_}'] = high_corr_5[0][_]+(i*len(comparison_metrics))\n",
    "            corrs[f'high-5-{i}_{_}'] = high_corr_5[1][_]+(i*len(comparison_metrics))\n",
    "\n",
    "        for _ in range(len(threes)):\n",
    "            indices[f'three_metric_{i}_{_}'] = np.array(threes[_])+(i*len(comparison_metrics))\n",
    "\n",
    "        for _ in range(len(fives)):\n",
    "            indices[f'five_metrics_{i}_{_}'] = np.array(fives[_])+(i*len(comparison_metrics))\n",
    "\n",
    "    print('finished creating indices')\n",
    "    \n",
    "    #now populate correlation dictionary with anything we don't already have\n",
    "    corr_matrix = train.corr()\n",
    "    for key, value in indices.items():\n",
    "\n",
    "        if key not in corrs:\n",
    "            \n",
    "            corr = 0\n",
    "            for i in value:\n",
    "                for j in value:\n",
    "\n",
    "                    if i>j:\n",
    "                        corr += corr_matrix.iloc[i,j]/math.comb(len(value),2)\n",
    "\n",
    "            corrs[key] = corr\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/gbcIndices/custom_indices_{ppm_windows[0]}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "        pickle.dump(indices,handle)\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/gbcIndices/mean_correlations_{ppm_windows[0]}_ppm.pkl', 'wb') as handle:\n",
    "\n",
    "        pickle.dump(corrs,handle)\n",
    "\n",
    "    print(f' total number of models: {len(models) * len(indices)}')\n",
    "    del(indices)\n",
    "    del(corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train all models, collecting input aucs, their correlations, and their train,val,test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{outputs_path}/intermediateOutputs/gbcIndices/custom_indices_{ppm_windows[0]}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "       indices = pickle.load(handle)\n",
    "   \n",
    "for window in ppm_windows:\n",
    "\n",
    "    chunks=list()\n",
    "    #catch case where we run out of chunks to combine\n",
    "    labels = list()\n",
    "    for j in range(num_chunks):\n",
    "        try:\n",
    "            chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/train/{window}_ppm/chunk_{j+1}.pkl')\n",
    "            labels = labels + chunk[label_field].tolist()\n",
    "            chunk = chunk.iloc[:,sim_indices]\n",
    "            chunks.append(chunk)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    print('created train')\n",
    "    train = pd.concat(chunks)\n",
    "    train['match'] = labels\n",
    "    del(chunk)\n",
    "    del(chunks)\n",
    "    \n",
    "    logpath = f'{outputs_path}/gbc_res/trainlog.txt'\n",
    "    trained_models = testUtils.train_and_name_models(train, models, indices, logpath = logpath)\n",
    "    names = sorted(list(trained_models.keys()))\n",
    "    logpath = f'{outputs_path}/gbc_res/evallog.txt'\n",
    "    train_aucs = testUtils.evaluate_models_by_subset(trained_models, indices, train, logpath = logpath)\n",
    "    del(train)\n",
    "\n",
    "    print('finished train')\n",
    "\n",
    "    # chunks=list()\n",
    "    # #catch case where we run out of chunks to combine\n",
    "    # labels = list()\n",
    "    # for j in range(num_chunks):\n",
    "    #     try:\n",
    "    #         chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/val/{window}_ppm/chunk_{j+1}.pkl')\n",
    "    #         labels = labels + chunk[label_field].tolist()\n",
    "    #         chunk = chunk.iloc[:,sim_indices]\n",
    "    #         chunks.append(chunk)\n",
    "    #     except:\n",
    "    #         break\n",
    "\n",
    "    # val = pd.concat(chunks)\n",
    "    # val['match'] = labels\n",
    "    # del(chunk)\n",
    "    # del(chunks)\n",
    "\n",
    "    # val_aucs = testUtils.evaluate_models_by_subset(trained_models, indices, val, logpath = logpath)\n",
    "    # del(val)\n",
    "\n",
    "    print('finished val')\n",
    "\n",
    "    chunks=list()\n",
    "    match_chunks = list()\n",
    "    #catch case where we run out of chunks to combine\n",
    "    labels = list()\n",
    "    for j in range(num_chunks):\n",
    "        try:\n",
    "            chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/test/{window}_ppm/chunk_{j+1}.pkl')\n",
    "            matches_chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test/{window}_ppm/chunk_{j+1}.pkl')\n",
    "            labels = labels + chunk[label_field].tolist()\n",
    "            chunk = chunk.iloc[:,sim_indices]\n",
    "            match_chunk = matches_chunk[['queryID','target_base']]\n",
    "            chunks.append(chunk)\n",
    "            match_chunks.append(match_chunk)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    test = pd.concat(chunks)\n",
    "    test_match = pd.concat(match_chunks)\n",
    "    test['queryID'] = test_match['queryID']\n",
    "    test['target_base'] = test_match['target_base']\n",
    "    test['match'] = labels\n",
    "    del(chunk)\n",
    "    del(chunks)\n",
    "    del(match_chunk)\n",
    "    del(match_chunks)\n",
    "    \n",
    "\n",
    "    test_aucs = testUtils.evaluate_models_by_subset(trained_models, indices, test, logpath = logpath)\n",
    "    del(test)\n",
    "\n",
    "    print('finished test')\n",
    "\n",
    "    model_aucs = pd.DataFrame([names, train_aucs, test_aucs]).transpose()\n",
    "    model_aucs.columns=['name','train','test']\n",
    "\n",
    "    model_aucs.to_csv(f'{outputs_path}/gbc_res/model_aucs_{window}_ppm.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recreate training data\n",
    "for window in ppm_windows:\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/gbcIndices/custom_indices_{window}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "       indices = pickle.load(handle)\n",
    "\n",
    "    chunks=list()\n",
    "    #catch case where we run out of chunks to combine\n",
    "    labels = list()\n",
    "    for j in range(num_chunks):\n",
    "        try:\n",
    "            chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/train/{window}_ppm/chunk_{j+1}.pkl')\n",
    "            labels = labels + chunk[label_field].tolist()\n",
    "            chunk = chunk.iloc[:,sim_indices]\n",
    "            chunks.append(chunk)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    train = pd.concat(chunks)\n",
    "    del(chunk)\n",
    "    del(chunks)\n",
    "\n",
    "    #create df for correlation and aucs on training data\n",
    "\n",
    "    individual_aucs = np.zeros(len(train.columns))\n",
    "    individual_aucs_test = np.zeros(len(train.columns))\n",
    "\n",
    "    for i in range(train.shape[1]):\n",
    "\n",
    "        individual_aucs[i] = auc(labels, train.iloc[:,i].to_numpy())\n",
    "\n",
    "    train = pd.read_csv(f'{outputs_path}/intermediateOutputs/datasets/train/{window}_ppm/corrs.csv').iloc[:,1:]\n",
    "\n",
    "    max_aucs, mean_aucs = testUtils.auc_data(model_aucs['name'].tolist(), indices, individual_aucs)\n",
    "    min_corrs, mean_corrs = testUtils.corr_data(model_aucs['name'].tolist(), indices, train)\n",
    "\n",
    "    num_features=list()\n",
    "    for name in model_aucs['name'].tolist():\n",
    "\n",
    "        num_features.append(len(indices[name.split('__')[0]]))\n",
    "\n",
    "    feature_attributes = pd.DataFrame([model_aucs['name'].tolist(), max_aucs, mean_aucs, min_corrs, mean_corrs, num_features]).transpose()\n",
    "    feature_attributes.columns = ['name', 'max_auc', 'mean_auc', 'min_corr', 'mean_corr', 'num_features']\n",
    "\n",
    "    feature_attributes.to_csv(f'{outputs_path}/gbc_res/model_attributes_{window}_ppm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Linear Models of Performance by Feature Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in ppm_windows:\n",
    "\n",
    "    with open(f'{outputs_path}/intermediateOutputs/gbcIndices/custom_indices_{window}_ppm.pkl', 'rb') as handle:\n",
    "\n",
    "       indices = pickle.load(handle)\n",
    "\n",
    "    chunks=list()\n",
    "    #catch case where we run out of chunks to combine\n",
    "    labels = list()\n",
    "    for j in range(num_chunks):\n",
    "        try:\n",
    "            chunk = pd.read_pickle(f'{outputs_path}/intermediateOutputs/datasets/test/{window}_ppm/chunk_{j+1}.pkl')\n",
    "            labels = labels + chunk[label_field].tolist()\n",
    "            chunk = chunk.iloc[:,sim_indices]\n",
    "            chunks.append(chunk)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    train = pd.concat(chunks)\n",
    "    del(chunk)\n",
    "    del(chunks)\n",
    "\n",
    "    #create df for correlation and aucs on training data\n",
    "    individual_aucs_test = np.zeros(len(train.columns))\n",
    "\n",
    "    for i in range(train.shape[1]):\n",
    "\n",
    "        individual_aucs_test[i] = auc(labels, train.iloc[:,i].to_numpy())\n",
    "\n",
    "del(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 3\n",
    "model_aucs = pd.read_csv(f'{outputs_path}/gbc_res/model_aucs_{window}_ppm.csv')\n",
    "feature_attributes = pd.read_csv(f'{outputs_path}/gbc_res/model_attributes_{window}_ppm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all Models, Generate Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No regularization\n",
    "reload(figures)\n",
    "all_features = np.array(list(range(5)))\n",
    "figures.performance_attribution(model_aucs, feature_attributes, [['_']], ['all'], model = lr(), feature_indices=all_features, figure=True)\n",
    "\n",
    "#regularization\n",
    "figures.performance_attribution(model_aucs, feature_attributes, [['_']], ['all'], model = Ridge(alpha=5), feature_indices=all_features, figure=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance as we vary the number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures.performance_attribution(model_aucs.iloc[1:], feature_attributes.iloc[1:], [['all']], ['all'], feature_indices = [4], model = lr(), figure = True, title = 'Performance by Feature Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 'All' Indices specifically, does Reducing Correlation Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(figures)\n",
    "figures.performance_attribution(model_aucs.iloc[1:], feature_attributes.iloc[1:], [['3-all'],['5-all'],['10-all'],['15-all'],['20-all']], [3,5,10,15,20], feature_indices = [2], model = lr(), figure = True, title = 'Performance by Corr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within one Cleaning Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(figures)\n",
    "yool = figures.performance_attribution(model_aucs.iloc[1:], feature_attributes.iloc[1:], [[f'corr-3-{i}' for i in range(40)],[f'corr-5-{i}' for i in range(40)]], ['3 per setting','5 per setting'], feature_indices = [0,2], model = lr(), figure = True, title = 'Performance by Corr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairs and Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(figures)\n",
    "yool = figures.performance_attribution(model_aucs.iloc[1:], feature_attributes.iloc[1:], [['pair'],['triplet']], ['Pairs','Triplets'], feature_indices = [2], model = lr(), figure = True, title = 'Performance by Corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16dbaba10>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.linspace(0,1,100)\n",
    "b= -0.2 + 2*a**2\n",
    "plt.plot(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Functions to original metrics, evaluate how far off we are on test data with original normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Ideas:\n",
    "\n",
    "Accuracy (In order of increasing difficulty):\n",
    "\n",
    "-Incorporate as feature how many possible chem structures (can also restrict to NPS) exist within a certain precursor distance. (violating golden rules or not)\n",
    "\n",
    "-include original NIST version or theoretical res as feature\n",
    "\n",
    "-Weight different ranges of spec differently for matches (more diversity/greater accuracy)\n",
    "\n",
    "-smush together top n results over different inchicores and come up with combined model predicting over individual inchicores\n",
    "\n",
    "-diagnostic ion/loss classing as a feature...do they match\n",
    "\n",
    "-kernelized smooth match\n",
    "\n",
    "-3d struct guesses...do they match (cores, but can generalize to 3d)\n",
    "\n",
    "Speed(In order of increasing difficulty):\n",
    "\n",
    "-combine sim metrics and expand(apply func to df)\n",
    "\n",
    "-exclude matches based on non-similarity features to cut down on needed comparisons\n",
    "\n",
    "-ion tables to upper bound similarity\n",
    "\n",
    "-only use one peak consolidation and matching protocol...then only do reweight transformations on already matched peaks for spec and sim features\n",
    "\n",
    "-can missing peaks in lower energy be explained by frags and losses from higher energy? incorporate into model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order to proceed:\n",
    "\n",
    "-recreate databases with coll energy included (standardized format across DBs)\n",
    "\n",
    "-what proportion of matches are the same coll energy?\n",
    "\n",
    "-quantify variability in peak appearance vs peak intensity across collision energies\n",
    "    -does this relate in a predictable way to fragment mass\n",
    "\n",
    "-test sim metrics for same coll energy vs not same col energy (is the same inductive bias useful)\n",
    "\n",
    "-Show that regular funcs are in the space of combo distance\n",
    "\n",
    "-test combining individual metrics that use different components of the 2 vectors (add, mult, dif)\n",
    "\n",
    "-range over individual metrics in combined score in attempt to explain why combining them is successful\n",
    "\n",
    "-train combo metrics with flattened components and individual (should these sims be broken out?)\n",
    "    -should we do this for same coll energy vs dif energies\n",
    "\n",
    "-are different combo metrics put into larger model more successful than the combined individual metrics\n",
    "\n",
    "-can tunasims be fit with nonlinearities between the components (flattened or not?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
