{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from importlib import reload\n",
    "import os\n",
    "from collections import Counter\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import TunaSims\n",
    "import func_ob\n",
    "import tools\n",
    "import datasetBuilder\n",
    "import testUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for Different Ways of Distributing Interspectral Intensity Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=list()\n",
    "scores_1=list()\n",
    "scores_2=list()\n",
    "\n",
    "total_difference = 0.9\n",
    "len_difference = 10\n",
    "max_len = 25\n",
    "\n",
    "func1 = partial(TunaSims.tuna_dif_distance,e=1,f=-1,h=500, i=-3,j=2,k=-800)\n",
    "func2 = partial(TunaSims.tuna_dif_distance,e=1,f=-1,h=500,i=-3,j=2,k=-800)\n",
    "\n",
    "normalize = False\n",
    "\n",
    "for i in range(1,max_len):\n",
    "\n",
    "    xs.append(i)\n",
    "    dif_1 = np.array([1/(x+1) for x in range(i)])\n",
    "    dif_1 = dif_1/sum(dif_1)*total_difference\n",
    "\n",
    "    dif_2 = np.array([total_difference/i for x in range(i)])\n",
    "\n",
    "    if normalize:\n",
    "        scores_1.append(1- 1/func1(dif_1))\n",
    "        scores_2.append(1 - 1/func2(dif_2))\n",
    "    else:\n",
    "        scores_1.append(func1(dif_1, np.zeros(len(dif_1))))\n",
    "        scores_2.append(func2(dif_2, np.zeros(len(dif_2))))\n",
    "\n",
    "plt.plot(xs, scores_1, label='descending')\n",
    "plt.plot(xs, scores_2, label='unfiorm')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#databases\n",
    "outputs_path='/Users/jonahpoczobutt/projects/TunaRes/testy'\n",
    "nist14='/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist14_highres.pkl'\n",
    "nist20_prot_deprot = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist20_prot_deprot.pkl'\n",
    "nist23_hr_prot_deprot_only = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist23_prot_deprot_only.pkl'\n",
    "nist23_hr_full ='/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist23_full.pkl'\n",
    "gnps='/Users/jonahpoczobutt/projects/raw_data/db_csvs/gnps_highres.pkl'\n",
    "mona='/Users/jonahpoczobutt/projects/raw_data/db_csvs/mona_highres.pkl'\n",
    "metlin='/Users/jonahpoczobutt/projects/raw_data/db_csvs/metlin_highres_inst.pkl'\n",
    "mona_nist = '/Users/jonahpoczobutt/projects/raw_data/db_csvs/mona_nist_prot_only.pkl'\n",
    "\n",
    "self_search=False\n",
    "query = metlin\n",
    "target = nist23_hr_full\n",
    "if self_search:\n",
    "    target=query\n",
    "    \n",
    "fullRun=True\n",
    "if fullRun:\n",
    "    os.mkdir(outputs_path)\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs')\n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs/splitMatches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullRun=True\n",
    "if fullRun:\n",
    "\n",
    "    #This should be replaced with a function to read in all the databases\n",
    "    query_ = pd.read_pickle(query)\n",
    "    all_bases = list(set(query_['inchi_base']))\n",
    "\n",
    "    if self_search:\n",
    "        query_.insert(0,'queryID', [i for i in range(len(query_))])\n",
    "    else:\n",
    "        query_.insert(0,'queryID', [\"_\" for i in range(len(query_))])\n",
    "\n",
    "    #this method is in place\n",
    "    np.random.shuffle(all_bases)\n",
    "\n",
    "    first_bases = all_bases[:int(len(all_bases)*0.5)]\n",
    "    second_bases = all_bases[int(len(all_bases)*0.5):int(len(all_bases)*0.7)]\n",
    "    third_bases = all_bases[int(len(all_bases)*0.7):]\n",
    "\n",
    "    first_query_ = query_[np.isin(query_['inchi_base'],first_bases)]\n",
    "    first_query_.reset_index(inplace=True)\n",
    "    first_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/first_query.pkl')\n",
    "    del(first_query_)\n",
    "\n",
    "    second_query_ = query_[np.isin(query_['inchi_base'],second_bases)]\n",
    "    second_query_.reset_index(inplace=True)\n",
    "    second_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/second_query.pkl')\n",
    "    del(second_query_)\n",
    "\n",
    "    third_query_ = query_[np.isin(query_['inchi_base'],third_bases)]\n",
    "    third_query_.reset_index(inplace=True)\n",
    "    third_query_.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/third_query.pkl')\n",
    "    del(third_query_)\n",
    "    del(query_)\n",
    "\n",
    "    \n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/first_bases.npy',first_bases)\n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/second_bases.npy',second_bases)\n",
    "    np.save(f'{outputs_path}/intermediateOutputs/splitMatches/third_bases.npy',third_bases)\n",
    "    del(first_bases)\n",
    "    del(second_bases)\n",
    "    del(third_bases)\n",
    "    del(all_bases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarity methods and transformation parameters below. Leave sim methods as None to run all\n",
    "reload(datasetBuilder)\n",
    "reload(tools)\n",
    "\n",
    "ppm_windows = [10]\n",
    "\n",
    "noise_threshes=[0.01]\n",
    "centroid_tolerance_vals = [0.05]\n",
    "centroid_tolerance_types=['da']\n",
    "powers=['orig']\n",
    "sim_methods=['lorentzian','entropy','chi2','fidelity','dot_product','proportional_entropy']\n",
    "prec_removes=[True]\n",
    "\n",
    "\n",
    "train_size=3e6\n",
    "val_size=1e6\n",
    "test_size=2e6\n",
    "\n",
    "max_matches=None\n",
    "adduct_match = False\n",
    "\n",
    "target_=pd.read_pickle(target)\n",
    "\n",
    "if self_search:\n",
    "    target_.insert(0,'queryID', [i for i in range(len(target_))])\n",
    "else:\n",
    "    target_.insert(0,'queryID', [\"*\" for i in range(len(target_))])\n",
    "\n",
    "for i in ppm_windows:\n",
    "\n",
    "    #read in first bases and shuffle order\n",
    "    query_train = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/first_query.pkl')\n",
    "    query_train=query_train.sample(frac=1)\n",
    "\n",
    "    #create matches for model to train on\n",
    "    matches = datasetBuilder.create_matches_df(query_train,target_,i,max_matches,train_size, adduct_match)\n",
    "    matches.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_matches_{i}_ppm.pkl')\n",
    "    del(query_train)\n",
    "\n",
    "    \n",
    "    cleaned = datasetBuilder.create_cleaned_df(\n",
    "                                        matches, \n",
    "                                        sim_methods, \n",
    "                                        noise_threshes, \n",
    "                                        centroid_tolerance_vals, \n",
    "                                        centroid_tolerance_types,\n",
    "                                        powers,\n",
    "                                        prec_removes\n",
    "    )\n",
    "\n",
    "    cleaned.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/train_cleaned_matches_{i}_ppm.pkl')\n",
    "\n",
    "    sub_train=cleaned.iloc[:,:2]\n",
    "    sub_train.columns=['query','target']\n",
    "    sub_train['match']=cleaned['match']\n",
    "\n",
    "    #read in first bases and shuffle order\n",
    "    query_test = pd.read_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/third_query.pkl')\n",
    "    query_test=query_test.sample(frac=1)\n",
    "\n",
    "    #create matches for model to train on\n",
    "    matches = datasetBuilder.create_matches_df(query_test,target_,i,max_matches,test_size, adduct_match)\n",
    "    matches.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test_matches_{i}_ppm.pkl')\n",
    "    del(query_test)\n",
    "\n",
    "    \n",
    "    cleaned = datasetBuilder.create_cleaned_df(\n",
    "                                        matches, \n",
    "                                        sim_methods, \n",
    "                                        noise_threshes, \n",
    "                                        centroid_tolerance_vals, \n",
    "                                        centroid_tolerance_types,\n",
    "                                        powers,\n",
    "                                        prec_removes\n",
    "    )\n",
    "\n",
    "    cleaned.to_pickle(f'{outputs_path}/intermediateOutputs/splitMatches/test_cleaned_matches_{i}_ppm.pkl')\n",
    "\n",
    "    sub_test=cleaned.iloc[:,:2]\n",
    "    sub_test.columns=['query','target']\n",
    "    sub_test['match']=cleaned['match']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Func Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(func_ob)\n",
    "reload(TunaSims)\n",
    "#helper lambda funcs\n",
    "squared_loss = lambda x: x**2\n",
    "lin_loss = lambda x: x\n",
    "l1_reg = lambda l,x: l*sum(np.abs(x))\n",
    "l2_reg = lambda l,x: l*sum(x**2)\n",
    "no_reg = lambda x: 0\n",
    "\n",
    "params = {'all':[i for i in 'abcdefghijklmno'],\n",
    "          'tot_dis':['a','b'],\n",
    "          'ind_dis':['e','f'],\n",
    "          'tot+ind':['a','b','e','f'],\n",
    "          'tot+ind_int':['a','b','e','f','m'],\n",
    "          'tot+ind+len':['a','b','e','f','i','j','m','n','o'],\n",
    "          'tot_dis_k':['a','b','c','d'],\n",
    "          'ind_dis_k':['e','f','g','h'],\n",
    "          'tot+ind_k':['a','b','c','d','e','f','g','h'],\n",
    "          'tot+ind_int_k':['a','b','c','d','e','f','g','h','i','j','k','l'],\n",
    "          }\n",
    "\n",
    "reg_funcs = [partial(l1_reg,1),partial(l1_reg,.1),partial(l2_reg,1),partial(l2_reg,.1),no_reg]\n",
    "reg_names = ['l1_1','l1_0.1','l2_1','l2_0.1','none']\n",
    "losses = [squared_loss, lin_loss]\n",
    "loss_names = ['squared','l1']\n",
    "momentums = [None,'simple','jonie']\n",
    "mom_weights = [[0.8,0.2],[0.2,0.8]]\n",
    "lambdas = [0.01,0.1,1]\n",
    "max_iters = [1e3,1e4,1e5]\n",
    "\n",
    "funcs=testUtils.create_all_funcs_stoch(reg_funcs=reg_funcs,\n",
    "                                       reg_names=reg_names,\n",
    "                                       losses=losses,\n",
    "                                       loss_names=loss_names,\n",
    "                                       momentums=momentums,\n",
    "                                       mom_weights=mom_weights,\n",
    "                                       lambdas=lambdas,\n",
    "                                       max_iters=max_iters)\n",
    "\n",
    "print(f'number of specifications: {len(funcs)}')\n",
    "\n",
    "trained = list()\n",
    "sub_train = sub_train.sample(frac=1)\n",
    "\n",
    "for i in range(len(funcs)):\n",
    "    \n",
    "    funcs[i].fit(sub_train)\n",
    "    trained.append(funcs[i])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Train Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_metrics = ['entropy',\n",
    "             'proportional_entropy',\n",
    "             'lorentzian',\n",
    "             'dot_product',\n",
    "             'fidelity',\n",
    "             'proportional_manhattan',\n",
    "             'max_fidelity',\n",
    "             'matusita',\n",
    "             'proportional_lorentzian',\n",
    "             'chi2',\n",
    "             'laplacian',\n",
    "             'max_laplacian',\n",
    "             'harmonic_mean',\n",
    "             'bhattacharya_1',\n",
    "             'squared_chord',\n",
    "             'cross_ent'\n",
    "             ]\n",
    "\n",
    "small = testUtils.trained_res_to_df(trained[:len(trained)/3],sub_train.iloc[:max_iters[0]])\n",
    "small_metrics = testUtils.orig(comparison_metrics,sub_train.iloc[:max_iters[0]])\n",
    "\n",
    "medium = testUtils.trained_res_to_df(trained[:len(trained)/3],sub_train.iloc[:max_iters[1]])\n",
    "medium_metrics = testUtils.orig(comparison_metrics,sub_train.iloc[:max_iters[1]])\n",
    "\n",
    "large = testUtils.trained_res_to_df(trained[:len(trained)/3],sub_train.iloc[:max_iters[2]])\n",
    "large_metrics = testUtils.orig(comparison_metrics,sub_train.iloc[:max_iters[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test = testUtils.trained_res_to_df(trained[:len(trained)/3],sub_test.iloc[max_iters[2]:])\n",
    "small_test_metrics = testUtils.orig(comparison_metrics,sub_test.iloc[max_iters[2]:])\n",
    "\n",
    "medium_test = testUtils.trained_res_to_df(trained[:len(trained)/3],sub_test.iloc[max_iters[2]:])\n",
    "medium_test_metrics = testUtils.orig(comparison_metrics,sub_test.iloc[max_iters[2]:])\n",
    "\n",
    "large_test = testUtils.trained_res_to_df(trained[:len(trained)/3],sub_test.iloc[max_iters[2]:])\n",
    "large_test_metrics = testUtils.orig(comparison_metrics,sub_test.iloc[max_iters[2]:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions: \n",
    "\n",
    "num of params not appearing to change train time much\n",
    "\n",
    "consider replacing knockouts with sigmoids\n",
    "\n",
    "consider tuning final sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Ideas:\n",
    "\n",
    "Accuracy (In order of increasing difficulty):\n",
    "\n",
    "-Incorporate as feature how many possible chem structures (can also restrict to NPS) exist within a certain precursor distance. (violating golden rules or not)\n",
    "\n",
    "-include original NIST version or theoretical res as feature\n",
    "\n",
    "-Weight different ranges of spec differently for matches (more diversity/greater accuracy)\n",
    "\n",
    "-smush together top n results over different inchicores and come up with combined model predicting over individual inchicores\n",
    "\n",
    "-diagnostic ion/loss classing as a feature...do they match\n",
    "\n",
    "-kernelized smooth match\n",
    "\n",
    "-3d struct guesses...do they match (cores, but can generalize to 3d)\n",
    "\n",
    "Speed(In order of increasing difficulty):\n",
    "\n",
    "-combine sim metrics and expand(apply func to df)\n",
    "\n",
    "-exclude matches based on non-similarity features to cut down on needed comparisons\n",
    "\n",
    "-ion tables to upper bound similarity\n",
    "\n",
    "-only use one peak consolidation and matching protocol...then only do reweight transformations on already matched peaks for spec and sim features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
