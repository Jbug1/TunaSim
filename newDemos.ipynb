{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TunaSims\n",
    "import numpy as np\n",
    "from funcTrainer import specSimTrainer, scoreByQueryTrainer\n",
    "import pandas as pd\n",
    "import datasetBuilder\n",
    "import tools_fast\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as hgbc\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _weight_intensity_by_entropy(x):\n",
    "    WEIGHT_START = 0.25\n",
    "    ENTROPY_CUTOFF = 3\n",
    "    weight_slope = (1 - WEIGHT_START) / ENTROPY_CUTOFF\n",
    "\n",
    "    if np.sum(x) > 0:\n",
    "        entropy_x = scipy.stats.entropy(x)\n",
    "        if entropy_x < ENTROPY_CUTOFF:\n",
    "            weight = WEIGHT_START + weight_slope * entropy_x\n",
    "            x = np.power(x, weight)\n",
    "            x_sum = np.sum(x)\n",
    "            x = x / x_sum\n",
    "    return x\n",
    "\n",
    "def ppm(base, ppm):\n",
    "    \"\"\"\n",
    "    convert ppm threshold to dalton based on precursor exact mass (base)\n",
    "    \"\"\"\n",
    "\n",
    "    return base * (ppm / 1e6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_mean_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Harmonic mean distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        1-2\\sum(\\frac{P_{i}Q_{i}}{P_{i}+Q_{i}})\n",
    "    \"\"\"\n",
    "    p = _weight_intensity_by_entropy(p)\n",
    "    q = _weight_intensity_by_entropy(q)\n",
    "    return 2 * np.sum(p * q / (p + q))\n",
    "\n",
    "def lorentzian_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Lorentzian distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\sum{\\ln(1+|P_i-Q_i|)}\n",
    "    \"\"\"\n",
    "    p = _weight_intensity_by_entropy(p)\n",
    "    q = _weight_intensity_by_entropy(q)\n",
    "    return 1 - np.sum(np.log(1 + np.abs(p - q)))\n",
    "\n",
    "def matusita_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Matusita distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\sqrt{\\sum(\\sqrt{P_{i}}-\\sqrt{Q_{i}})^2}\n",
    "    \"\"\"\n",
    "    p = _weight_intensity_by_entropy(p)\n",
    "    q = _weight_intensity_by_entropy(q)\n",
    "    return 1- np.sum(np.power(np.sqrt(p) - np.sqrt(q), 2))\n",
    "\n",
    "def probabilistic_symmetric_chi_squared_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Probabilistic symmetric Ï‡2 distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\frac{1}{2} \\times \\sum\\frac{(P_{i}-Q_{i}\\ )^2}{P_{i}+Q_{i}\\ }\n",
    "    \"\"\"\n",
    "    p = _weight_intensity_by_entropy(p)\n",
    "    q = _weight_intensity_by_entropy(q)\n",
    "    return 1- (1 / 2 * np.sum(np.power(p - q, 2) / (p + q)))\n",
    "\n",
    "def entropy_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Unweighted entropy distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        -\\frac{2\\times S_{PQ}-S_P-S_Q} {ln(4)}, S_I=\\sum_{i} {I_i ln(I_i)}\n",
    "    \"\"\"\n",
    "    p = _weight_intensity_by_entropy(p)\n",
    "    q = _weight_intensity_by_entropy(q)\n",
    "    merged = p + q\n",
    "    entropy_increase = 2 * \\\n",
    "                       scipy.stats.entropy(merged) - scipy.stats.entropy(p) - \\\n",
    "                       scipy.stats.entropy(q)\n",
    "    \n",
    "    return 1 - entropy_increase\n",
    "\n",
    "def dot_product_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Dot product distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        1 - \\sqrt{\\frac{(\\sum{Q_iP_i})^2}{\\sum{Q_i^2\\sum P_i^2}}}\n",
    "    \"\"\"\n",
    "    p = _weight_intensity_by_entropy(p)\n",
    "    q = _weight_intensity_by_entropy(q)    \n",
    "    score = np.power(np.sum(q * p), 2) / (\n",
    "        np.sum(np.power(q, 2)) * np.sum(np.power(p, 2))\n",
    "    )\n",
    "    return np.sqrt(score)\n",
    "\n",
    "def sigmoid(z):\n",
    "    \n",
    "        return 1/(1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Matches DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_dataset = False\n",
    "if create_new_dataset:\n",
    "    \n",
    "    n_dfs = 3\n",
    "    set_names = ['train','val','test']\n",
    "    dataset_sizes = 2e6\n",
    "\n",
    "    input_df = pd.read_pickle('/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist20.pkl')\n",
    "    input_df.sort_values(by = 'inchi_base', inplace = True)\n",
    "    input_df['queryID'] = [i for i in range(len(input_df))]\n",
    "    print(len(input_df))\n",
    "    all_bases = list(set(input_df['inchi_base']))\n",
    "    print(len(all_bases))\n",
    "    np.random.shuffle(all_bases)\n",
    "\n",
    "    base_sets = list()\n",
    "    separated_dfs = list()\n",
    "    assigned_inds = list()\n",
    "\n",
    "    for i in range(n_dfs):\n",
    "        base_set = all_bases[int(i * len(all_bases)/n_dfs): int((i + 1) *len(all_bases)/n_dfs)]\n",
    "        base_sets.append(set(base_set))\n",
    "        assigned_inds.append(list())\n",
    "\n",
    "    for i in range(len(input_df)):\n",
    "\n",
    "        for j in range(len(base_sets)):\n",
    "\n",
    "            if input_df.iloc[i]['inchi_base'] in base_sets[j]:\n",
    "\n",
    "                assigned_inds[j].append(i)\n",
    "                break\n",
    "\n",
    "    for i in range(n_dfs):   \n",
    "        datasetBuilder.create_matches_df_chunk(input_df.iloc[assigned_inds[i]], \n",
    "                                                input_df.iloc[assigned_inds[i]],\n",
    "                                                10,\n",
    "                                                dataset_sizes,\n",
    "                                                dataset_sizes,\n",
    "                                                f'/Users/jonahpoczobutt/projects/TunaRes/NIST20_inputs/{set_names[i]}',\n",
    "                                                f'loggy.log')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create old similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_output_dir = '/Users/jonahpoczobutt/projects/TunaRes/oldSimRes'\n",
    "if create_new_dataset:\n",
    "\n",
    "     demo_matches = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/Nist20_inputs/train/chunk_1.pkl')\n",
    "     demo_matches_val = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/Nist20_inputs/val/chunk_1.pkl')\n",
    "\n",
    "     queries = list()\n",
    "     targets = list()\n",
    "     indices = list()\n",
    "     for i in range(len(demo_matches)):\n",
    "\n",
    "          query = demo_matches.iloc[i]['query'][demo_matches.iloc[i]['query'][:,0] < demo_matches.iloc[i]['precquery'] - ppm(demo_matches.iloc[i]['precquery'],3)]\n",
    "          target = demo_matches.iloc[i]['target'][demo_matches.iloc[i]['target'][:,0] < demo_matches.iloc[i]['prectarget'] - ppm(demo_matches.iloc[i]['prectarget'],3)]\n",
    "\n",
    "          if len(query) > 0 and len(target) > 0:\n",
    "               indices.append(i)\n",
    "               queries.append(query)\n",
    "               targets.append(target)\n",
    "\n",
    "     demo_matches = demo_matches.iloc[indices]\n",
    "     demo_matches['query'] = queries\n",
    "     demo_matches['target'] = targets\n",
    "\n",
    "     queries = list()\n",
    "     targets = list()\n",
    "     indices = list()\n",
    "     for i in range(len(demo_matches_val)):\n",
    "\n",
    "          query = demo_matches_val.iloc[i]['query'][demo_matches_val.iloc[i]['query'][:,0] < demo_matches_val.iloc[i]['precquery'] - ppm(demo_matches_val.iloc[i]['precquery'],3)]\n",
    "          target = demo_matches_val.iloc[i]['target'][demo_matches_val.iloc[i]['target'][:,0] < demo_matches_val.iloc[i]['prectarget'] - ppm(demo_matches_val.iloc[i]['prectarget'],3)]\n",
    "\n",
    "          if len(query) > 0 and len(target) > 0:\n",
    "               indices.append(i)\n",
    "               queries.append(query)\n",
    "               targets.append(target)\n",
    "\n",
    "     demo_matches_val = demo_matches_val.iloc[indices]\n",
    "     demo_matches_val['query'] = queries\n",
    "     demo_matches_val['target'] = targets\n",
    "\n",
    "     demo_matches.to_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_no_prec.pkl')\n",
    "     demo_matches_val.to_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_val_no_prec.pkl')\n",
    "\n",
    "     sim_names = ['prob','matusita','entropy','dot','lorentzian','harmonic']\n",
    "     distances = [probabilistic_symmetric_chi_squared_distance,\n",
    "               matusita_distance,\n",
    "               entropy_distance,\n",
    "               dot_product_distance,\n",
    "               lorentzian_distance,\n",
    "               harmonic_mean_distance]\n",
    "\n",
    "     for _ in range(len(sim_names)):\n",
    "\n",
    "          matched_scores_val = list()\n",
    "          for i in range(len(demo_matches_val)):\n",
    "          \n",
    "               matched = tools_fast.match_spectrum(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], ms2_da = 0.05)\n",
    "               matched_scores_val.append(sigmoid(distances[_](matched[:,1]/sum(matched[:,1]), matched[:,2]/sum(matched[:,2]))))\n",
    "\n",
    "          np.save(f'{sims_output_dir}/val_{sim_names[_]}.npy', np.array(matched_scores_val))\n",
    "\n",
    "          matched_scores = list()\n",
    "          for i in range(len(demo_matches)):\n",
    "\n",
    "               matched = tools_fast.match_spectrum(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'], ms2_da = 0.05)\n",
    "               matched_scores.append(sigmoid(distances[_](matched[:,1]/sum(matched[:,1]), matched[:,2]/sum(matched[:,2]))))\n",
    "\n",
    "          np.save(f'{sims_output_dir}/train_{sim_names[_]}.npy', np.array(matched_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "init_vals = {\n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'add_norm_b' : 1,\n",
    "    'target_intensity_a': 0.1,\n",
    "    'query_intensity_a': 0.1,\n",
    "    'target_intensity_b': 0.1,\n",
    "    'query_intensity_b': 0.1,\n",
    "    }\n",
    "\n",
    "init_vals_2 = {\n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'add_norm_b' : 1,\n",
    "    'target_normalized_intensity_int': 0,\n",
    "    'query_normalized_intensity_int': 0,\n",
    "    'target_normalized_intensity_a': 0.1,\n",
    "    'query_normalized_intensity_a': 0.1,\n",
    "    'target_normalized_intensity_b': 0.1,\n",
    "    'query_normalized_intensity_b': 0.1,\n",
    "    # 'target_normalized_intensity_c': 0.1,\n",
    "    # 'query_normalized_intensity_c': 0.1,\n",
    "    # 'target_mz_int': 1e-10,\n",
    "    # 'query_mz_int': 1e-10,\n",
    "    # 'target_mz_a': 0.001,\n",
    "    # 'query_mz_a': 0.001,\n",
    "    # 'target_mz_b': 0.001,\n",
    "    # 'query_mz_b': 0.001,\n",
    "    # 'target_mz_c': 0.001,\n",
    "    # 'query_mz_c': 0.001,\n",
    "    # 'target_intensity_int': 0,\n",
    "    # 'query_intensity_int': 0,\n",
    "    # 'target_intensity_a': 1,\n",
    "    # 'query_intensity_a': 1,\n",
    "    # 'target_intensity_b': 1,\n",
    "    # 'query_intensity_b': 1,\n",
    "    # 'target_intensity_c': 1,\n",
    "    # 'query_intensity_c': 1,\n",
    "    }\n",
    "\n",
    "init_vals_3 = {\n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'dif_add_norm_b' : 1,\n",
    "    'mult_add_norm_b' : 1,\n",
    "    # 'target_normalized_intensity_int': 0,\n",
    "    # 'query_normalized_intensity_int': 0,\n",
    "    'target_normalized_intensity_a': 1,\n",
    "    'query_normalized_intensity_a': 1,\n",
    "    'target_normalized_intensity_b': 1,\n",
    "    'query_normalized_intensity_b': 1,\n",
    "    # 'target_normalized_intensity_c': 0.1,\n",
    "    # 'query_normalized_intensity_c': 0.1,\n",
    "    # 'target_mz_int': 0,\n",
    "    # 'query_mz_int': 0,\n",
    "    # 'target_mz_a': 1,\n",
    "    # 'query_mz_a': 1,\n",
    "    # 'target_mz_b': 0.,\n",
    "    # 'query_mz_b': 0.,\n",
    "    # 'target_mz_c': 0.001,\n",
    "    # 'query_mz_c': 0.001,\n",
    "    # 'target_intensity_int': 0,\n",
    "    # 'query_intensity_int': 0,\n",
    "    # 'target_intensity_a': 1,\n",
    "    # 'query_intensity_a': 1,\n",
    "    # 'target_intensity_b': 1,\n",
    "    # 'query_intensity_b': 1,\n",
    "    # 'target_intensity_c': 1,\n",
    "    # 'query_intensity_c': 1,\n",
    "    }\n",
    "\n",
    "regularization_grad = lambda x: 0.\n",
    "\n",
    "fixed_vals = {'sigmoid_score' : True, \n",
    "              'weight_combine': 'multiply'\n",
    "    }\n",
    "\n",
    "fixed_vals = {}\n",
    "\n",
    "bounds = {'add_norm_b': (0, 2),\n",
    "          'mult_add_norm_b': (0, 2),\n",
    "          'dif_add_norm_b': (0, 2),\n",
    "          'mult_b': (1e-10, 2),\n",
    "          'add_norm_a': (1e-10, 3),\n",
    "          'dif_b': (1e-10, 2),\n",
    "          'dif_a':(-1.5,1.5),\n",
    "          'mult_a': (-1.5,1.5),\n",
    "          'target_normalized_intensity_int': (-0.2,1),\n",
    "          'query_normalized_intensity_int': (-0.2,1),\n",
    "          'target_normalized_intensity_a': (1e-10,2),\n",
    "          'query_normalized_intensity_a': (1e-10,2),\n",
    "          'target_normalized_intensity_b': (0,2),\n",
    "          'query_normalized_intensity_b': (0,2),\n",
    "          'target_normalized_intensity_c': (-2,2),\n",
    "          'query_normalized_intensity_c': (-2,2),\n",
    "          'target_mz_b': (-2,2),\n",
    "          'query_mz_b': (-2,2),\n",
    "          'target_mz_a': (-2,2),\n",
    "          'query_mz_a': (-2,2),\n",
    "          'target_mz_int': (-0.2,1),\n",
    "          'query_mz_int': (-0.2,1),\n",
    "          'target_mz_c': (-2,2),\n",
    "          'query_mz_c': (-2,2),\n",
    "           'target_intensity_int': (-0.2,1),\n",
    "           'query_intensity_int': (-0.2,1),\n",
    "          'target_intensity_a': (1e-10,2),\n",
    "          'query_intensity_a': (1e-10,2),\n",
    "          'target_intensity_b': (1e-10,2),\n",
    "          'query_intensity_b': (1e-10,2),\n",
    "          'target_intensity_c': (1e-10,2),\n",
    "          'query_intensity_c': (1e-10,2),\n",
    "          }\n",
    "\n",
    "\n",
    "init_names = ['intensity']\n",
    "inits = [init_vals]\n",
    "ad_params = [(0.98,0.025)]\n",
    "func_obs = list()\n",
    "\n",
    "for i in range(1):\n",
    "    for momentum in [None]:\n",
    "        for sched in [None]:\n",
    "            for i in range(len(inits)):\n",
    "                for ad_param in ad_params:\n",
    "                \n",
    "                    # func_obs.append(func_ob(f'{momentum}_{sched}_{init_names[i]}_{ad_param}',\n",
    "                    #             sim_func = TunaSims.ExpandedTuna,\n",
    "                    #             init_vals = inits[i].copy(),\n",
    "                    #             fixed_vals = fixed_vals,\n",
    "                    #             regularization_grad = regularization_grad,\n",
    "                    #             bounds = bounds,\n",
    "                    #             max_iter = 1e6,\n",
    "                    #             learning_rates = 0.001,\n",
    "                    #             momentum_type = momentum,\n",
    "                    #             learning_rate_scheduler = sched,\n",
    "                    #             learning_beta = 0.5,\n",
    "                    #             momentum_beta = 0.3,\n",
    "                    #             tol = 0,\n",
    "                    #             balance_classes = True,\n",
    "                    #             groupby_column = 'queryID_target_base',\n",
    "                    #             ad_int = ad_param[0],\n",
    "                    #             ad_slope= ad_param[1]))\n",
    "                    \n",
    "                    func_obs.append(specSimTrainer(f'{momentum}_{sched}_{init_names[i]}_{ad_param}',\n",
    "                                init_vals = inits[i].copy(),\n",
    "                                fixed_vals = fixed_vals,\n",
    "                                bounds = bounds,\n",
    "                                max_iter = 1e6,\n",
    "                                learning_rates = 0.005,\n",
    "                                learning_rate_scheduler = sched,\n",
    "                                learning_beta = 0.5,\n",
    "                                balance_column= 'score',\n",
    "                                groupby_column = 'queryID_target_base',\n",
    "                                ad_int = ad_param[0],\n",
    "                                ad_slope= ad_param[1]))\n",
    "                \n",
    "print(len(func_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m model_\u001b[38;5;241m.\u001b[39mmax_iter \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m     40\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 41\u001b[0m model_\u001b[38;5;241m.\u001b[39mfit(demo_matches)\n\u001b[1;32m     42\u001b[0m accumulated_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/TunaSim/funcTrainer.py:122\u001b[0m, in \u001b[0;36mfuncTrainer.fit\u001b[0;34m(self, train_data, verbose)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_zeros \u001b[38;5;241m=\u001b[39m counts[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_ones \u001b[38;5;241m=\u001b[39m counts[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstoch_descent(verbose)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrained_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_vals\n",
      "File \u001b[0;32m~/projects/TunaSim/funcTrainer.py:193\u001b[0m, in \u001b[0;36mfuncTrainer.stoch_descent\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    190\u001b[0m     score, pred_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_match_grad()\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     score, pred_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouped_match_grad()\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m#update with the score of choice and funcOb's loss function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(score, pred_val)    \n",
      "File \u001b[0;32m~/projects/TunaSim/funcTrainer.py:166\u001b[0m, in \u001b[0;36mfuncTrainer.grouped_match_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index()\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m#select only what we are interested in grouping\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m sub \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupby_column] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupby_column]]\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m#in the first round, we want to pick the index with the highest similarity scores\u001b[39;00m\n\u001b[1;32m    169\u001b[0m sims \u001b[38;5;241m=\u001b[39m sub\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim_func\u001b[38;5;241m.\u001b[39mpredict(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m], x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m], grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m), \n\u001b[1;32m    170\u001b[0m           axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m    171\u001b[0m           result_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39meq)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:5803\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5800\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   5801\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 5803\u001b[0m res_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   5805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:346\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 346\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:131\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "demo_matches = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_no_prec.pkl')\n",
    "\n",
    "\n",
    "demo_matches['score'] = 1 * demo_matches['InchiCoreMatch']\n",
    "demo_matches['queryID_target_base'] = [str(demo_matches.iloc[i]['queryID']) + '_' + demo_matches.iloc[i]['target_base'] for i in range(len(demo_matches))]\n",
    "\n",
    "train_auc_top = {i.name: list() for i in func_obs}\n",
    "val_auc_top = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_auc_all = {i.name: list() for i in func_obs}\n",
    "val_auc_all = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_times = {i.name: list() for i in func_obs}\n",
    "\n",
    "absolutes = [0, 1e4]\n",
    "offsets = [absolutes[i+1] - absolutes[i] for i in range(len(absolutes)-1)]\n",
    "\n",
    "reps = 1\n",
    "\n",
    "trained_obs = []\n",
    "\n",
    "for model in func_obs:\n",
    "\n",
    "    for _ in range(reps):\n",
    "\n",
    "        model_ = copy.deepcopy(model)\n",
    "\n",
    "        accumulated = 0\n",
    "        accumulated_time = 0\n",
    "        train_aucs_top = list()\n",
    "        val_aucs_top = list()\n",
    "        train_aucs_all = list()\n",
    "        val_aucs_all = list()\n",
    "        trained_obs_sub = list()\n",
    "\n",
    "        for i in offsets:\n",
    "            \n",
    "            model_.max_iter = i\n",
    "            \n",
    "            start = time.time()\n",
    "            model_.fit(demo_matches)\n",
    "            accumulated_time += time.time() - start\n",
    "\n",
    "            print('done training')\n",
    "\n",
    "            demo_matches_val = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_val_no_prec.pkl')\n",
    "            demo_matches_val['score'] = 1 * demo_matches_val['InchiCoreMatch']\n",
    "\n",
    "            demo_matches['preds'] = [model_.sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'], grads = False) for i in range(len(demo_matches))]\n",
    "            demo_matches_val['preds'] = [model_.sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches_val))]\n",
    "\n",
    "            # train_aucs_all.append(round(roc_auc_score(demo_matches['score'] , demo_matches['preds']), 4)) \n",
    "            # val_aucs_all.append(round(roc_auc_score(demo_matches_val['score'] , demo_matches_val['preds']),4))\n",
    "\n",
    "            temp = demo_matches.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "            temp_val = demo_matches_val.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "\n",
    "            train_aucs_top.append(round(roc_auc_score(temp['score'] , temp['preds']), 4)) \n",
    "            val_aucs_top.append(round(roc_auc_score(temp_val['score'] , temp_val['preds']),4))\n",
    "\n",
    "            accumulated += model_.max_iter\n",
    "\n",
    "        trained_obs_sub.append(copy.deepcopy(model_))\n",
    "        \n",
    "    trained_obs.append(trained_obs_sub)\n",
    "    train_times[model.name].append(round(accumulated_time/60, 4))\n",
    "    train_auc_all[model.name].append(train_aucs_all)\n",
    "    train_auc_top[model.name].append(train_aucs_top)\n",
    "    val_auc_all[model.name].append(val_aucs_all)\n",
    "    val_auc_top[model.name].append(val_aucs_top)\n",
    "\n",
    "    print(model.name)\n",
    "\n",
    "    model_1 = model_\n",
    "\n",
    "train_auc_top, val_auc_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(yool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m demo_matches[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [model_\u001b[38;5;241m.\u001b[39msim_func\u001b[38;5;241m.\u001b[39mpredict(demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m], demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m],demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecquery\u001b[39m\u001b[38;5;124m'\u001b[39m], demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprectarget\u001b[39m\u001b[38;5;124m'\u001b[39m], grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(demo_matches))]\n\u001b[1;32m      2\u001b[0m temp \u001b[38;5;241m=\u001b[39m demo_matches\u001b[38;5;241m.\u001b[39mgroupby(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueryID\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_base\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mmax\u001b[39m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m])]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m demo_matches[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [model_\u001b[38;5;241m.\u001b[39msim_func\u001b[38;5;241m.\u001b[39mpredict(demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m], demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m],demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecquery\u001b[39m\u001b[38;5;124m'\u001b[39m], demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprectarget\u001b[39m\u001b[38;5;124m'\u001b[39m], grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(demo_matches))]\n\u001b[1;32m      2\u001b[0m temp \u001b[38;5;241m=\u001b[39m demo_matches\u001b[38;5;241m.\u001b[39mgroupby(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueryID\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_base\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mmax\u001b[39m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m])]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1716\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3794\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3792\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced_from_mgr(new_mgr, axes\u001b[38;5;241m=\u001b[39mnew_mgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m-> 3794\u001b[0m result\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex[i]\n\u001b[1;32m   3795\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   3796\u001b[0m result\u001b[38;5;241m.\u001b[39m_set_is_copy(\u001b[38;5;28mself\u001b[39m, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5350\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5346\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   5347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex does not support mutable operations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 5350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5351\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5352\u001b[0m \u001b[38;5;124;03m    Override numpy.ndarray's __getitem__ method to work as desired.\u001b[39;00m\n\u001b[1;32m   5353\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5359\u001b[0m \n\u001b[1;32m   5360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   5361\u001b[0m     getitem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "demo_matches['preds'] = [model_.sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches))]\n",
    "temp = demo_matches.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4863"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mult_a -0.21695341221202163\n",
      "mult_b 0.9485074360920535\n",
      "dif_a -0.6125025601553813\n",
      "dif_b 0.5450995873645109\n",
      "add_norm_b 1.2880577121253958\n",
      "target_intensity_a 0.7842293416389545\n",
      "query_intensity_a 0.197052623956463\n",
      "target_intensity_b 0.49281132778952164\n",
      "query_intensity_b 1.0761041440627694\n"
     ]
    }
   ],
   "source": [
    "for i in model_.init_vals:\n",
    "\n",
    "    print(i, getattr(model_.sim_func, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/TunaRes/pickled_models/model_1.pickle', 'rb') as handle:\n",
    "\n",
    "    model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mult_a 0.9175589293724825\n",
      "mult_b 0.5187002432765382\n",
      "dif_a -1.2223835473295799\n",
      "dif_b 1.3383418856018803\n",
      "add_norm_b 0.5728447184049312\n",
      "target_normalized_intensity_a 1.0930801921557052\n",
      "query_normalized_intensity_a 1.1064697841074982\n",
      "target_normalized_intensity_b 0.46364712690275367\n",
      "query_normalized_intensity_b 0.39168090602160793\n"
     ]
    }
   ],
   "source": [
    "for i in model_.init_vals:\n",
    "\n",
    "    print(i, getattr(model, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.sim_func.nonzero_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.sim_func.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model_.sim_func.grads1.keys():\n",
    "    print(i, getattr(model_.sim_func,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TunaSims\n",
    "\n",
    "mer = TunaSims.ScoreByQuery(raw_scores_int = 0,\n",
    "                            raw_scores_a = 1,\n",
    "                            raw_scores_b = 1,\n",
    "                            dif_from_top_int = 0,\n",
    "                            dif_from_top_a = -1,\n",
    "                            dif_from_top_b = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funcOb\n",
    "import TunaSims\n",
    "\n",
    "inits = {'raw_scores_int' :0,\n",
    "        'raw_scores_a' : 1,\n",
    "        'raw_scores_b' : 1,\n",
    "        'dif_from_top_int' : 0,\n",
    "        'dif_from_top_a' : -1,\n",
    "        'dif_from_top_b' : 1}\n",
    "\n",
    "fixed_vals = {}\n",
    "\n",
    "a = funcOb.scoreByQueryFunc(name = 'testy',\n",
    "                            init_vals = inits,\n",
    "                            fixed_vals = fixed_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.dot(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([None, 1])\n",
    "(a == None).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot([1,2], [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mer.predict(scores = [0.9, 0.8, 0.5], match_names = ['a', 'b', 'c'], grads = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to add the object attributes back so that we ca properly adjust gradients...for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.sum([[1,2,3], [1,2,3]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.6,1,0,1])\n",
    "sort_order = np.argsort(-a)\n",
    "mask = (sort_order == 0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "\n",
    "np.sum([np.array([1,2,3]),np.array([4,5,6])], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[sort_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "np.prod(np.vstack((a[sort_order], mask,a)),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(temp['preds'], bins = 100)\n",
    "plt.title('Preds Train')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(temp_val['preds'], bins = 100)\n",
    "plt.title('Preds Val')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = np.array([0,1,0,0,0,0])\n",
    "\n",
    "\n",
    "#np.sum(np.trues - preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('function of remaining scores')\n",
    "print(np.concatenate((preds,[0])))\n",
    "print(np.max(preds) - np.concatenate((preds,[0])))\n",
    "\n",
    "print('then move through in reverse for scores above')\n",
    "print(np.concatenate((preds[::-1],[0])))\n",
    "print(np.concatenate((preds[::-1],[0])) - np.min(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([0.45,0.4,0.3])\n",
    "padded = np.concatenate(([1-preds[0]], preds))\n",
    "max_dif = (np.max(padded) - padded)\n",
    "prob_above = np.array([sum(padded[:i]) for i in range(len(padded))])\n",
    "print(padded)\n",
    "print(max_dif)\n",
    "print(prob_above)\n",
    "\n",
    "\n",
    "#should also have function of other scores summed after a non-linear transformation\n",
    "#array[not]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(['a',None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_none_prob(max_prob):\n",
    "    \"\"\" \n",
    "    probs must already be sorted from max to min and have\n",
    "    candidate names in corresponding order\n",
    "    \"\"\"\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab only inchicores where performance was bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['residual'] = np.abs(temp['score'] - temp['preds'])\n",
    "median_residual = np.median(temp['residual'])\n",
    "print(len(temp[temp['score'] == 1])/len(temp))\n",
    "\n",
    "pos = 0\n",
    "neg = 0\n",
    "bad_ids = list()\n",
    "for i in range(len(temp)):\n",
    "\n",
    "    if temp.iloc[i]['residual'] >= median_residual:\n",
    "        bad_ids.append(temp.iloc[i]['queryID_target_base'])\n",
    "\n",
    "        if temp.iloc[i]['score'] == 1:\n",
    "            pos+=1\n",
    "\n",
    "        else:\n",
    "            neg+=1\n",
    "\n",
    "bad_ids = set(bad_ids)\n",
    "\n",
    "residual_inds = list()\n",
    "\n",
    "for i in range(len(demo_matches)):\n",
    "\n",
    "    if demo_matches.iloc[i]['queryID_target_base'] in bad_ids:\n",
    "\n",
    "        residual_inds.append(i)\n",
    "\n",
    "demo_matches = demo_matches.iloc[residual_inds]\n",
    "print(len(demo_matches))\n",
    "print(len(bad_ids))\n",
    "print(pos / (pos + neg))\n",
    "\n",
    "train_auc_top = {i.name: list() for i in func_obs}\n",
    "val_auc_top = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_auc_all = {i.name: list() for i in func_obs}\n",
    "val_auc_all = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_times = {i.name: list() for i in func_obs}\n",
    "\n",
    "absolutes = [0,1e5]\n",
    "offsets = [absolutes[i+1] - absolutes[i] for i in range(len(absolutes)-1)]\n",
    "\n",
    "reps = 1\n",
    "\n",
    "trained_obs = []\n",
    "\n",
    "for model in func_obs:\n",
    "\n",
    "    for _ in range(reps):\n",
    "\n",
    "        model_ = copy.deepcopy(model)\n",
    "\n",
    "        accumulated = 0\n",
    "        accumulated_time = 0\n",
    "        train_aucs_top = list()\n",
    "        val_aucs_top = list()\n",
    "        train_aucs_all = list()\n",
    "        val_aucs_all = list()\n",
    "        trained_obs_sub = list()\n",
    "\n",
    "        for i in offsets:\n",
    "            \n",
    "            model_.max_iter = i\n",
    "            \n",
    "            start = time.time()\n",
    "            model_.fit(demo_matches)\n",
    "            accumulated_time += time.time() - start\n",
    "\n",
    "            demo_matches['preds'] = [model_.sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches))]\n",
    "            demo_matches_val['preds'] = [model_.sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches_val))]\n",
    "\n",
    "            train_aucs_all.append(round(roc_auc_score(demo_matches['score'] , demo_matches['preds']), 4)) \n",
    "            val_aucs_all.append(round(roc_auc_score(demo_matches_val['score'] , demo_matches_val['preds']),4))\n",
    "\n",
    "            temp = demo_matches.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "            temp_val = demo_matches_val.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "\n",
    "            train_aucs_top.append(round(roc_auc_score(temp['score'] , temp['preds']), 4)) \n",
    "            val_aucs_top.append(round(roc_auc_score(temp_val['score'] , temp_val['preds']),4))\n",
    "\n",
    "            accumulated += model_.max_iter\n",
    "\n",
    "        trained_obs_sub.append(copy.deepcopy(model_))\n",
    "        \n",
    "    trained_obs.append(trained_obs_sub)\n",
    "    train_times[model.name].append(round(accumulated_time/60, 4))\n",
    "    train_auc_all[model.name].append(train_aucs_all)\n",
    "    train_auc_top[model.name].append(train_aucs_top)\n",
    "    val_auc_all[model.name].append(val_aucs_all)\n",
    "    val_auc_top[model.name].append(val_aucs_top)\n",
    "\n",
    "    print(model.name)\n",
    "\n",
    "    model_2 = model_\n",
    "\n",
    "train_auc_top, val_auc_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['residual'] = np.abs(temp['score'] - temp['preds'])\n",
    "median_residual = np.median(temp['residual'])\n",
    "print(len(temp[temp['score'] == 1])/len(temp))\n",
    "print(median_residual)\n",
    "\n",
    "pos = 0\n",
    "neg = 0\n",
    "bad_ids = list()\n",
    "for i in range(len(temp)):\n",
    "\n",
    "    if temp.iloc[i]['residual'] >= median_residual:\n",
    "        bad_ids.append(temp.iloc[i]['queryID_target_base'])\n",
    "\n",
    "        if temp.iloc[i]['score'] == 1:\n",
    "            pos+=1\n",
    "\n",
    "        else:\n",
    "            neg+=1\n",
    "\n",
    "bad_ids = set(bad_ids)\n",
    "\n",
    "residual_inds = list()\n",
    "\n",
    "for i in range(len(demo_matches)):\n",
    "\n",
    "    if demo_matches.iloc[i]['queryID_target_base'] in bad_ids:\n",
    "\n",
    "        residual_inds.append(i)\n",
    "\n",
    "demo_matches = demo_matches.iloc[residual_inds]\n",
    "print(len(demo_matches))\n",
    "print(len(bad_ids))\n",
    "print(pos / (pos + neg))\n",
    "\n",
    "train_auc_top = {i.name: list() for i in func_obs}\n",
    "val_auc_top = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_auc_all = {i.name: list() for i in func_obs}\n",
    "val_auc_all = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_times = {i.name: list() for i in func_obs}\n",
    "\n",
    "absolutes = [0,1e5]\n",
    "offsets = [absolutes[i+1] - absolutes[i] for i in range(len(absolutes)-1)]\n",
    "\n",
    "reps = 1\n",
    "\n",
    "trained_obs = []\n",
    "\n",
    "for model in func_obs:\n",
    "\n",
    "    for _ in range(reps):\n",
    "\n",
    "        model_ = copy.deepcopy(model)\n",
    "\n",
    "        accumulated = 0\n",
    "        accumulated_time = 0\n",
    "        train_aucs_top = list()\n",
    "        val_aucs_top = list()\n",
    "        train_aucs_all = list()\n",
    "        val_aucs_all = list()\n",
    "        trained_obs_sub = list()\n",
    "\n",
    "        for i in offsets:\n",
    "            \n",
    "            model_.max_iter = i\n",
    "            \n",
    "            start = time.time()\n",
    "            model_.fit(demo_matches)\n",
    "            accumulated_time += time.time() - start\n",
    "\n",
    "            demo_matches['preds'] = [model_.sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches))]\n",
    "            demo_matches_val['preds'] = [model_.sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches_val))]\n",
    "\n",
    "            train_aucs_all.append(round(roc_auc_score(demo_matches['score'] , demo_matches['preds']), 4)) \n",
    "            val_aucs_all.append(round(roc_auc_score(demo_matches_val['score'] , demo_matches_val['preds']),4))\n",
    "\n",
    "            temp = demo_matches.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "            temp_val = demo_matches_val.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "\n",
    "            train_aucs_top.append(round(roc_auc_score(temp['score'] , temp['preds']), 4)) \n",
    "            val_aucs_top.append(round(roc_auc_score(temp_val['score'] , temp_val['preds']),4))\n",
    "\n",
    "            accumulated += model_.max_iter\n",
    "\n",
    "        trained_obs_sub.append(copy.deepcopy(model_))\n",
    "        \n",
    "    trained_obs.append(trained_obs_sub)\n",
    "    train_times[model.name].append(round(accumulated_time/60, 4))\n",
    "    train_auc_all[model.name].append(train_aucs_all)\n",
    "    train_auc_top[model.name].append(train_aucs_top)\n",
    "    val_auc_all[model.name].append(val_aucs_all)\n",
    "    val_auc_top[model.name].append(val_aucs_top)\n",
    "\n",
    "    print(model.name)\n",
    "\n",
    "    model_3 = model_\n",
    "\n",
    "train_auc_top, val_auc_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['residual'] = np.abs(temp['score'] - temp['preds'])\n",
    "median_residual = np.median(temp['residual'])\n",
    "print(len(temp[temp['score'] == 1])/len(temp))\n",
    "print(median_residual)\n",
    "\n",
    "pos = 0\n",
    "neg = 0\n",
    "bad_ids = list()\n",
    "for i in range(len(temp)):\n",
    "\n",
    "    if temp.iloc[i]['residual'] >= median_residual:\n",
    "        bad_ids.append(temp.iloc[i]['queryID_target_base'])\n",
    "\n",
    "        if temp.iloc[i]['score'] == 1:\n",
    "            pos+=1\n",
    "\n",
    "        else:\n",
    "            neg+=1\n",
    "\n",
    "bad_ids = set(bad_ids)\n",
    "\n",
    "residual_inds = list()\n",
    "\n",
    "for i in range(len(demo_matches)):\n",
    "\n",
    "    if demo_matches.iloc[i]['queryID_target_base'] in bad_ids:\n",
    "\n",
    "        residual_inds.append(i)\n",
    "\n",
    "demo_matches = demo_matches.iloc[residual_inds]\n",
    "print(len(demo_matches))\n",
    "print(len(bad_ids))\n",
    "print(pos / (pos + neg))\n",
    "\n",
    "train_auc_top = {i.name: list() for i in func_obs}\n",
    "val_auc_top = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_auc_all = {i.name: list() for i in func_obs}\n",
    "val_auc_all = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_times = {i.name: list() for i in func_obs}\n",
    "\n",
    "absolutes = [0,1e5]\n",
    "offsets = [absolutes[i+1] - absolutes[i] for i in range(len(absolutes)-1)]\n",
    "\n",
    "reps = 1\n",
    "\n",
    "trained_obs = []\n",
    "\n",
    "for model in func_obs:\n",
    "\n",
    "    for _ in range(reps):\n",
    "\n",
    "        model_ = copy.deepcopy(model)\n",
    "\n",
    "        accumulated = 0\n",
    "        accumulated_time = 0\n",
    "        train_aucs_top = list()\n",
    "        val_aucs_top = list()\n",
    "        train_aucs_all = list()\n",
    "        val_aucs_all = list()\n",
    "        trained_obs_sub = list()\n",
    "\n",
    "        for i in offsets:\n",
    "            \n",
    "            model_.max_iter = i\n",
    "            \n",
    "            start = time.time()\n",
    "            model_.fit(demo_matches)\n",
    "            accumulated_time += time.time() - start\n",
    "\n",
    "            demo_matches['preds'] = [model_.sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches))]\n",
    "            demo_matches_val['preds'] = [model_.sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches_val))]\n",
    "\n",
    "            train_aucs_all.append(round(roc_auc_score(demo_matches['score'] , demo_matches['preds']), 4)) \n",
    "            val_aucs_all.append(round(roc_auc_score(demo_matches_val['score'] , demo_matches_val['preds']),4))\n",
    "\n",
    "            temp = demo_matches.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "            temp_val = demo_matches_val.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "\n",
    "            train_aucs_top.append(round(roc_auc_score(temp['score'] , temp['preds']), 4)) \n",
    "            val_aucs_top.append(round(roc_auc_score(temp_val['score'] , temp_val['preds']),4))\n",
    "\n",
    "            accumulated += model_.max_iter\n",
    "\n",
    "        trained_obs_sub.append(copy.deepcopy(model_))\n",
    "        \n",
    "    trained_obs.append(trained_obs_sub)\n",
    "    train_times[model.name].append(round(accumulated_time/60, 4))\n",
    "    train_auc_all[model.name].append(train_aucs_all)\n",
    "    train_auc_top[model.name].append(train_aucs_top)\n",
    "    val_auc_all[model.name].append(val_aucs_all)\n",
    "    val_auc_top[model.name].append(val_aucs_top)\n",
    "\n",
    "    print(model.name)\n",
    "\n",
    "    model_4 = model_\n",
    "\n",
    "train_auc_top, val_auc_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_1, model_2, model_3, model_4]:\n",
    "\n",
    "    print('\\n')\n",
    "    for i in init_vals:\n",
    "        print(i, round(getattr(model.sim_func, i),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_matches = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_no_prec.pkl')\n",
    "\n",
    "all_scores_train = dict()\n",
    "all_scores_val = dict()\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4]\n",
    "mod_names = ['model_1', 'model_2', 'model_3', 'model_4']\n",
    "\n",
    "for _ in range(len(models)):\n",
    "\n",
    "    print(mod_names[_])\n",
    "\n",
    "    all_scores_train[mod_names[_]] = [models[_].sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches))]\n",
    "    \n",
    "all_scores_train['queryID'] = demo_matches['queryID'].tolist()\n",
    "all_scores_train['target_base'] = demo_matches['target_base'].tolist()\n",
    "all_scores_train['score'] = demo_matches['score'].tolist()\n",
    "\n",
    "del(demo_matches)\n",
    "\n",
    "demo_matches_val = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_val_no_prec.pkl')\n",
    "\n",
    "for _ in range(len(models)):\n",
    "\n",
    "    all_scores_val[mod_names[_]] = [models[_].sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches_val))]\n",
    "    print(mod_names[_])\n",
    "\n",
    "all_scores_val['queryID'] = demo_matches_val['queryID'].tolist()\n",
    "all_scores_val['target_base'] = demo_matches_val['target_base'].tolist()\n",
    "all_scores_val['score'] = demo_matches_val['score'].tolist()\n",
    "del(demo_matches_val)\n",
    "\n",
    "for sim in sim_names:\n",
    "\n",
    "    print(sim)\n",
    "\n",
    "    all_scores_train[sim] = np.load(f'{sims_output_dir}/train_{sim}.npy')\n",
    "    all_scores_val[sim] = np.load(f'{sims_output_dir}/val_{sim}.npy')\n",
    "\n",
    "all_scores_train = pd.DataFrame(all_scores_train)\n",
    "all_scores_val = pd.DataFrame(all_scores_val)\n",
    "\n",
    "all_scores_train.to_pickle('/Users/jonahpoczobutt/projects/TunaRes/sim_scores/train.pickle')\n",
    "all_scores_val.to_pickle('/Users/jonahpoczobutt/projects/TunaRes/sim_scores/val.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/sim_scores/train.pickle')\n",
    "val_data = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/sim_scores/val.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_scores_train = train_data.groupby(['queryID', 'target_base']).max()\n",
    "max_scores_val = val_data.groupby(['queryID', 'target_base']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in max_scores_train.columns[:-1]:\n",
    "\n",
    "    print(f\"{col}: train: {round(roc_auc_score(max_scores_train['score'], max_scores_train[col]),4)} val: {round(roc_auc_score(max_scores_val['score'], max_scores_val[col]),4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[:,:-3].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Train Models with Each Pair/Triplet of Sim Scores Old and New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create column groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_names = ['prob', 'matusita', 'entropy', 'dot', 'lorentzian', 'harmonic']\n",
    "\n",
    "old_sim_combos = list()\n",
    "for n in range(1,7):\n",
    "\n",
    "    for comb in combinations(sim_names, n):\n",
    "        old_sim_combos.append(list(comb))\n",
    "\n",
    "\n",
    "new_sim_combos = list()\n",
    "new_sims = ['model_1', 'model_2', 'model_3', 'model_4']\n",
    "for n in range(1,5):\n",
    "\n",
    "    for comb in combinations(new_sims, n):\n",
    "        new_sim_combos.append(list(comb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Models for each Column Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_performance_old = dict()\n",
    "\n",
    "trained = 0\n",
    "consolidated = True\n",
    "for combo in old_sim_combos:\n",
    "\n",
    "    model = hgbc()\n",
    "    if consolidated:\n",
    "        train = max_scores_train\n",
    "        val = max_scores_val\n",
    "\n",
    "    else:\n",
    "        train = train_data.copy()\n",
    "        val = val_data.copy()\n",
    "\n",
    "    model.fit(train[combo], train['score'])\n",
    "\n",
    "    if consolidated:\n",
    "\n",
    "        preds = model.predict_proba(train[combo])[:,1]\n",
    "        preds_val = model.predict_proba(val[combo])[:,1]\n",
    "\n",
    "    else:\n",
    "\n",
    "        train['preds'] = model.predict_proba(train[combo])[:,1]\n",
    "        val['preds'] = model.predict_proba(val[combo])[:,1]\n",
    "\n",
    "        train = train.groupby(['queryID', 'target_base']).max()\n",
    "        val = val.groupby(['queryID', 'target_base']).max()\n",
    "\n",
    "        preds = train['preds']\n",
    "        preds_val = val['preds']\n",
    "    \n",
    "    train_auc = roc_auc_score(train['score'], preds)\n",
    "    val_auc = roc_auc_score(val['score'], preds_val)\n",
    "\n",
    "    sim_performance_old['-'.join(combo)] = (train_auc, val_auc)\n",
    "\n",
    "    trained +=1\n",
    "    if trained % 10 == 0:\n",
    "        print(trained)\n",
    "\n",
    "sim_performance_new = dict()\n",
    "trained = 0\n",
    "for combo in new_sim_combos:\n",
    "\n",
    "    model = hgbc()\n",
    "    if consolidated:\n",
    "        train = max_scores_train\n",
    "        val = max_scores_val\n",
    "\n",
    "    else:\n",
    "        train = train_data.copy()\n",
    "        val = val_data.copy()\n",
    "\n",
    "    model.fit(train[combo], train['score'])\n",
    "\n",
    "    if consolidated:\n",
    "        \n",
    "        preds = model.predict_proba(train[combo])[:,1]\n",
    "        preds_val = model.predict_proba(val[combo])[:,1]\n",
    "\n",
    "    else:\n",
    "\n",
    "        train['preds'] = model.predict_proba(train[combo])[:,1]\n",
    "        val['preds'] = model.predict_proba(val[combo])[:,1]\n",
    "\n",
    "        train = train.groupby(['queryID', 'target_base']).max()\n",
    "        val = val.groupby(['queryID', 'target_base']).max()\n",
    "\n",
    "        preds = train['preds']\n",
    "        preds_val = val['preds']\n",
    "    \n",
    "    train_auc = roc_auc_score(train['score'], preds)\n",
    "    val_auc = roc_auc_score(val['score'], preds_val)\n",
    "\n",
    "    sim_performance_new['-'.join(combo)] = (train_auc, val_auc)\n",
    "\n",
    "    trained +=1\n",
    "    if trained % 10 == 0:\n",
    "        print(trained)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==1]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==1]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==2]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==2]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==3]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==3]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==4]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==4]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==5]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==5]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==6]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==1]), np.max([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==1]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==2]), np.max([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==2]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==3]), np.max([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==3]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==4]), np.max([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Val Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==1]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==1]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==2]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==2]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==3]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==3]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==4]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==4]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==5]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==5]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==6]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==1]), np.max([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==1]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==2]), np.max([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==2]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==3]), np.max([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==3]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==4]), np.max([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3,4,5]:\n",
    "\n",
    "    performances = [val[1] for key, val in sim_performance_old.items() if len(key.split('-')) == i]\n",
    "    keys = [key for key, val in sim_performance_old.items() if len(key.split('-')) == i]\n",
    "\n",
    "    max_key = keys[np.argmax(performances)]\n",
    "    print(i, max_key, round(sim_performance_old[max_key][0],4), round(sim_performance_old[max_key][1],4))\n",
    "\n",
    "print('\\n')\n",
    "for i in [1,2,3,4]:\n",
    "\n",
    "    performances = [val[1] for key, val in sim_performance_new.items() if len(key.split('-')) == i]\n",
    "    keys = [key for key, val in sim_performance_new.items() if len(key.split('-')) == i]\n",
    "\n",
    "    max_key = keys[np.argmax(performances)]\n",
    "    print(i, max_key, round(sim_performance_new[max_key][0],4), round(sim_performance_new[max_key][1],4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
