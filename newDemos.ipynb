{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TunaSims\n",
    "import numpy as np\n",
    "from funcOb import func_ob\n",
    "import pandas as pd\n",
    "import tools_fast\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as hgbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _weight_intensity_by_entropy(x):\n",
    "    WEIGHT_START = 0.25\n",
    "    ENTROPY_CUTOFF = 3\n",
    "    weight_slope = (1 - WEIGHT_START) / ENTROPY_CUTOFF\n",
    "\n",
    "    if np.sum(x) > 0:\n",
    "        entropy_x = scipy.stats.entropy(x)\n",
    "        if entropy_x < ENTROPY_CUTOFF:\n",
    "            weight = WEIGHT_START + weight_slope * entropy_x\n",
    "            x = np.power(x, weight)\n",
    "            x_sum = np.sum(x)\n",
    "            x = x / x_sum\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_mean_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Harmonic mean distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        1-2\\sum(\\frac{P_{i}Q_{i}}{P_{i}+Q_{i}})\n",
    "    \"\"\"\n",
    "\n",
    "    return 2 * np.sum(p * q / (p + q))\n",
    "\n",
    "def lorentzian_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Lorentzian distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\sum{\\ln(1+|P_i-Q_i|)}\n",
    "    \"\"\"\n",
    "\n",
    "    return 1 - np.sum(np.log(1 + np.abs(p - q)))\n",
    "\n",
    "def matusita_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Matusita distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\sqrt{\\sum(\\sqrt{P_{i}}-\\sqrt{Q_{i}})^2}\n",
    "    \"\"\"\n",
    "\n",
    "    return 1- np.sum(np.power(np.sqrt(p) - np.sqrt(q), 2))\n",
    "\n",
    "def probabilistic_symmetric_chi_squared_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Probabilistic symmetric Ï‡2 distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\frac{1}{2} \\times \\sum\\frac{(P_{i}-Q_{i}\\ )^2}{P_{i}+Q_{i}\\ }\n",
    "    \"\"\"\n",
    "\n",
    "    return 1- (1 / 2 * np.sum(np.power(p - q, 2) / (p + q)))\n",
    "\n",
    "def entropy_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Unweighted entropy distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        -\\frac{2\\times S_{PQ}-S_P-S_Q} {ln(4)}, S_I=\\sum_{i} {I_i ln(I_i)}\n",
    "    \"\"\"\n",
    "\n",
    "    merged = p + q\n",
    "    entropy_increase = 2 * \\\n",
    "                       scipy.stats.entropy(merged) - scipy.stats.entropy(p) - \\\n",
    "                       scipy.stats.entropy(q)\n",
    "    \n",
    "    return 1 - entropy_increase\n",
    "\n",
    "def dot_product_distance(p, q):\n",
    "    r\"\"\"\n",
    "    Dot product distance:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        1 - \\sqrt{\\frac{(\\sum{Q_iP_i})^2}{\\sum{Q_i^2\\sum P_i^2}}}\n",
    "    \"\"\"\n",
    "    \n",
    "    score = np.power(np.sum(q * p), 2) / (\n",
    "        np.sum(np.power(q, 2)) * np.sum(np.power(p, 2))\n",
    "    )\n",
    "    return np.sqrt(score)\n",
    "\n",
    "def sigmoid(z):\n",
    "    \n",
    "        return 1/(1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create old similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_output_dir = '/Users/jonahpoczobutt/projects/TunaRes/oldSimResUW'\n",
    "\n",
    "demo_matches = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/metlinGnps_NIST20_matchedPol/intermediateOutputs/splitMatches/train/10_ppm/chunk_1.pkl')\n",
    "demo_matches_val = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/metlinGnps_NIST20_matchedPol/intermediateOutputs/splitMatches/train/10_ppm/chunk_2.pkl')\n",
    "demo_matches['score'] = 1 * demo_matches['InchiCoreMatch']\n",
    "demo_matches_val['score'] = 1 * demo_matches_val['InchiCoreMatch']\n",
    "\n",
    "sim_names = ['prob','matusita','entropy','dot','lorentzian','harmonic']\n",
    "distances = [probabilistic_symmetric_chi_squared_distance,\n",
    "             matusita_distance,\n",
    "             entropy_distance,\n",
    "             dot_product_distance,\n",
    "             lorentzian_distance,\n",
    "             harmonic_mean_distance]\n",
    "\n",
    "# for _ in range(len(sim_names)):\n",
    "\n",
    "#      matched_scores_val = list()\n",
    "#      for i in range(len(demo_matches_val)):\n",
    "     \n",
    "#           matched = tools_fast.match_spectrum(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], ms2_da = 0.05)\n",
    "#           matched_scores_val.append(sigmoid(distances[_](matched[:,1]/sum(matched[:,1]), matched[:,2]/sum(matched[:,2]))))\n",
    "\n",
    "#      np.save(f'{sims_output_dir}/val_{sim_names[_]}.npy', np.array(matched_scores_val))\n",
    "\n",
    "#      matched_scores = list()\n",
    "#      for i in range(len(demo_matches)):\n",
    "\n",
    "#           matched = tools_fast.match_spectrum(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'], ms2_da = 0.05)\n",
    "#           matched_scores.append(sigmoid(distances[_](matched[:,1]/sum(matched[:,1]), matched[:,2]/sum(matched[:,2]))))\n",
    "\n",
    "#      np.save(f'{sims_output_dir}/train_{sim_names[_]}.npy', np.array(matched_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_vals = {\n",
    "    'mult_a' : 1,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 1,\n",
    "    'dif_b':1,\n",
    "    'add_norm_b' : 1,\n",
    "    # 'target_normalized_intensity_int': 0,\n",
    "    # 'query_normalized_intensity_int': 0,\n",
    "    'target_normalized_intensity_a': 1,\n",
    "    'query_normalized_intensity_a': 1,\n",
    "    'target_normalized_intensity_b': 1,\n",
    "    'query_normalized_intensity_b': 1,\n",
    "    'target_normalized_intensity_c': 1,\n",
    "    'query_normalized_intensity_c': 1,\n",
    "    # 'target_mz_int': 1e-10,\n",
    "    # 'query_mz_int': 1e-10,\n",
    "    'target_mz_a': 1,\n",
    "    'query_mz_a': 1,\n",
    "    'target_mz_b': 1,\n",
    "    'query_mz_b': 1,\n",
    "    'target_mz_c': 1,\n",
    "    'query_mz_c': 1,\n",
    "    # 'target_intensity_int': 0,\n",
    "    # 'query_intensity_int': 0,\n",
    "    # 'target_intensity_a': 1,\n",
    "    # 'query_intensity_a': 1,\n",
    "    # 'target_intensity_b': 1,\n",
    "    # 'query_intensity_b': 1,\n",
    "    # 'target_intensity_c': 1,\n",
    "    # 'query_intensity_c': 1,\n",
    "    }\n",
    "\n",
    "regularization_grad = lambda x: 0.\n",
    "\n",
    "fixed_vals = {'sigmoid_score' : True, \n",
    "              'weight_combine': 'multiply'\n",
    "    }\n",
    "\n",
    "bounds = {'add_norm_b': (0, 2),\n",
    "          'mult_b': (1e-10, 2),\n",
    "          'add_norm_a': (1e-10, 3),\n",
    "          'dif_b': (1e-10, 2),\n",
    "          'dif_a':(-1.5,1.5),\n",
    "          'mult_a': (-1.5,1.5),\n",
    "          'target_normalized_intensity_int': (-0.2,1),\n",
    "          'query_normalized_intensity_int': (-0.2,1),\n",
    "          'target_normalized_intensity_a': (-2,2),\n",
    "          'query_normalized_intensity_a': (-2,2),\n",
    "          'target_normalized_intensity_b': (-2,2),\n",
    "          'query_normalized_intensity_b': (-2,2),\n",
    "          'target_normalized_intensity_c': (-2,2),\n",
    "          'query_normalized_intensity_c': (-2,2),\n",
    "          'target_normalized_intensity_a': (-2,2),\n",
    "          'query_normalized_intensity_a': (-2,2),\n",
    "          'target_mz_b': (-2,2),\n",
    "          'query_mz_b': (-2,2),\n",
    "          'target_mz_a': (-2,2),\n",
    "          'query_mz_a': (-2,2),\n",
    "          'target_mz_int': (-0.2,1),\n",
    "          'query_mz_int': (-0.2,1),\n",
    "          'target_mz_c': (-2,2),\n",
    "          'query_mz_c': (-2,2),\n",
    "           'target_intensity_int': (-0.2,1),\n",
    "           'query_intensity_int': (-0.2,1),\n",
    "          'target_intensity_a': (1e-10,2),\n",
    "          'query_intensity_a': (1e-10,2),\n",
    "          'target_intensity_b': (1e-10,2),\n",
    "          'query_intensity_b': (1e-10,2),\n",
    "          'target_intensity_c': (1e-10,2),\n",
    "          'query_intensity_c': (1e-10,2),\n",
    "          }\n",
    "\n",
    "testerooni = func_ob('teesterooni',\n",
    "                     sim_func = TunaSims.ExpandedTuna,\n",
    "                     init_vals = init_vals,\n",
    "                     fixed_vals = fixed_vals,\n",
    "                     regularization_grad = regularization_grad,\n",
    "                     bounds = bounds,\n",
    "                     max_iter = 300000,\n",
    "                     lambdas = 0.001,\n",
    "                     tol = 0,\n",
    "                     balance_classes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained values\n",
      "mult_a 1\n",
      "mult_b 1\n",
      "dif_a 1\n",
      "dif_b 1\n",
      "add_norm_b 1\n",
      "target_normalized_intensity_a 1\n",
      "query_normalized_intensity_a 1\n",
      "target_normalized_intensity_b 1\n",
      "query_normalized_intensity_b 1\n",
      "target_normalized_intensity_c 1\n",
      "query_normalized_intensity_c 1\n",
      "target_mz_a 1\n",
      "query_mz_a 1\n",
      "target_mz_b 1\n",
      "query_mz_b 1\n",
      "target_mz_c 1\n",
      "query_mz_c 1\n"
     ]
    }
   ],
   "source": [
    "print('trained values')\n",
    "for i in testerooni.init_vals.keys():\n",
    "    print(i, getattr(testerooni.sim_func,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'updated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mround \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     testerooni\u001b[38;5;241m.\u001b[39mfit(demo_matches, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e5\u001b[39m)\n\u001b[1;32m      5\u001b[0m     preds \u001b[38;5;241m=\u001b[39m [testerooni\u001b[38;5;241m.\u001b[39msim_func\u001b[38;5;241m.\u001b[39mpredict(demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m], demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m],demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecquery\u001b[39m\u001b[38;5;124m'\u001b[39m], demo_matches\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprectarget\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(demo_matches))]\n\u001b[1;32m      6\u001b[0m     preds_val \u001b[38;5;241m=\u001b[39m [testerooni\u001b[38;5;241m.\u001b[39msim_func\u001b[38;5;241m.\u001b[39mpredict(demo_matches_val\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m], demo_matches_val\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m], demo_matches_val\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecquery\u001b[39m\u001b[38;5;124m'\u001b[39m], demo_matches_val\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprectarget\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(demo_matches_val))]\n",
      "File \u001b[0;32m~/projects/TunaSim/funcOb.py:119\u001b[0m, in \u001b[0;36mfunc_ob.fit\u001b[0;34m(self, train_data, verbose)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_grad_start\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstoch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstoch_descent(train_data, verbose)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscipy_solver_estimate(train_data)\n",
      "File \u001b[0;32m~/projects/TunaSim/funcOb.py:174\u001b[0m, in \u001b[0;36mfunc_ob.stoch_descent\u001b[0;34m(self, train_data, verbose)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim_func\u001b[38;5;241m.\u001b[39mpredict(train_data\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m    166\u001b[0m                                       train_data\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m    167\u001b[0m                                       train_data\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecquery\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m    168\u001b[0m                                       train_data\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprectarget\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# if abs(train_data.iloc[index]['score'] - self.pred_val) > 0.5:\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m#      print(index, train_data.iloc[index]['score'], self.pred_val, self.sim_func.mult_a, self.sim_func.add_norm_b)\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m#update with the score of choice and funcOb's loss function\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(train_data\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_val, i)    \n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m#update object based on results\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/projects/TunaSim/funcOb.py:250\u001b[0m, in \u001b[0;36mfunc_ob.step\u001b[0;34m(self, score, pred_val, i)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds:\n\u001b[1;32m    249\u001b[0m         bounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds[key]\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim_func, key, \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(bounds[\u001b[38;5;241m0\u001b[39m], updated), bounds[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim_func, key, updated)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'updated' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "\n",
    "    print(f'round {i+1}')\n",
    "    testerooni.fit(demo_matches, verbose = 1e5)\n",
    "    preds = [testerooni.sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget']) for i in range(len(demo_matches))]\n",
    "    preds_val = [testerooni.sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget']) for i in range(len(demo_matches_val))]\n",
    "\n",
    "    print(round(roc_auc_score(demo_matches['score'] , np.array(preds)), 4), round(roc_auc_score(demo_matches_val['score'] , np.array(preds_val)), 4))\n",
    "    print('\\n') \n",
    "\n",
    "print('trained values')\n",
    "for i in testerooni.init_vals.keys():\n",
    "    print(i, getattr(testerooni.sim_func,i))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('aucs')\n",
    "print(round(roc_auc_score(demo_matches['score'] , np.array(preds)), 4), round(roc_auc_score(demo_matches_val['score'] , np.array(preds_val)), 4))\n",
    "\n",
    "for sim in sim_names:\n",
    "    print(sim, round(roc_auc_score(demo_matches['score'], np.load(f'{sims_output_dir}/train_{sim}.npy')),4), round(roc_auc_score(demo_matches_val['score'], np.load(f'{sims_output_dir}/val_{sim}.npy')),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(preds, bins = 100)\n",
    "plt.title('Preds Train')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(preds_val, bins = 100)\n",
    "plt.title('Preds Val')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels_train = demo_matches['score']\n",
    "original_labels_val = demo_matches_val['score']\n",
    "#maintain mapping to 0 1 interval\n",
    "demo_matches['score'] = (demo_matches['score'] - preds + 1) / 2\n",
    "plt.hist(demo_matches['score'], bins = 100)\n",
    "plt.title('train_residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testerooni = func_ob('teesterooni',\n",
    "                     sim_func = TunaSims.ExpandedTuna,\n",
    "                     init_vals = init_vals,\n",
    "                     fixed_vals = fixed_vals,\n",
    "                     regularization_grad = regularization_grad,\n",
    "                     bounds = bounds,\n",
    "                     max_iter = 1000000,\n",
    "                     lambdas = 0.001,\n",
    "                     tol = 0,\n",
    "                     balance_classes = False)\n",
    "\n",
    "testerooni.fit(demo_matches, verbose = 1e7)\n",
    "print(testerooni.converged)\n",
    "\n",
    "\n",
    "preds_2 = np.array([testerooni.sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget']) for i in range(len(demo_matches))])\n",
    "preds_val_2 = np.array([testerooni.sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget']) for i in range(len(demo_matches_val))])\n",
    "\n",
    "plt.hist(preds_2, bins = 100)\n",
    "plt.title('Train Preds 2')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(preds_2, bins = 100)\n",
    "plt.title('Val Preds 2')\n",
    "plt.show()\n",
    "\n",
    "print('trained values')\n",
    "for i in testerooni.init_vals.keys():\n",
    "    print(i, getattr(testerooni.sim_func,i))\n",
    "\n",
    "preds_combined = preds + (2 * preds_2 - 1)\n",
    "preds_combined_val = preds_val + (2 * preds_val_2 - 1)\n",
    "\n",
    "plt.hist((1 + original_labels_train - preds_combined) / 2, bins = 100)\n",
    "plt.title('Two Stage Train Residuals')\n",
    "plt.show()\n",
    "\n",
    "plt.hist((1 + original_labels_val - preds_combined_val) / 2, bins = 100)\n",
    "plt.title('Two Stage Val Residuals')\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n",
    "print('aucs')\n",
    "print(round(roc_auc_score(original_labels_train , preds_combined), 4), round(roc_auc_score(original_labels_val, preds_combined_val), 4))\n",
    "for sim in sim_names:\n",
    "    print(sim, round(roc_auc_score(original_labels_train, np.load(f'{sims_output_dir}/train_{sim}.npy')),4), round(roc_auc_score(original_labels_val, np.load(f'{sims_output_dir}/val_{sim}.npy')),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#maintain mapping to 0 1 interval\n",
    "demo_matches['score'] = (demo_matches['score'] - preds_combined + 1) / 2\n",
    "plt.hist(demo_matches['score'], bins = 100)\n",
    "plt.title('train_residuals')\n",
    "plt.show()\n",
    "\n",
    "testerooni = func_ob('teesterooni',\n",
    "                     sim_func = TunaSims.ExpandedTuna,\n",
    "                     init_vals = init_vals,\n",
    "                     fixed_vals = fixed_vals,\n",
    "                     regularization_grad = regularization_grad,\n",
    "                     bounds = bounds,\n",
    "                     max_iter = 1000000,\n",
    "                     lambdas = 0.001,\n",
    "                     tol = 0,\n",
    "                     balance_classes = False)\n",
    "\n",
    "testerooni.fit(demo_matches, verbose = 100000)\n",
    "print(testerooni.converged)\n",
    "\n",
    "\n",
    "preds_3 = np.array([testerooni.sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget']) for i in range(len(demo_matches))])\n",
    "preds_val_3 = np.array([testerooni.sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget']) for i in range(len(demo_matches_val))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores_train = dict()\n",
    "all_scores_val = dict()\n",
    "\n",
    "for sim in sim_names:\n",
    "\n",
    "    all_scores_train[sim] = np.load(f'{sims_output_dir}/train_{sim}.npy')\n",
    "    all_scores_val[sim] = np.load(f'{sims_output_dir}/val_{sim}.npy')\n",
    "\n",
    "all_scores_train['preds'] = preds\n",
    "all_scores_val['preds'] = preds_val\n",
    "\n",
    "all_scores_train['preds2'] = preds_2\n",
    "all_scores_val['preds2'] = preds_val_2\n",
    "\n",
    "all_scores_train['preds3'] = preds_3\n",
    "all_scores_val['preds3'] = preds_val_3\n",
    "\n",
    "all_scores_train['score'] = original_labels_train\n",
    "all_scores_val['score'] = original_labels_val\n",
    "\n",
    "train_data = pd.DataFrame(all_scores_train)\n",
    "val_data = pd.DataFrame(all_scores_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Val Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Train Models with Each Pair/Triplet of Sim Scores Old and New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create column groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_sim_combos = list()\n",
    "for sim1 in sim_names:\n",
    "    for sim2 in sim_names:\n",
    "        for sim3 in sim_names:\n",
    "\n",
    "            old_sim_combos.append(list(set([sim1, sim2, sim3])))\n",
    "\n",
    "new_sim_combos = list()\n",
    "new_sims = ['preds', 'preds2', 'preds3']\n",
    "for sim1 in new_sims:\n",
    "    for sim2 in new_sims:\n",
    "        for sim3 in new_sims:  \n",
    "\n",
    "            new_sim_combos.append(list(set([sim1, sim2, sim3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Models for each Column Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_performance = dict()\n",
    "\n",
    "for combo in old_sim_combos:\n",
    "\n",
    "    print(combo)\n",
    "\n",
    "    model = hgbc()\n",
    "    model.fit(train_data[combo], train_data['score'])\n",
    "    train_auc = roc_auc_score(original_labels_train, model.predict_proba(train_data[combo])[:,1])\n",
    "    val_auc = roc_auc_score(original_labels_val, model.predict_proba(val_data[combo])[:,1])\n",
    "\n",
    "    sim_performance['_'.join(combo)] = (train_auc, val_auc)\n",
    "\n",
    "sim_performance_new = dict()\n",
    "for combo in new_sim_combos:\n",
    "\n",
    "    print(combo)\n",
    "\n",
    "    model = hgbc()\n",
    "    model.fit(train_data[combo], train_data['score'])\n",
    "    train_auc = roc_auc_score(original_labels_train, model.predict_proba(train_data[combo])[:,1])\n",
    "    val_auc = roc_auc_score(original_labels_val, model.predict_proba(val_data[combo])[:,1])\n",
    "\n",
    "    sim_performance_new['_'.join(combo)] = (train_auc, val_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([val[1] for key, val in sim_performance.items() if len(key.split('_'))==1]))\n",
    "print(np.mean([val[1] for key, val in sim_performance.items() if len(key.split('_'))==2]))\n",
    "print(np.mean([val[1] for key, val in sim_performance.items() if len(key.split('_'))==3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([val[1] for key, val in sim_performance_new.items() if len(key.split('_'))==1 and 'preds' in key]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_new.items() if len(key.split('_'))==2 and 'preds' in key]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_new.items() if len(key.split('_'))==3 and 'preds' in key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_performance_2 = dict()\n",
    "for combo in new_sim_combos:\n",
    "\n",
    "    if 'preds' not in combo:\n",
    "        continue\n",
    "\n",
    "    for sim in sim_names:\n",
    "\n",
    "        combo_new = combo + [sim]\n",
    "\n",
    "        model = hgbc()\n",
    "        model.fit(train_data[combo_new], train_data['score'])\n",
    "        train_auc = roc_auc_score(original_labels_train, model.predict_proba(train_data[combo_new])[:,1])\n",
    "        val_auc = roc_auc_score(original_labels_val, model.predict_proba(val_data[combo_new])[:,1])\n",
    "\n",
    "        sim_performance_2['_'.join(combo_new)] = (train_auc, val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([val[1] for key, val in sim_performance_2.items() if len(key.split('_'))==2]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_2.items() if len(key.split('_'))==3]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
