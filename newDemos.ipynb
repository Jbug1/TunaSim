{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TunaSims\n",
    "import numpy as np\n",
    "from funcTrainer import specSimTrainer\n",
    "\n",
    "#import datasetBuilder\n",
    "import tools_fast\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as hgbc\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.DataFrame([[1,2,3],[4,5,6]])\n",
    "a[['a','b']] = [[5,'a'],[5,'a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nist_input = pd.read_pickle('/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist23_full.pkl')\n",
    "metlin = pd.read_pickle('/Users/jonahpoczobutt/projects/raw_data/db_csvs/metlin.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "metlin_ids = set(metlin['inchi_base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13490"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metlin_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_bases = pd.read_pickle('/Users/jonahpoczobutt/projects/raw_data/db_csvs/metlin_gnps.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>precursor_type</th>\n",
       "      <th>n_peaks</th>\n",
       "      <th>precursor</th>\n",
       "      <th>inchi</th>\n",
       "      <th>inchi_base</th>\n",
       "      <th>instrument</th>\n",
       "      <th>collision_energy</th>\n",
       "      <th>spectrum</th>\n",
       "      <th>mode</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>[M+Na]+</td>\n",
       "      <td>88</td>\n",
       "      <td>360.069</td>\n",
       "      <td>ZWIHLCKHOMJFNY-SNAWJCMRSA-N</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>HCD</td>\n",
       "      <td>54</td>\n",
       "      <td>[[53.0387, 9.4], [55.018, 24.5], [55.0544, 40....</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>[M+Na]+</td>\n",
       "      <td>92</td>\n",
       "      <td>360.069</td>\n",
       "      <td>ZWIHLCKHOMJFNY-SNAWJCMRSA-N</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>HCD</td>\n",
       "      <td>62</td>\n",
       "      <td>[[51.0231, 15.4], [53.0023, 15.9], [53.0387, 4...</td>\n",
       "      <td>+</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>[M+Na]+</td>\n",
       "      <td>76</td>\n",
       "      <td>360.069</td>\n",
       "      <td>ZWIHLCKHOMJFNY-SNAWJCMRSA-N</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>HCD</td>\n",
       "      <td>71</td>\n",
       "      <td>[[51.0231, 79.3], [53.0024, 42.4], [53.0387, 6...</td>\n",
       "      <td>+</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>[M+Na]+</td>\n",
       "      <td>80</td>\n",
       "      <td>360.069</td>\n",
       "      <td>ZWIHLCKHOMJFNY-SNAWJCMRSA-N</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>HCD</td>\n",
       "      <td>79</td>\n",
       "      <td>[[51.023, 143.3], [53.0023, 44.8], [53.0387, 9...</td>\n",
       "      <td>+</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>[M+Na]+</td>\n",
       "      <td>70</td>\n",
       "      <td>360.069</td>\n",
       "      <td>ZWIHLCKHOMJFNY-SNAWJCMRSA-N</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>HCD</td>\n",
       "      <td>90</td>\n",
       "      <td>[[50.0153, 34.2], [51.023, 237.1], [52.0309, 1...</td>\n",
       "      <td>+</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048554</th>\n",
       "      <td></td>\n",
       "      <td>[M+Na]+</td>\n",
       "      <td>19</td>\n",
       "      <td>360.069</td>\n",
       "      <td>ZWIHLCKHOMJFNY-SNAWJCMRSA-N</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>HCD</td>\n",
       "      <td>16</td>\n",
       "      <td>[[86.0966, 8.4], [87.1001, 2.5], [116.0708, 21...</td>\n",
       "      <td>+</td>\n",
       "      <td>1820925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048555</th>\n",
       "      <td></td>\n",
       "      <td>[M+Na]+</td>\n",
       "      <td>30</td>\n",
       "      <td>360.069</td>\n",
       "      <td>ZWIHLCKHOMJFNY-SNAWJCMRSA-N</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>HCD</td>\n",
       "      <td>21</td>\n",
       "      <td>[[70.0653, 5.8], [72.081, 3.6], [86.0966, 50.1...</td>\n",
       "      <td>+</td>\n",
       "      <td>1820926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048556</th>\n",
       "      <td></td>\n",
       "      <td>[M+Na]+</td>\n",
       "      <td>49</td>\n",
       "      <td>360.069</td>\n",
       "      <td>ZWIHLCKHOMJFNY-SNAWJCMRSA-N</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>HCD</td>\n",
       "      <td>26</td>\n",
       "      <td>[[70.0654, 79.9], [72.081, 55.6], [79.0215, 16...</td>\n",
       "      <td>+</td>\n",
       "      <td>1820927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048557</th>\n",
       "      <td></td>\n",
       "      <td>[M+Na]+</td>\n",
       "      <td>57</td>\n",
       "      <td>360.069</td>\n",
       "      <td>ZWIHLCKHOMJFNY-SNAWJCMRSA-N</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>HCD</td>\n",
       "      <td>32</td>\n",
       "      <td>[[57.07, 13.1], [69.0701, 19.4], [70.0653, 125...</td>\n",
       "      <td>+</td>\n",
       "      <td>1820928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048558</th>\n",
       "      <td></td>\n",
       "      <td>[M+Na]+</td>\n",
       "      <td>68</td>\n",
       "      <td>360.069</td>\n",
       "      <td>ZWIHLCKHOMJFNY-SNAWJCMRSA-N</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>HCD</td>\n",
       "      <td>38</td>\n",
       "      <td>[[55.0544, 18.0], [57.0701, 13.2], [67.0544, 7...</td>\n",
       "      <td>+</td>\n",
       "      <td>1820929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1820930 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        name precursor_type  n_peaks  precursor                        inchi  \\\n",
       "0                   [M+Na]+       88    360.069  ZWIHLCKHOMJFNY-SNAWJCMRSA-N   \n",
       "1                   [M+Na]+       92    360.069  ZWIHLCKHOMJFNY-SNAWJCMRSA-N   \n",
       "2                   [M+Na]+       76    360.069  ZWIHLCKHOMJFNY-SNAWJCMRSA-N   \n",
       "3                   [M+Na]+       80    360.069  ZWIHLCKHOMJFNY-SNAWJCMRSA-N   \n",
       "4                   [M+Na]+       70    360.069  ZWIHLCKHOMJFNY-SNAWJCMRSA-N   \n",
       "...      ...            ...      ...        ...                          ...   \n",
       "1048554             [M+Na]+       19    360.069  ZWIHLCKHOMJFNY-SNAWJCMRSA-N   \n",
       "1048555             [M+Na]+       30    360.069  ZWIHLCKHOMJFNY-SNAWJCMRSA-N   \n",
       "1048556             [M+Na]+       49    360.069  ZWIHLCKHOMJFNY-SNAWJCMRSA-N   \n",
       "1048557             [M+Na]+       57    360.069  ZWIHLCKHOMJFNY-SNAWJCMRSA-N   \n",
       "1048558             [M+Na]+       68    360.069  ZWIHLCKHOMJFNY-SNAWJCMRSA-N   \n",
       "\n",
       "             inchi_base instrument  collision_energy  \\\n",
       "0        ZWIHLCKHOMJFNY        HCD                54   \n",
       "1        ZWIHLCKHOMJFNY        HCD                62   \n",
       "2        ZWIHLCKHOMJFNY        HCD                71   \n",
       "3        ZWIHLCKHOMJFNY        HCD                79   \n",
       "4        ZWIHLCKHOMJFNY        HCD                90   \n",
       "...                 ...        ...               ...   \n",
       "1048554  ZWIHLCKHOMJFNY        HCD                16   \n",
       "1048555  ZWIHLCKHOMJFNY        HCD                21   \n",
       "1048556  ZWIHLCKHOMJFNY        HCD                26   \n",
       "1048557  ZWIHLCKHOMJFNY        HCD                32   \n",
       "1048558  ZWIHLCKHOMJFNY        HCD                38   \n",
       "\n",
       "                                                  spectrum mode       ID  \n",
       "0        [[53.0387, 9.4], [55.018, 24.5], [55.0544, 40....    +        0  \n",
       "1        [[51.0231, 15.4], [53.0023, 15.9], [53.0387, 4...    +        1  \n",
       "2        [[51.0231, 79.3], [53.0024, 42.4], [53.0387, 6...    +        2  \n",
       "3        [[51.023, 143.3], [53.0023, 44.8], [53.0387, 9...    +        3  \n",
       "4        [[50.0153, 34.2], [51.023, 237.1], [52.0309, 1...    +        4  \n",
       "...                                                    ...  ...      ...  \n",
       "1048554  [[86.0966, 8.4], [87.1001, 2.5], [116.0708, 21...    +  1820925  \n",
       "1048555  [[70.0653, 5.8], [72.081, 3.6], [86.0966, 50.1...    +  1820926  \n",
       "1048556  [[70.0654, 79.9], [72.081, 55.6], [79.0215, 16...    +  1820927  \n",
       "1048557  [[57.07, 13.1], [69.0701, 19.4], [70.0653, 125...    +  1820928  \n",
       "1048558  [[55.0544, 18.0], [57.0701, 13.2], [67.0544, 7...    +  1820929  \n",
       "\n",
       "[1820930 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nist_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15          \n",
       "16          \n",
       "17          \n",
       "18          \n",
       "19          \n",
       "          ..\n",
       "1026609     \n",
       "1026610     \n",
       "1026611     \n",
       "1026612     \n",
       "1026613     \n",
       "Name: name, Length: 435482, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nist_input['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>queryID</th>\n",
       "      <th>inchi_base</th>\n",
       "      <th>score</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4382</td>\n",
       "      <td>BGRYOVBFCLQICL</td>\n",
       "      <td>True</td>\n",
       "      <td>0.017609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8211</td>\n",
       "      <td>HNPKDEDJNOBPTB</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8211</td>\n",
       "      <td>PKJBSZTYNDRXEQ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8211</td>\n",
       "      <td>UXQXWDAYKMXFDH</td>\n",
       "      <td>True</td>\n",
       "      <td>0.637622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14541</td>\n",
       "      <td>AKFIXMYXISUTAF</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>14541</td>\n",
       "      <td>DSDNAKHZNJAGHN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>14541</td>\n",
       "      <td>NJVADEFPOCMONF</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>14541</td>\n",
       "      <td>NOHMOWQGVDSLNY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.901930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>14541</td>\n",
       "      <td>WALMEPYKXGNNSY</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>14541</td>\n",
       "      <td>XCRBJSLPMIXFOO</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>14541</td>\n",
       "      <td>ZFHBPZHOLGMDMW</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>24700</td>\n",
       "      <td>BGOJKUCHTMYINI</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>24700</td>\n",
       "      <td>DNAMQWAMMWRLBC</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>24700</td>\n",
       "      <td>DORFFLQTHPKFDY</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>24700</td>\n",
       "      <td>GCYWVCQBMLYQGZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>24700</td>\n",
       "      <td>GYXPHGPELZUVGI</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>24700</td>\n",
       "      <td>HDMYXONNVAOHFR</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>24700</td>\n",
       "      <td>KLLGGGQNRTVBSU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>24700</td>\n",
       "      <td>KQFDQVMJLKUUDA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>24700</td>\n",
       "      <td>MBYLRWSUZLFUTO</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  queryID      inchi_base  score     preds\n",
       "0            0     4382  BGRYOVBFCLQICL   True  0.017609\n",
       "1            1     8211  HNPKDEDJNOBPTB  False  0.013081\n",
       "2            2     8211  PKJBSZTYNDRXEQ  False  0.013081\n",
       "3            3     8211  UXQXWDAYKMXFDH   True  0.637622\n",
       "4            4    14541  AKFIXMYXISUTAF  False  0.013081\n",
       "5            5    14541  DSDNAKHZNJAGHN  False  0.013081\n",
       "6            6    14541  NJVADEFPOCMONF  False  0.013081\n",
       "7            7    14541  NOHMOWQGVDSLNY   True  0.901930\n",
       "8            8    14541  WALMEPYKXGNNSY  False  0.013081\n",
       "9            9    14541  XCRBJSLPMIXFOO  False  0.013081\n",
       "10          10    14541  ZFHBPZHOLGMDMW  False  0.013081\n",
       "11          11    24700  BGOJKUCHTMYINI  False  0.013081\n",
       "12          12    24700  DNAMQWAMMWRLBC  False  0.013081\n",
       "13          13    24700  DORFFLQTHPKFDY  False  0.013081\n",
       "14          14    24700  GCYWVCQBMLYQGZ  False  0.013081\n",
       "15          15    24700  GYXPHGPELZUVGI  False  0.050114\n",
       "16          16    24700  HDMYXONNVAOHFR  False  0.013081\n",
       "17          17    24700  KLLGGGQNRTVBSU  False  0.013081\n",
       "18          18    24700  KQFDQVMJLKUUDA  False  0.013081\n",
       "19          19    24700  MBYLRWSUZLFUTO  False  0.013081"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_outputs_path = '/Users/jonahpoczobutt/projects/TunaRes/updated_results/intermediate_outputs/'\n",
    "\n",
    "pd.concat([pd.read_csv(f'{intermediate_outputs_path}/tunasims_aggregated_top_train.csv'),\n",
    "                         pd.read_csv(f'{intermediate_outputs_path}/tunasims_aggregated_top_val_1.csv')])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>queryID</th>\n",
       "      <th>inchi_base</th>\n",
       "      <th>score</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4382</td>\n",
       "      <td>BGRYOVBFCLQICL</td>\n",
       "      <td>True</td>\n",
       "      <td>0.022507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8211</td>\n",
       "      <td>HNPKDEDJNOBPTB</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8211</td>\n",
       "      <td>PKJBSZTYNDRXEQ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8211</td>\n",
       "      <td>UXQXWDAYKMXFDH</td>\n",
       "      <td>True</td>\n",
       "      <td>0.679844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14541</td>\n",
       "      <td>AKFIXMYXISUTAF</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>834</td>\n",
       "      <td>1792308</td>\n",
       "      <td>OPKKXWUGXHSFQI</td>\n",
       "      <td>False</td>\n",
       "      <td>0.073790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>1792308</td>\n",
       "      <td>OSFDXYVWIQEZHA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.017782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>836</td>\n",
       "      <td>1792308</td>\n",
       "      <td>RZMLRXSIZRAAAS</td>\n",
       "      <td>False</td>\n",
       "      <td>0.082156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>837</td>\n",
       "      <td>1792308</td>\n",
       "      <td>VOEIEXVBLCRZCS</td>\n",
       "      <td>False</td>\n",
       "      <td>0.551711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>838</td>\n",
       "      <td>1792308</td>\n",
       "      <td>YRNODZRPIGNGMY</td>\n",
       "      <td>False</td>\n",
       "      <td>0.073790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>839 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  queryID      inchi_base  score     preds\n",
       "0             0     4382  BGRYOVBFCLQICL   True  0.022507\n",
       "1             1     8211  HNPKDEDJNOBPTB  False  0.008877\n",
       "2             2     8211  PKJBSZTYNDRXEQ  False  0.008877\n",
       "3             3     8211  UXQXWDAYKMXFDH   True  0.679844\n",
       "4             4    14541  AKFIXMYXISUTAF  False  0.008877\n",
       "..          ...      ...             ...    ...       ...\n",
       "834         834  1792308  OPKKXWUGXHSFQI  False  0.073790\n",
       "835         835  1792308  OSFDXYVWIQEZHA  False  0.017782\n",
       "836         836  1792308  RZMLRXSIZRAAAS  False  0.082156\n",
       "837         837  1792308  VOEIEXVBLCRZCS  False  0.551711\n",
       "838         838  1792308  YRNODZRPIGNGMY  False  0.073790\n",
       "\n",
       "[839 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/updated_results/intermediate_outputs/tunasims_aggregated_top_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 'a'],\n",
       "       [5, 'a']], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[['a','b']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_output_dir = '/Users/jonahpoczobutt/projects/TunaRes/oldSimRes'\n",
    "if create_new_dataset:\n",
    "\n",
    "     demo_matches = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/Nist20_inputs/train/chunk_1.pkl')\n",
    "     demo_matches_val = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/Nist20_inputs/val/chunk_1.pkl')\n",
    "\n",
    "     queries = list()\n",
    "     targets = list()\n",
    "     indices = list()\n",
    "     for i in range(len(demo_matches)):\n",
    "\n",
    "          query = demo_matches.iloc[i]['query'][demo_matches.iloc[i]['query'][:,0] < demo_matches.iloc[i]['precquery'] - ppm(demo_matches.iloc[i]['precquery'],3)]\n",
    "          target = demo_matches.iloc[i]['target'][demo_matches.iloc[i]['target'][:,0] < demo_matches.iloc[i]['prectarget'] - ppm(demo_matches.iloc[i]['prectarget'],3)]\n",
    "\n",
    "          if len(query) > 0 and len(target) > 0:\n",
    "               indices.append(i)\n",
    "               queries.append(query)\n",
    "               targets.append(target)\n",
    "\n",
    "     demo_matches = demo_matches.iloc[indices]\n",
    "     demo_matches['query'] = queries\n",
    "     demo_matches['target'] = targets\n",
    "\n",
    "     queries = list()\n",
    "     targets = list()\n",
    "     indices = list()\n",
    "     for i in range(len(demo_matches_val)):\n",
    "\n",
    "          query = demo_matches_val.iloc[i]['query'][demo_matches_val.iloc[i]['query'][:,0] < demo_matches_val.iloc[i]['precquery'] - ppm(demo_matches_val.iloc[i]['precquery'],3)]\n",
    "          target = demo_matches_val.iloc[i]['target'][demo_matches_val.iloc[i]['target'][:,0] < demo_matches_val.iloc[i]['prectarget'] - ppm(demo_matches_val.iloc[i]['prectarget'],3)]\n",
    "\n",
    "          if len(query) > 0 and len(target) > 0:\n",
    "               indices.append(i)\n",
    "               queries.append(query)\n",
    "               targets.append(target)\n",
    "\n",
    "     demo_matches_val = demo_matches_val.iloc[indices]\n",
    "     demo_matches_val['query'] = queries\n",
    "     demo_matches_val['target'] = targets\n",
    "\n",
    "     demo_matches.to_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_no_prec.pkl')\n",
    "     demo_matches_val.to_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_val_no_prec.pkl')\n",
    "\n",
    "     sim_names = ['prob','matusita','entropy','dot','lorentzian','harmonic']\n",
    "     distances = [probabilistic_symmetric_chi_squared_distance,\n",
    "               matusita_distance,\n",
    "               entropy_distance,\n",
    "               dot_product_distance,\n",
    "               lorentzian_distance,\n",
    "               harmonic_mean_distance]\n",
    "\n",
    "     for _ in range(len(sim_names)):\n",
    "\n",
    "          matched_scores_val = list()\n",
    "          for i in range(len(demo_matches_val)):\n",
    "          \n",
    "               matched = tools_fast.match_spectrum(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], ms2_da = 0.05)\n",
    "               matched_scores_val.append(sigmoid(distances[_](matched[:,1]/sum(matched[:,1]), matched[:,2]/sum(matched[:,2]))))\n",
    "\n",
    "          np.save(f'{sims_output_dir}/val_{sim_names[_]}.npy', np.array(matched_scores_val))\n",
    "\n",
    "          matched_scores = list()\n",
    "          for i in range(len(demo_matches)):\n",
    "\n",
    "               matched = tools_fast.match_spectrum(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'], ms2_da = 0.05)\n",
    "               matched_scores.append(sigmoid(distances[_](matched[:,1]/sum(matched[:,1]), matched[:,2]/sum(matched[:,2]))))\n",
    "\n",
    "          np.save(f'{sims_output_dir}/train_{sim_names[_]}.npy', np.array(matched_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_vals = {\n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'add_norm_b' : 1,\n",
    "    'target_intensity_a': 0.1,\n",
    "    'query_intensity_a': 0.1,\n",
    "    'target_intensity_b': 0.1,\n",
    "    'query_intensity_b': 0.1,\n",
    "    }\n",
    "\n",
    "init_vals_2 = {\n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'add_norm_a': 1,\n",
    "    'add_norm_b' : 1,\n",
    "    'target_intensity_a': 0.1,\n",
    "    'query_intensity_a': 0.1,\n",
    "    'target_intensity_b': 0.1,\n",
    "    'query_intensity_b': 0.1,\n",
    "    }\n",
    "\n",
    "init_vals_3 = {\n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'add_norm_int': 0,\n",
    "    'add_norm_a': 1,\n",
    "    'add_norm_b' : 1,\n",
    "    'target_intensity_a': 0.1,\n",
    "    'query_intensity_a': 0.1,\n",
    "    'target_intensity_b': 0.1,\n",
    "    'query_intensity_b': 0.1,\n",
    "    }\n",
    "\n",
    "regularization_grad = lambda x: 0.\n",
    "\n",
    "fixed_vals = {'sigmoid_score' : True, \n",
    "              'weight_combine': 'multiply'\n",
    "    }\n",
    "\n",
    "fixed_vals = {}\n",
    "\n",
    "bounds = {'add_norm_b': (0, 2),\n",
    "          'mult_add_norm_b': (0, 2),\n",
    "          'dif_add_norm_b': (0, 2),\n",
    "          'mult_b': (1e-10, 2),\n",
    "          'add_norm_a': (1e-10, 3),\n",
    "          'dif_b': (1e-10, 2),\n",
    "          'dif_a':(-3,3),\n",
    "          'mult_a': (-3,3),\n",
    "          'add_norm_int': (0, 3),\n",
    "          'target_normalized_intensity_int': (-0.2,1),\n",
    "          'query_normalized_intensity_int': (-0.2,1),\n",
    "          'target_normalized_intensity_a': (1e-10,2),\n",
    "          'query_normalized_intensity_a': (1e-10,2),\n",
    "          'target_normalized_intensity_b': (0,2),\n",
    "          'query_normalized_intensity_b': (0,2),\n",
    "          'target_normalized_intensity_c': (-2,2),\n",
    "          'query_normalized_intensity_c': (-2,2),\n",
    "          'target_mz_b': (-2,2),\n",
    "          'query_mz_b': (-2,2),\n",
    "          'target_mz_a': (-2,2),\n",
    "          'query_mz_a': (-2,2),\n",
    "          'target_mz_int': (-0.2,1),\n",
    "          'query_mz_int': (-0.2,1),\n",
    "          'target_mz_c': (-2,2),\n",
    "          'query_mz_c': (-2,2),\n",
    "           'target_intensity_int': (-0.2,1),\n",
    "           'query_intensity_int': (-0.2,1),\n",
    "          'target_intensity_a': (1e-10,2),\n",
    "          'query_intensity_a': (1e-10,2),\n",
    "          'target_intensity_b': (1e-10,2),\n",
    "          'query_intensity_b': (1e-10,2),\n",
    "          'target_intensity_c': (1e-10,2),\n",
    "          'query_intensity_c': (1e-10,2),\n",
    "          }\n",
    "\n",
    "\n",
    "init_names = ['b', 'ab', 'abint']\n",
    "inits = [init_vals, init_vals_2, init_vals_3]\n",
    "ad_params = [(0.98,0.025)]\n",
    "func_obs = list()\n",
    "\n",
    "for i in range(1):\n",
    "    for momentum in [None]:\n",
    "        for sched in [None]:\n",
    "            for i in range(len(inits)):\n",
    "                for ad_param in ad_params:\n",
    "                \n",
    "                    # func_obs.append(func_ob(f'{momentum}_{sched}_{init_names[i]}_{ad_param}',\n",
    "                    #             sim_func = TunaSims.ExpandedTuna,\n",
    "                    #             init_vals = inits[i].copy(),\n",
    "                    #             fixed_vals = fixed_vals,\n",
    "                    #             regularization_grad = regularization_grad,\n",
    "                    #             bounds = bounds,\n",
    "                    #             max_iter = 1e6,\n",
    "                    #             learning_rates = 0.001,\n",
    "                    #             momentum_type = momentum,\n",
    "                    #             learning_rate_scheduler = sched,\n",
    "                    #             learning_beta = 0.5,\n",
    "                    #             momentum_beta = 0.3,\n",
    "                    #             tol = 0,\n",
    "                    #             balance_classes = True,\n",
    "                    #             groupby_column = 'queryID_target_base',\n",
    "                    #             ad_int = ad_param[0],\n",
    "                    #             ad_slope= ad_param[1]))\n",
    "                    \n",
    "                    func_obs.append(specSimTrainer(f'{momentum}_{sched}_{init_names[i]}_{ad_param}',\n",
    "                                init_vals = inits[i].copy(),\n",
    "                                fixed_vals = fixed_vals,\n",
    "                                bounds = bounds,\n",
    "                                max_iter = 1e6,\n",
    "                                learning_rates = 0.005,\n",
    "                                learning_rate_scheduler = sched,\n",
    "                                learning_beta = 0.5,\n",
    "                                balance_column= 'score',\n",
    "                                groupby_column = 'queryID_target_base',\n",
    "                                ad_int = ad_param[0],\n",
    "                                ad_slope= ad_param[1]))\n",
    "                \n",
    "print(len(func_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TunaSims import speedyTuna\n",
    "demo_matches = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_no_prec.pkl')\n",
    "demo_matches_val = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_val_no_prec.pkl')\n",
    "#demo_matches = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_lite.pkl')\n",
    "\n",
    "demo_matches['score'] = 1 * demo_matches['InchiCoreMatch']\n",
    "demo_matches['queryID_target_base'] = demo_matches['queryID'].astype(str) + '_' + demo_matches['target_base'].astype(str)\n",
    "demo_matches_val['queryID_target_base'] = demo_matches_val['queryID'].astype(str) + '_' + demo_matches_val['target_base'].astype(str)\n",
    "\n",
    "demo_matches_val['score'] = 1 * demo_matches_val['InchiCoreMatch']\n",
    "\n",
    "train_auc_top = {i.name: list() for i in func_obs}\n",
    "val_auc_top = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_auc_all = {i.name: list() for i in func_obs}\n",
    "val_auc_all = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_times = {i.name: list() for i in func_obs}\n",
    "\n",
    "absolutes = [0, 1e5]\n",
    "offsets = [absolutes[i+1] - absolutes[i] for i in range(len(absolutes)-1)]\n",
    "\n",
    "reps = 5\n",
    "\n",
    "trained_obs = []\n",
    "\n",
    "for model in func_obs:\n",
    "\n",
    "    accumulated = 0\n",
    "    accumulated_time = 0\n",
    "    train_aucs_top = list()\n",
    "    val_aucs_top = list()\n",
    "    train_aucs_all = list()\n",
    "    val_aucs_all = list()\n",
    "    trained_obs_sub = list()\n",
    "\n",
    "    for _ in range(reps):\n",
    "\n",
    "        model_ = copy.deepcopy(model)\n",
    "\n",
    "        for i in offsets:\n",
    "            \n",
    "            model_.max_iter = i\n",
    "\n",
    "            keys = model_.sim_func.grad_names\n",
    "            inits = {keys[i]: np.random.uniform(model_.bounds[i][0], model_.bounds[i][1]) for i in range(len(keys))}\n",
    "            model_.sim_func = speedyTuna(**inits)\n",
    "            \n",
    "            print('start')\n",
    "            start = time.time()\n",
    "            model_.fit(demo_matches)\n",
    "            accumulated_time += time.time() - start\n",
    "\n",
    "            print(f'done training: {round((accumulated_time)/60, 4)}')\n",
    "\n",
    "            demo_matches['preds'] = model_.sim_func.predict_for_dataset(demo_matches)\n",
    "            demo_matches_val['preds'] = model_.sim_func.predict_for_dataset(demo_matches_val)\n",
    "\n",
    "            temp = demo_matches[['queryID_target_base','preds','score']].groupby(by=['queryID_target_base']).max()\n",
    "            temp_val = demo_matches_val[['queryID_target_base','preds','score']].groupby(by=['queryID_target_base']).max()\n",
    "\n",
    "            train_aucs_top.append(round(roc_auc_score(temp['score'] , temp['preds']), 4)) \n",
    "            val_aucs_top.append(round(roc_auc_score(temp_val['score'] , temp_val['preds']),4))\n",
    "\n",
    "            print(train_aucs_top, val_aucs_top)\n",
    "\n",
    "            accumulated += model_.max_iter\n",
    "\n",
    "        trained_obs_sub.append(copy.deepcopy(model_))\n",
    "        \n",
    "    trained_obs.append(trained_obs_sub)\n",
    "    train_times[model.name].append(round(accumulated_time/60, 4))\n",
    "    train_auc_all[model.name].append(train_aucs_all)\n",
    "    train_auc_top[model.name].append(train_aucs_top)\n",
    "    val_auc_all[model.name].append(val_aucs_all)\n",
    "    val_auc_top[model.name].append(val_aucs_top)\n",
    "\n",
    "    print(model.name)\n",
    "\n",
    "    model_1 = model_\n",
    "\n",
    "train_auc_top, val_auc_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.sim_func.grad_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/TunaRes/pickled_models/model_1.pickle', 'rb') as handle:\n",
    "    model = pickle.load(handle)\n",
    "\n",
    "\n",
    "for i in model_1.init_vals:\n",
    "\n",
    "    print(i, getattr(model_1.sim_func,i), getattr(model,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/TunaRes/pickled_models/model_1.pickle', 'rb') as handle:\n",
    "    model_ = pickle.load(handle)\n",
    "\n",
    "model_.query_mz = False\n",
    "model_.target_mz = False\n",
    "model_.query_mz_offset = False\n",
    "model_.target_mz_offset = False\n",
    "model_.query_intensity = False\n",
    "model_.target_intensity = False\n",
    "model_.query_normalized_intensity = False\n",
    "model_.target_normalized_intensity = False\n",
    "\n",
    "demo_matches['preds'] = [model_.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'], demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches))]\n",
    "#demo_matches_val['preds'] = [model_.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget'],grads = False) for i in range(len(demo_matches_val))]\n",
    "\n",
    "# train_aucs_all.append(round(roc_auc_score(demo_matches['score'] , demo_matches['preds']), 4)) \n",
    "# val_aucs_all.append(round(roc_auc_score(demo_matches_val['score'] , demo_matches_val['preds']),4))\n",
    "\n",
    "temp = demo_matches.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "#temp_val = demo_matches_val.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "\n",
    "train_aucs_top.append(round(roc_auc_score(temp['score'] , temp['preds']), 4)) \n",
    "#val_aucs_top.append(round(roc_auc_score(temp_val['score'] , temp_val['preds']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TunaSims\n",
    "import TunaSimsOld\n",
    "import pandas as pd\n",
    "\n",
    "demo_matches = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_no_prec.pkl')\n",
    "\n",
    "new = TunaSims.speedyTuna(query_intensity_a = 1,\n",
    "                          query_intensity_b = 1,\n",
    "                          target_intensity_a = 1,\n",
    "                          target_intensity_b = 1,\n",
    "                          mult_a = 0.001,\n",
    "                          mult_b = 1,\n",
    "                          dif_a= 0.001,\n",
    "                          dif_b = 1,\n",
    "                          add_norm_a= 1,\n",
    "                          add_norm_b= 1)\n",
    "\n",
    "old = TunaSimsOld.ExpandedTuna(query_normalized_intensity_a = 1,\n",
    "                          query_normalized_intensity_b = 1,\n",
    "                          target_normalized_intensity_a = 1,\n",
    "                          target_normalized_intensity_b = 1,\n",
    "                          mult_a = 0.001,\n",
    "                          mult_b = 1,\n",
    "                          dif_a= 0.001,\n",
    "                          dif_b = 1,\n",
    "                          add_norm_a= 1,\n",
    "                          add_norm_b= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(999,1001):\n",
    "    new.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'], grads = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    new.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'], grads = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(999,1001):\n",
    "    old.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'], demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    old.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'], demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = pd.DataFrame([1 for i in range(1000)] + [5 for i in range(100)] + [3 for i in range(50000)], columns = ['yoop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy.sort_values(by='yoop', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in range(1000)]\n",
    "for i in range(10000):\n",
    "    \n",
    "    np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model_.init_vals:\n",
    "\n",
    "    print(i, getattr(model_.sim_func, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/TunaRes/pickled_models/model_1.pickle', 'rb') as handle:\n",
    "\n",
    "    model_ = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model_.init_vals:\n",
    "\n",
    "    print(i, getattr(model, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.sim_func.nonzero_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.sim_func.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model_.sim_func.grads1.keys():\n",
    "    print(i, getattr(model_.sim_func,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TunaSims\n",
    "\n",
    "mer = TunaSims.ScoreByQuery(raw_scores_int = 0,\n",
    "                            raw_scores_a = 1,\n",
    "                            raw_scores_b = 1,\n",
    "                            dif_from_top_int = 0,\n",
    "                            dif_from_top_a = -1,\n",
    "                            dif_from_top_b = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funcOb\n",
    "import TunaSims\n",
    "\n",
    "inits = {'raw_scores_int' :0,\n",
    "        'raw_scores_a' : 1,\n",
    "        'raw_scores_b' : 1,\n",
    "        'dif_from_top_int' : 0,\n",
    "        'dif_from_top_a' : -1,\n",
    "        'dif_from_top_b' : 1}\n",
    "\n",
    "fixed_vals = {}\n",
    "\n",
    "a = funcOb.scoreByQueryFunc(name = 'testy',\n",
    "                            init_vals = inits,\n",
    "                            fixed_vals = fixed_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.dot(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([None, 1])\n",
    "(a == None).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot([1,2], [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mer.predict(scores = [0.9, 0.8, 0.5], match_names = ['a', 'b', 'c'], grads = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to add the object attributes back so that we ca properly adjust gradients...for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.sum([[1,2,3], [1,2,3]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.6,1,0,1])\n",
    "sort_order = np.argsort(-a)\n",
    "mask = (sort_order == 0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "\n",
    "np.sum([np.array([1,2,3]),np.array([4,5,6])], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[sort_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "np.prod(np.vstack((a[sort_order], mask,a)),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(temp['preds'], bins = 100)\n",
    "plt.title('Preds Train')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(temp_val['preds'], bins = 100)\n",
    "plt.title('Preds Val')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = np.array([0,1,0,0,0,0])\n",
    "\n",
    "\n",
    "#np.sum(np.trues - preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('function of remaining scores')\n",
    "print(np.concatenate((preds,[0])))\n",
    "print(np.max(preds) - np.concatenate((preds,[0])))\n",
    "\n",
    "print('then move through in reverse for scores above')\n",
    "print(np.concatenate((preds[::-1],[0])))\n",
    "print(np.concatenate((preds[::-1],[0])) - np.min(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([0.45,0.4,0.3])\n",
    "padded = np.concatenate(([1-preds[0]], preds))\n",
    "max_dif = (np.max(padded) - padded)\n",
    "prob_above = np.array([sum(padded[:i]) for i in range(len(padded))])\n",
    "print(padded)\n",
    "print(max_dif)\n",
    "print(prob_above)\n",
    "\n",
    "\n",
    "#should also have function of other scores summed after a non-linear transformation\n",
    "#array[not]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(['a',None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_none_prob(max_prob):\n",
    "    \"\"\" \n",
    "    probs must already be sorted from max to min and have\n",
    "    candidate names in corresponding order\n",
    "    \"\"\"\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab only inchicores where performance was bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['residual'] = np.abs(temp['score'] - temp['preds'])\n",
    "median_residual = np.median(temp['residual'])\n",
    "print(len(temp[temp['score'] == 1])/len(temp))\n",
    "\n",
    "pos = 0\n",
    "neg = 0\n",
    "bad_ids = list()\n",
    "for i in range(len(temp)):\n",
    "\n",
    "    if temp.iloc[i]['residual'] >= median_residual:\n",
    "        bad_ids.append(temp.iloc[i]['queryID_target_base'])\n",
    "\n",
    "        if temp.iloc[i]['score'] == 1:\n",
    "            pos+=1\n",
    "\n",
    "        else:\n",
    "            neg+=1\n",
    "\n",
    "bad_ids = set(bad_ids)\n",
    "\n",
    "residual_inds = list()\n",
    "\n",
    "for i in range(len(demo_matches)):\n",
    "\n",
    "    if demo_matches.iloc[i]['queryID_target_base'] in bad_ids:\n",
    "\n",
    "        residual_inds.append(i)\n",
    "\n",
    "demo_matches = demo_matches.iloc[residual_inds]\n",
    "print(len(demo_matches))\n",
    "print(len(bad_ids))\n",
    "print(pos / (pos + neg))\n",
    "\n",
    "train_auc_top = {i.name: list() for i in func_obs}\n",
    "val_auc_top = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_auc_all = {i.name: list() for i in func_obs}\n",
    "val_auc_all = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_times = {i.name: list() for i in func_obs}\n",
    "\n",
    "absolutes = [0,1e5]\n",
    "offsets = [absolutes[i+1] - absolutes[i] for i in range(len(absolutes)-1)]\n",
    "\n",
    "reps = 1\n",
    "\n",
    "trained_obs = []\n",
    "\n",
    "for model in func_obs:\n",
    "\n",
    "    for _ in range(reps):\n",
    "\n",
    "        model_ = copy.deepcopy(model)\n",
    "\n",
    "        accumulated = 0\n",
    "        accumulated_time = 0\n",
    "        train_aucs_top = list()\n",
    "        val_aucs_top = list()\n",
    "        train_aucs_all = list()\n",
    "        val_aucs_all = list()\n",
    "        trained_obs_sub = list()\n",
    "\n",
    "        for i in offsets:\n",
    "            \n",
    "            model_.max_iter = i\n",
    "            \n",
    "            start = time.time()\n",
    "            model_.fit(demo_matches)\n",
    "            accumulated_time += time.time() - start\n",
    "\n",
    "            demo_matches['preds'] = [model_.sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches))]\n",
    "            demo_matches_val['preds'] = [model_.sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches_val))]\n",
    "\n",
    "            train_aucs_all.append(round(roc_auc_score(demo_matches['score'] , demo_matches['preds']), 4)) \n",
    "            val_aucs_all.append(round(roc_auc_score(demo_matches_val['score'] , demo_matches_val['preds']),4))\n",
    "\n",
    "            temp = demo_matches.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "            temp_val = demo_matches_val.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "\n",
    "            train_aucs_top.append(round(roc_auc_score(temp['score'] , temp['preds']), 4)) \n",
    "            val_aucs_top.append(round(roc_auc_score(temp_val['score'] , temp_val['preds']),4))\n",
    "\n",
    "            accumulated += model_.max_iter\n",
    "\n",
    "        trained_obs_sub.append(copy.deepcopy(model_))\n",
    "        \n",
    "    trained_obs.append(trained_obs_sub)\n",
    "    train_times[model.name].append(round(accumulated_time/60, 4))\n",
    "    train_auc_all[model.name].append(train_aucs_all)\n",
    "    train_auc_top[model.name].append(train_aucs_top)\n",
    "    val_auc_all[model.name].append(val_aucs_all)\n",
    "    val_auc_top[model.name].append(val_aucs_top)\n",
    "\n",
    "    print(model.name)\n",
    "\n",
    "    model_2 = model_\n",
    "\n",
    "train_auc_top, val_auc_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['residual'] = np.abs(temp['score'] - temp['preds'])\n",
    "median_residual = np.median(temp['residual'])\n",
    "print(len(temp[temp['score'] == 1])/len(temp))\n",
    "print(median_residual)\n",
    "\n",
    "pos = 0\n",
    "neg = 0\n",
    "bad_ids = list()\n",
    "for i in range(len(temp)):\n",
    "\n",
    "    if temp.iloc[i]['residual'] >= median_residual:\n",
    "        bad_ids.append(temp.iloc[i]['queryID_target_base'])\n",
    "\n",
    "        if temp.iloc[i]['score'] == 1:\n",
    "            pos+=1\n",
    "\n",
    "        else:\n",
    "            neg+=1\n",
    "\n",
    "bad_ids = set(bad_ids)\n",
    "\n",
    "residual_inds = list()\n",
    "\n",
    "for i in range(len(demo_matches)):\n",
    "\n",
    "    if demo_matches.iloc[i]['queryID_target_base'] in bad_ids:\n",
    "\n",
    "        residual_inds.append(i)\n",
    "\n",
    "demo_matches = demo_matches.iloc[residual_inds]\n",
    "print(len(demo_matches))\n",
    "print(len(bad_ids))\n",
    "print(pos / (pos + neg))\n",
    "\n",
    "train_auc_top = {i.name: list() for i in func_obs}\n",
    "val_auc_top = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_auc_all = {i.name: list() for i in func_obs}\n",
    "val_auc_all = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_times = {i.name: list() for i in func_obs}\n",
    "\n",
    "absolutes = [0,1e5]\n",
    "offsets = [absolutes[i+1] - absolutes[i] for i in range(len(absolutes)-1)]\n",
    "\n",
    "reps = 1\n",
    "\n",
    "trained_obs = []\n",
    "\n",
    "for model in func_obs:\n",
    "\n",
    "    for _ in range(reps):\n",
    "\n",
    "        model_ = copy.deepcopy(model)\n",
    "\n",
    "        accumulated = 0\n",
    "        accumulated_time = 0\n",
    "        train_aucs_top = list()\n",
    "        val_aucs_top = list()\n",
    "        train_aucs_all = list()\n",
    "        val_aucs_all = list()\n",
    "        trained_obs_sub = list()\n",
    "\n",
    "        for i in offsets:\n",
    "            \n",
    "            model_.max_iter = i\n",
    "            \n",
    "            start = time.time()\n",
    "            model_.fit(demo_matches)\n",
    "            accumulated_time += time.time() - start\n",
    "\n",
    "            demo_matches['preds'] = [model_.sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches))]\n",
    "            demo_matches_val['preds'] = [model_.sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches_val))]\n",
    "\n",
    "            train_aucs_all.append(round(roc_auc_score(demo_matches['score'] , demo_matches['preds']), 4)) \n",
    "            val_aucs_all.append(round(roc_auc_score(demo_matches_val['score'] , demo_matches_val['preds']),4))\n",
    "\n",
    "            temp = demo_matches.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "            temp_val = demo_matches_val.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "\n",
    "            train_aucs_top.append(round(roc_auc_score(temp['score'] , temp['preds']), 4)) \n",
    "            val_aucs_top.append(round(roc_auc_score(temp_val['score'] , temp_val['preds']),4))\n",
    "\n",
    "            accumulated += model_.max_iter\n",
    "\n",
    "        trained_obs_sub.append(copy.deepcopy(model_))\n",
    "        \n",
    "    trained_obs.append(trained_obs_sub)\n",
    "    train_times[model.name].append(round(accumulated_time/60, 4))\n",
    "    train_auc_all[model.name].append(train_aucs_all)\n",
    "    train_auc_top[model.name].append(train_aucs_top)\n",
    "    val_auc_all[model.name].append(val_aucs_all)\n",
    "    val_auc_top[model.name].append(val_aucs_top)\n",
    "\n",
    "    print(model.name)\n",
    "\n",
    "    model_3 = model_\n",
    "\n",
    "train_auc_top, val_auc_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['residual'] = np.abs(temp['score'] - temp['preds'])\n",
    "median_residual = np.median(temp['residual'])\n",
    "print(len(temp[temp['score'] == 1])/len(temp))\n",
    "print(median_residual)\n",
    "\n",
    "pos = 0\n",
    "neg = 0\n",
    "bad_ids = list()\n",
    "for i in range(len(temp)):\n",
    "\n",
    "    if temp.iloc[i]['residual'] >= median_residual:\n",
    "        bad_ids.append(temp.iloc[i]['queryID_target_base'])\n",
    "\n",
    "        if temp.iloc[i]['score'] == 1:\n",
    "            pos+=1\n",
    "\n",
    "        else:\n",
    "            neg+=1\n",
    "\n",
    "bad_ids = set(bad_ids)\n",
    "\n",
    "residual_inds = list()\n",
    "\n",
    "for i in range(len(demo_matches)):\n",
    "\n",
    "    if demo_matches.iloc[i]['queryID_target_base'] in bad_ids:\n",
    "\n",
    "        residual_inds.append(i)\n",
    "\n",
    "demo_matches = demo_matches.iloc[residual_inds]\n",
    "print(len(demo_matches))\n",
    "print(len(bad_ids))\n",
    "print(pos / (pos + neg))\n",
    "\n",
    "train_auc_top = {i.name: list() for i in func_obs}\n",
    "val_auc_top = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_auc_all = {i.name: list() for i in func_obs}\n",
    "val_auc_all = {i.name: list() for i in func_obs}\n",
    "\n",
    "train_times = {i.name: list() for i in func_obs}\n",
    "\n",
    "absolutes = [0,1e5]\n",
    "offsets = [absolutes[i+1] - absolutes[i] for i in range(len(absolutes)-1)]\n",
    "\n",
    "reps = 1\n",
    "\n",
    "trained_obs = []\n",
    "\n",
    "for model in func_obs:\n",
    "\n",
    "    for _ in range(reps):\n",
    "\n",
    "        model_ = copy.deepcopy(model)\n",
    "\n",
    "        accumulated = 0\n",
    "        accumulated_time = 0\n",
    "        train_aucs_top = list()\n",
    "        val_aucs_top = list()\n",
    "        train_aucs_all = list()\n",
    "        val_aucs_all = list()\n",
    "        trained_obs_sub = list()\n",
    "\n",
    "        for i in offsets:\n",
    "            \n",
    "            model_.max_iter = i\n",
    "            \n",
    "            start = time.time()\n",
    "            model_.fit(demo_matches)\n",
    "            accumulated_time += time.time() - start\n",
    "\n",
    "            demo_matches['preds'] = [model_.sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches))]\n",
    "            demo_matches_val['preds'] = [model_.sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches_val))]\n",
    "\n",
    "            train_aucs_all.append(round(roc_auc_score(demo_matches['score'] , demo_matches['preds']), 4)) \n",
    "            val_aucs_all.append(round(roc_auc_score(demo_matches_val['score'] , demo_matches_val['preds']),4))\n",
    "\n",
    "            temp = demo_matches.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "            temp_val = demo_matches_val.groupby(by=['queryID','target_base']).apply(lambda x: x[x['preds'] == max(x['preds'])].iloc[0])\n",
    "\n",
    "            train_aucs_top.append(round(roc_auc_score(temp['score'] , temp['preds']), 4)) \n",
    "            val_aucs_top.append(round(roc_auc_score(temp_val['score'] , temp_val['preds']),4))\n",
    "\n",
    "            accumulated += model_.max_iter\n",
    "\n",
    "        trained_obs_sub.append(copy.deepcopy(model_))\n",
    "        \n",
    "    trained_obs.append(trained_obs_sub)\n",
    "    train_times[model.name].append(round(accumulated_time/60, 4))\n",
    "    train_auc_all[model.name].append(train_aucs_all)\n",
    "    train_auc_top[model.name].append(train_aucs_top)\n",
    "    val_auc_all[model.name].append(val_aucs_all)\n",
    "    val_auc_top[model.name].append(val_aucs_top)\n",
    "\n",
    "    print(model.name)\n",
    "\n",
    "    model_4 = model_\n",
    "\n",
    "train_auc_top, val_auc_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_1, model_2, model_3, model_4]:\n",
    "\n",
    "    print('\\n')\n",
    "    for i in init_vals:\n",
    "        print(i, round(getattr(model.sim_func, i),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_matches = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_no_prec.pkl')\n",
    "\n",
    "all_scores_train = dict()\n",
    "all_scores_val = dict()\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4]\n",
    "mod_names = ['model_1', 'model_2', 'model_3', 'model_4']\n",
    "\n",
    "for _ in range(len(models)):\n",
    "\n",
    "    print(mod_names[_])\n",
    "\n",
    "    all_scores_train[mod_names[_]] = [models[_].sim_func.predict(demo_matches.iloc[i]['query'], demo_matches.iloc[i]['target'],demo_matches.iloc[i]['precquery'], demo_matches.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches))]\n",
    "    \n",
    "all_scores_train['queryID'] = demo_matches['queryID'].tolist()\n",
    "all_scores_train['target_base'] = demo_matches['target_base'].tolist()\n",
    "all_scores_train['score'] = demo_matches['score'].tolist()\n",
    "\n",
    "del(demo_matches)\n",
    "\n",
    "demo_matches_val = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/inputs/demo_matches_val_no_prec.pkl')\n",
    "\n",
    "for _ in range(len(models)):\n",
    "\n",
    "    all_scores_val[mod_names[_]] = [models[_].sim_func.predict(demo_matches_val.iloc[i]['query'], demo_matches_val.iloc[i]['target'], demo_matches_val.iloc[i]['precquery'], demo_matches_val.iloc[i]['prectarget'], grads = False) for i in range(len(demo_matches_val))]\n",
    "    print(mod_names[_])\n",
    "\n",
    "all_scores_val['queryID'] = demo_matches_val['queryID'].tolist()\n",
    "all_scores_val['target_base'] = demo_matches_val['target_base'].tolist()\n",
    "all_scores_val['score'] = demo_matches_val['score'].tolist()\n",
    "del(demo_matches_val)\n",
    "\n",
    "for sim in sim_names:\n",
    "\n",
    "    print(sim)\n",
    "\n",
    "    all_scores_train[sim] = np.load(f'{sims_output_dir}/train_{sim}.npy')\n",
    "    all_scores_val[sim] = np.load(f'{sims_output_dir}/val_{sim}.npy')\n",
    "\n",
    "all_scores_train = pd.DataFrame(all_scores_train)\n",
    "all_scores_val = pd.DataFrame(all_scores_val)\n",
    "\n",
    "all_scores_train.to_pickle('/Users/jonahpoczobutt/projects/TunaRes/sim_scores/train.pickle')\n",
    "all_scores_val.to_pickle('/Users/jonahpoczobutt/projects/TunaRes/sim_scores/val.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/sim_scores/train.pickle')\n",
    "val_data = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/sim_scores/val.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_scores_train = train_data.groupby(['queryID', 'target_base']).max()\n",
    "max_scores_val = val_data.groupby(['queryID', 'target_base']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in max_scores_train.columns[:-1]:\n",
    "\n",
    "    print(f\"{col}: train: {round(roc_auc_score(max_scores_train['score'], max_scores_train[col]),4)} val: {round(roc_auc_score(max_scores_val['score'], max_scores_val[col]),4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[:,:-3].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Train Models with Each Pair/Triplet of Sim Scores Old and New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create column groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_names = ['prob', 'matusita', 'entropy', 'dot', 'lorentzian', 'harmonic']\n",
    "\n",
    "old_sim_combos = list()\n",
    "for n in range(1,7):\n",
    "\n",
    "    for comb in combinations(sim_names, n):\n",
    "        old_sim_combos.append(list(comb))\n",
    "\n",
    "\n",
    "new_sim_combos = list()\n",
    "new_sims = ['model_1', 'model_2', 'model_3', 'model_4']\n",
    "for n in range(1,5):\n",
    "\n",
    "    for comb in combinations(new_sims, n):\n",
    "        new_sim_combos.append(list(comb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Models for each Column Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_performance_old = dict()\n",
    "\n",
    "trained = 0\n",
    "consolidated = True\n",
    "for combo in old_sim_combos:\n",
    "\n",
    "    model = hgbc()\n",
    "    if consolidated:\n",
    "        train = max_scores_train\n",
    "        val = max_scores_val\n",
    "\n",
    "    else:\n",
    "        train = train_data.copy()\n",
    "        val = val_data.copy()\n",
    "\n",
    "    model.fit(train[combo], train['score'])\n",
    "\n",
    "    if consolidated:\n",
    "\n",
    "        preds = model.predict_proba(train[combo])[:,1]\n",
    "        preds_val = model.predict_proba(val[combo])[:,1]\n",
    "\n",
    "    else:\n",
    "\n",
    "        train['preds'] = model.predict_proba(train[combo])[:,1]\n",
    "        val['preds'] = model.predict_proba(val[combo])[:,1]\n",
    "\n",
    "        train = train.groupby(['queryID', 'target_base']).max()\n",
    "        val = val.groupby(['queryID', 'target_base']).max()\n",
    "\n",
    "        preds = train['preds']\n",
    "        preds_val = val['preds']\n",
    "    \n",
    "    train_auc = roc_auc_score(train['score'], preds)\n",
    "    val_auc = roc_auc_score(val['score'], preds_val)\n",
    "\n",
    "    sim_performance_old['-'.join(combo)] = (train_auc, val_auc)\n",
    "\n",
    "    trained +=1\n",
    "    if trained % 10 == 0:\n",
    "        print(trained)\n",
    "\n",
    "sim_performance_new = dict()\n",
    "trained = 0\n",
    "for combo in new_sim_combos:\n",
    "\n",
    "    model = hgbc()\n",
    "    if consolidated:\n",
    "        train = max_scores_train\n",
    "        val = max_scores_val\n",
    "\n",
    "    else:\n",
    "        train = train_data.copy()\n",
    "        val = val_data.copy()\n",
    "\n",
    "    model.fit(train[combo], train['score'])\n",
    "\n",
    "    if consolidated:\n",
    "        \n",
    "        preds = model.predict_proba(train[combo])[:,1]\n",
    "        preds_val = model.predict_proba(val[combo])[:,1]\n",
    "\n",
    "    else:\n",
    "\n",
    "        train['preds'] = model.predict_proba(train[combo])[:,1]\n",
    "        val['preds'] = model.predict_proba(val[combo])[:,1]\n",
    "\n",
    "        train = train.groupby(['queryID', 'target_base']).max()\n",
    "        val = val.groupby(['queryID', 'target_base']).max()\n",
    "\n",
    "        preds = train['preds']\n",
    "        preds_val = val['preds']\n",
    "    \n",
    "    train_auc = roc_auc_score(train['score'], preds)\n",
    "    val_auc = roc_auc_score(val['score'], preds_val)\n",
    "\n",
    "    sim_performance_new['-'.join(combo)] = (train_auc, val_auc)\n",
    "\n",
    "    trained +=1\n",
    "    if trained % 10 == 0:\n",
    "        print(trained)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==1]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==1]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==2]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==2]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==3]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==3]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==4]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==4]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==5]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==5]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==6]), np.max([val[0] for key, val in sim_performance_old.items() if len(key.split('-'))==6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==1]), np.max([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==1]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==2]), np.max([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==2]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==3]), np.max([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==3]))\n",
    "print(np.mean([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==4]), np.max([val[0] for key, val in sim_performance_new.items() if len(key.split('-'))==4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Val Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==1]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==1]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==2]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==2]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==3]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==3]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==4]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==4]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==5]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==5]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==6]), np.max([val[1] for key, val in sim_performance_old.items() if len(key.split('-'))==6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==1]), np.max([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==1]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==2]), np.max([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==2]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==3]), np.max([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==3]))\n",
    "print(np.mean([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==4]), np.max([val[1] for key, val in sim_performance_new.items() if len(key.split('-'))==4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3,4,5]:\n",
    "\n",
    "    performances = [val[1] for key, val in sim_performance_old.items() if len(key.split('-')) == i]\n",
    "    keys = [key for key, val in sim_performance_old.items() if len(key.split('-')) == i]\n",
    "\n",
    "    max_key = keys[np.argmax(performances)]\n",
    "    print(i, max_key, round(sim_performance_old[max_key][0],4), round(sim_performance_old[max_key][1],4))\n",
    "\n",
    "print('\\n')\n",
    "for i in [1,2,3,4]:\n",
    "\n",
    "    performances = [val[1] for key, val in sim_performance_new.items() if len(key.split('-')) == i]\n",
    "    keys = [key for key, val in sim_performance_new.items() if len(key.split('-')) == i]\n",
    "\n",
    "    max_key = keys[np.argmax(performances)]\n",
    "    print(i, max_key, round(sim_performance_new[max_key][0],4), round(sim_performance_new[max_key][1],4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
