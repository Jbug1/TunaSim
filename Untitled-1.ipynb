{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input = pd.read_pickle('/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist23_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('/Users/jonahpoczobutt/projects/TunaRes/network_results', exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "yoop = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/raw/query/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.DataFrame([[1,2],[3,4]], columns =['a','b'])\n",
    "\n",
    "a[['a',]].to_numpy().astype(tuple)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tuna_1_post_downsample.pkl')['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tuna_1_post_downsample.pkl')['queryID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tuna_0_post_downsample.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppm(base, ppm):\n",
    "    \"\"\"\n",
    "    convert ppm threshold to dalton based on precursor exact mass (base)\n",
    "    \"\"\"\n",
    "\n",
    "    return base * (ppm / 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1]\n",
    "    else:\n",
    "        return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [True]\n",
    "\n",
    "not a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/performance/tuna_agg_performances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/pickled_objects/tuna_0.pkl', 'rb') as handle:\n",
    "    yoop = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_vals = {\n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'add_norm_a' : 0.001,\n",
    "    'add_norm_b' : 1,\n",
    "    'target_intensity_a': 0.1,\n",
    "    'query_intensity_a': 0.1,\n",
    "    'target_intensity_b': 0.1,\n",
    "    'query_intensity_b': 0.1,\n",
    "    }\n",
    "\n",
    "for i in init_vals:\n",
    "\n",
    "    print(i, getattr(yoop, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/performance/tuna_agg_performances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.5, 1]\n",
    "max_leaf_nodes = [31, 40, 80]\n",
    "max_iter = [200, 400]\n",
    "l2_regs = [10, 20, 40, 80]\n",
    "i=1\n",
    "\n",
    "nones = 0\n",
    "ths = 0\n",
    "fs = 0\n",
    "eights = 0\n",
    "\n",
    "for rate in learning_rates:\n",
    "    for leaf in max_leaf_nodes:\n",
    "     for iter in max_iter:\n",
    "          for reg in l2_regs:\n",
    "\n",
    "               print(rate, leaf, iter, reg, round(performance.iloc[i]['train'],3), round(performance.iloc[i]['val'],3))\n",
    "               i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/matched/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('/Users/jonahpoczobutt/projects/raw_data/db_csvs/gnps_highres.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queryID</th>\n",
       "      <th>inchi_base</th>\n",
       "      <th>preds</th>\n",
       "      <th>score</th>\n",
       "      <th>top_hit_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.609713</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>WYVSACLCCJHHGJ</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.876582</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28</td>\n",
       "      <td>WYVSACLCCJHHGJ</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.894143</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816762</th>\n",
       "      <td>1820922</td>\n",
       "      <td>WLSOGIGMSWCVID</td>\n",
       "      <td>0.048545</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816761</th>\n",
       "      <td>1820922</td>\n",
       "      <td>MLOMRDQPPYHSAX</td>\n",
       "      <td>0.029819</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816759</th>\n",
       "      <td>1820922</td>\n",
       "      <td>HOEVRHHMDJKUMZ</td>\n",
       "      <td>0.028737</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816763</th>\n",
       "      <td>1820922</td>\n",
       "      <td>ZLLQQKITWRWKTD</td>\n",
       "      <td>0.021522</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816760</th>\n",
       "      <td>1820922</td>\n",
       "      <td>LREZRXWUEZCZRU</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755168 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        queryID      inchi_base     preds  score  top_hit_correct\n",
       "9            27  ZWIHLCKHOMJFNY  0.609713   True            False\n",
       "8            27  WYVSACLCCJHHGJ  0.003769  False            False\n",
       "11           28  ZWIHLCKHOMJFNY  0.876582   True            False\n",
       "10           28  WYVSACLCCJHHGJ  0.003048  False            False\n",
       "13           30  ZWIHLCKHOMJFNY  0.894143   True            False\n",
       "...         ...             ...       ...    ...              ...\n",
       "816762  1820922  WLSOGIGMSWCVID  0.048545  False            False\n",
       "816761  1820922  MLOMRDQPPYHSAX  0.029819  False            False\n",
       "816759  1820922  HOEVRHHMDJKUMZ  0.028737  False            False\n",
       "816763  1820922  ZLLQQKITWRWKTD  0.021522  False            False\n",
       "816760  1820922  LREZRXWUEZCZRU  0.000743  False            False\n",
       "\n",
       "[755168 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelLayer import queryAdjustmentLayer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m model = queryAdjustmentLayer(gbc())\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/TunaSim/modelLayer.py:156\u001b[39m, in \u001b[36mqueryAdjustmentLayer.select_model\u001b[39m\u001b[34m(self, train, val)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mselect_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, train, val):\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     train, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_input_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     val, _ = \u001b[38;5;28mself\u001b[39m.process_input_data(val)\n\u001b[32m    159\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_layer.select_model(train, val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/TunaSim/modelLayer.py:107\u001b[39m, in \u001b[36mqueryAdjustmentLayer.process_input_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_input_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[32m    103\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" \u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    Only want to take in instances where there is more than 1 hit\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     start = \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m()\n\u001b[32m    108\u001b[39m     grouped = data.groupby(\u001b[38;5;28mself\u001b[39m.groupby_column).size()\n\u001b[32m    110\u001b[39m     multi_hit_ids = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'builtin_function_or_method' object has no attribute 'time'"
     ]
    }
   ],
   "source": [
    "model = queryAdjustmentLayer(gbc())\n",
    "\n",
    "model.select_model(new_inputs, new_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/pickled_objects/network.pkl', 'rb') as handle:\n",
    "\n",
    "    network = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "top_tunas = pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tunasims_top_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(top_tunas['queryID'])) / len(top_tunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TunaSims import scoreByQuery2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "derp = [i for i in range(len(input_data))]\n",
    "input_data.insert(0, 'derp', derp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queryID</th>\n",
       "      <th>inchi_base</th>\n",
       "      <th>tuna_0</th>\n",
       "      <th>tuna_1</th>\n",
       "      <th>tuna_2</th>\n",
       "      <th>tuna_3</th>\n",
       "      <th>tuna_4</th>\n",
       "      <th>tuna_5</th>\n",
       "      <th>tuna_6</th>\n",
       "      <th>tuna_7</th>\n",
       "      <th>tuna_8</th>\n",
       "      <th>tuna_9</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.965620</td>\n",
       "      <td>0.853035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.984180</td>\n",
       "      <td>0.818285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.991853</td>\n",
       "      <td>0.775993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.883486</td>\n",
       "      <td>0.628148</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.999845</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.759604</td>\n",
       "      <td>0.579820</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999110</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816763</th>\n",
       "      <td>1820922</td>\n",
       "      <td>ZLLQQKITWRWKTD</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>0.809742</td>\n",
       "      <td>0.023770</td>\n",
       "      <td>0.204931</td>\n",
       "      <td>0.988353</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816764</th>\n",
       "      <td>1820922</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.384420</td>\n",
       "      <td>0.797928</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996485</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816765</th>\n",
       "      <td>1820925</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.899068</td>\n",
       "      <td>0.717106</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816766</th>\n",
       "      <td>1820927</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.998012</td>\n",
       "      <td>0.650041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816767</th>\n",
       "      <td>1820929</td>\n",
       "      <td>ZWIHLCKHOMJFNY</td>\n",
       "      <td>0.754885</td>\n",
       "      <td>0.794811</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816768 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        queryID      inchi_base    tuna_0    tuna_1    tuna_2    tuna_3  \\\n",
       "0             0  ZWIHLCKHOMJFNY  0.965620  0.853035  1.000000  1.000000   \n",
       "1             4  ZWIHLCKHOMJFNY  0.984180  0.818285  1.000000  1.000000   \n",
       "2             5  ZWIHLCKHOMJFNY  0.991853  0.775993  1.000000  1.000000   \n",
       "3            12  ZWIHLCKHOMJFNY  0.883486  0.628148  0.999926  0.999845   \n",
       "4            13  ZWIHLCKHOMJFNY  0.759604  0.579820  0.999699  0.999781   \n",
       "...         ...             ...       ...       ...       ...       ...   \n",
       "816763  1820922  ZLLQQKITWRWKTD  0.011621  0.809742  0.023770  0.204931   \n",
       "816764  1820922  ZWIHLCKHOMJFNY  0.384420  0.797928  0.999999  1.000000   \n",
       "816765  1820925  ZWIHLCKHOMJFNY  0.899068  0.717106  0.999984  0.999988   \n",
       "816766  1820927  ZWIHLCKHOMJFNY  0.998012  0.650041  1.000000  1.000000   \n",
       "816767  1820929  ZWIHLCKHOMJFNY  0.754885  0.794811  1.000000  1.000000   \n",
       "\n",
       "          tuna_4    tuna_5    tuna_6    tuna_7  tuna_8  tuna_9  score  \n",
       "0       0.855878  1.000000  0.999897  1.000000     1.0     1.0   True  \n",
       "1       0.982090  1.000000  0.999822  1.000000     1.0     1.0   True  \n",
       "2       0.991651  1.000000  0.999324  1.000000     1.0     1.0   True  \n",
       "3       0.999770  0.999993  0.999984  0.999999     1.0     1.0   True  \n",
       "4       0.999110  0.999996  0.999687  1.000000     1.0     1.0   True  \n",
       "...          ...       ...       ...       ...     ...     ...    ...  \n",
       "816763  0.988353  0.000009  0.999975  1.000000     1.0     1.0  False  \n",
       "816764  0.996485  0.999962  0.999937  1.000000     1.0     1.0   True  \n",
       "816765  0.999978  1.000000  1.000000  1.000000     1.0     1.0   True  \n",
       "816766  0.998817  1.000000  0.999630  1.000000     1.0     1.0   True  \n",
       "816767  0.949362  1.000000  0.999760  1.000000     1.0     1.0   True  \n",
       "\n",
       "[816768 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start\n",
      "yoop\n",
      "start\n",
      "yoop\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'HistGradientBoostingClassifier' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     13\u001b[39m new_inputs = pd.DataFrame({\u001b[33m'\u001b[39m\u001b[33mqueryID\u001b[39m\u001b[33m'\u001b[39m: input_data[\u001b[33m'\u001b[39m\u001b[33mqueryID\u001b[39m\u001b[33m'\u001b[39m].to_numpy(),\n\u001b[32m     14\u001b[39m               \u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m: input_data[\u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m].to_numpy(),\n\u001b[32m     15\u001b[39m               \u001b[33m'\u001b[39m\u001b[33mpreds\u001b[39m\u001b[33m'\u001b[39m: init_model.predict_proba(input_data.iloc[:, \u001b[32m2\u001b[39m:-\u001b[32m1\u001b[39m])[:,\u001b[32m1\u001b[39m]})\n\u001b[32m     17\u001b[39m new_inputs.sort_values(by = [\u001b[33m'\u001b[39m\u001b[33mqueryID\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mpreds\u001b[39m\u001b[33m'\u001b[39m], ascending = \u001b[38;5;28;01mFalse\u001b[39;00m, inplace = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/TunaSim/modelLayer.py:184\u001b[39m, in \u001b[36mqueryAdjustmentLayer.select_model\u001b[39m\u001b[34m(self, train, val)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28mself\u001b[39m.train, \u001b[38;5;28mself\u001b[39m.yoop = \u001b[38;5;28mself\u001b[39m.process_input_data(train)\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.val, _ = \u001b[38;5;28mself\u001b[39m.process_input_data(val)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/TunaSim/modelLayer.py:37\u001b[39m, in \u001b[36mmodelLayer.select_model\u001b[39m\u001b[34m(self, train, val)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mself\u001b[39m.val_performance = \u001b[38;5;28mlist\u001b[39m()\n\u001b[32m     36\u001b[39m counter = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#exclude groupby and label from inputs\u001b[39;49;00m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#generate validation preds\u001b[39;49;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'HistGradientBoostingClassifier' object is not iterable"
     ]
    }
   ],
   "source": [
    "from modelLayer import queryAdjustmentLayer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as gbc\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "trainer = queryAdjustmentLayer(gbc(),\n",
    "                               jobs = 1)\n",
    "init_model = gbc()\n",
    "input_data = pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tunasims_top_train.csv')\n",
    "\n",
    "init_model.fit(input_data.iloc[:,2:-1], input_data.iloc[:,-1])\n",
    "\n",
    "new_inputs = pd.DataFrame({'queryID': input_data['queryID'].to_numpy(),\n",
    "              'score': input_data['score'].to_numpy(),\n",
    "              'preds': init_model.predict_proba(input_data.iloc[:, 2:-1])[:,1]})\n",
    "\n",
    "new_inputs.sort_values(by = ['queryID','preds'], ascending = False, inplace = True)\n",
    "\n",
    "trainer.select_model(new_inputs, new_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195173"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yoop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "yoop = trainer.data.groupby(['queryID'])['preds']\n",
    "\n",
    "ind = 0\n",
    "for i in yoop:\n",
    "\n",
    "    if len(i[1])\n",
    "    \n",
    "    ind +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, np.int64(1))\n",
      "(1, np.int64(2))\n",
      "(2, np.int64(3))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in enumerate(np.array([1,2,3])):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.single_hit_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = gbc()\n",
    "mod.fit(input_data.iloc[:,2:-1], input_data.iloc[:,-1])\n",
    "outputs = mod.predict_proba(input_data.iloc[:,2:-1])[:,1]\n",
    "\n",
    "new_inputs = pd.DataFrame({'queryID': input_data['queryID'],\n",
    "                           'score': input_data['score']})\n",
    "\n",
    "\n",
    "labels = new_inputs.groupby('queryID').first()['score']\n",
    "sizes = new_inputs.groupby('queryID').size()\n",
    "\n",
    "top_hit_correct = [[label for _ in range(size)] for label, size in zip(labels, sizes)]\n",
    "top_hit_correct = [item for sublist in top_hit_correct for item in sublist]    \n",
    "\n",
    "new_inputs['top_hit_correct'] = top_hit_correct\n",
    "new_inputs = new_inputs.sort_values(by=['queryID', 'preds'], ascending=[True, False])\n",
    "\n",
    "grouped = new_inputs.groupby('queryID').size()\n",
    "\n",
    "multi_hit_ids = set()\n",
    "for id, size in zip(grouped.index, grouped):\n",
    "\n",
    "    if size > 1:\n",
    "\n",
    "        multi_hit_ids.add(id)\n",
    "\n",
    "indices_to_retain = list()\n",
    "for i, id in enumerate(new_inputs['queryID']):\n",
    "\n",
    "    if id in multi_hit_ids:\n",
    "\n",
    "        indices_to_retain.append(i)\n",
    "\n",
    "new_inputs = new_inputs.iloc[indices_to_retain]\n",
    "trainer.fit(new_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_scores_a 1.95413268806502\n",
      "raw_scores_b 0.0012781820940014896\n",
      "top_to_next_a 1.9992988478413334\n",
      "top_to_next_b 0.5044625501972753\n",
      "entropy_a -1.4081079586617495\n",
      "entropy_b 0.7373795568945911\n"
     ]
    }
   ],
   "source": [
    "for i in trainer.function.grad_names:\n",
    "\n",
    "    print(i, getattr(trainer.function, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = new_inputs.groupby('queryID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9    0.609713\n",
      "8    0.003769\n",
      "Name: preds, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for group in preds:\n",
    "\n",
    "    print(group[1]['preds'])\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trainer.function.grad_names:\n",
    "\n",
    "    print(i, getattr(trainer.function, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62295649, 0.62295649, 0.62173773, 0.62173773])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "a = np.array([0.8, 0.8,0.1, 0.1])\n",
    "trainer.function.predict(a, scipy.stats.entropy(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.162277660168379"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.1 ** -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oldMetrics import oldMetricEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "val_match = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/matched/val_1.pkl')\n",
    "\n",
    "evaluator = oldMetricEvaluator(val_match,\n",
    "                               ['queryID', 'inchi_base'],\n",
    "                                '/Users/jonahpoczobutt/projects/TunaRes/test',\n",
    "                               '/Users/jonahpoczobutt/projects/TunaRes/test')\n",
    "\n",
    "#evaluator.evaluate_and_write_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Users/jonahpoczobutt/projects/TunaRes/network_results_speed/intermediate_ouputs/pickled_objects/network.pkl','rb') as handle:\n",
    "\n",
    "    network = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.tunaSim_trainers[0].n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = network.tunaSim_trainers[0].function\n",
    "\n",
    "init_vals = {\n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'add_norm_b' : 1,\n",
    "    'target_intensity_a': 0.1,\n",
    "    'query_intensity_a': 0.1,\n",
    "    'target_intensity_b': 0.1,\n",
    "    'query_intensity_b': 0.1,\n",
    "    }\n",
    "\n",
    "for i in init_vals:\n",
    "    print(i, getattr(func,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array([0]) * np.array([np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(top_tunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2,3],[1,2,3]])\n",
    "np.sum(a, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.power(np.array([0]), -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(top_tunas['tuna_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(yoop.drop(['spectrum','mode'], axis = 1).groupby(['queryID','inchi_base']).min().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Users/jonahpoczobutt/projects/TunaRes/network_results/network.pkl', 'rb') as handle:\n",
    "\n",
    "    yoop = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tunasims_top_train.csv')\n",
    "val = pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tunasims_top_val_1.csv')\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as gbc\n",
    "\n",
    "model = gbc()\n",
    "model.fit(train.iloc[:,2:3], train.iloc[:,-1])\n",
    "\n",
    "roc_auc_score(train.iloc[:,-1], model.predict_proba(train.iloc[:,2:3])[:,1])\n",
    "roc_auc_score(val.iloc[:,-1], model.predict_proba(val.iloc[:,2:3])[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difs = list()\n",
    "tops = list()\n",
    "seconds = list()\n",
    "anys = list()\n",
    "\n",
    "for query in set(train['queryID']):\n",
    "\n",
    "    sub = train[train['queryID'] == query]\n",
    "    sub.sort_values(by = 'aggregated_preds', ascending = False, inplace = True)\n",
    "\n",
    "    anys.append(True in sub['score'].tolist())\n",
    "    \n",
    "    if len(sub) > 1:\n",
    "        tops.append(sub['aggregated_preds'].iloc[0])\n",
    "        seconds.append(sub['aggregated_preds'].iloc[1])\n",
    "        difs.append(sub['aggregated_preds'].iloc[0] - sub['aggregated_preds'].iloc[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True in sub['score'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(results.iloc[:,-1], model.predict_proba(results.iloc[:,-6:-1])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier as gbc\n",
    "\n",
    "model = gbc()\n",
    "model.fit(results.iloc[:,-6:-1], results.iloc[:,-1])\n",
    "\n",
    "roc_auc_score(results.iloc[:,-1], model.predict_proba(results.iloc[:,-6:-1])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(results['score'], results['tuna_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#yoop = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/matched/test.pkl')\n",
    "\n",
    "from pickle import load\n",
    "with open('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/pickled_objects/tuna_0.pkl', 'rb') as handle:\n",
    "\n",
    "    sim = load(handle)\n",
    "\n",
    "init_vals = {\n",
    "    \n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'add_norm_b' : 1,\n",
    "    'add_norm_int': 0,\n",
    "    'target_intensity_a': 0.1,\n",
    "    'query_intensity_a': 0.1,\n",
    "    'target_intensity_b': 0.1,\n",
    "    'query_intensity_b': 0.1,\n",
    "    }\n",
    "\n",
    "for i in init_vals:\n",
    "    print(i, getattr(sim,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tuna_0_post_downsample.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 1, use .apply in predict for dataset\n",
    "sim.predict_for_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2 use zipped query and target\n",
    "import numpy as np\n",
    "res = np.zeros(len(dataset))\n",
    "\n",
    "for index, query, target in zip([i for i in range(dataset.shape[0])], dataset['query'], dataset['target']):\n",
    "\n",
    "    res[index] = sim.predict(query, target)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "\n",
    "    res = pool.starmap(sim.predict, zip(dataset['query'].tolist(), dataset['target'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(q, t, tol):\n",
    "\n",
    "    match_inds = np.zeros(max(q.shape[0], t.shape[0]))\n",
    "\n",
    "    target_pointer = 0\n",
    "\n",
    "    for i in range(len(q)):\n",
    "\n",
    "        search_ind = np.searchsorted(t[target_pointer:], q[i], side=\"left\")\n",
    "\n",
    "        close_left =  q[i] - t[search_ind - 1]\n",
    "        close_right = t[search_ind] - q[i]\n",
    "\n",
    "        #first check if the close left value is within range\n",
    "        if close_left < tol:\n",
    "\n",
    "            if close_right < close_left:\n",
    "\n",
    "                #if the right is closer, then we should check the next value over\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match(a,b,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.searchsorted(b, 2, side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(1e6)):\n",
    "\n",
    "    joner(a[0], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(1e6)):\n",
    "\n",
    "    joner_2(a[0], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joner(val, arr):\n",
    "\n",
    "    return np.argmin(np.abs(val - arr))\n",
    "\n",
    "def joner_2(val, arr):\n",
    "\n",
    "    return np.searchsorted(arr, val, side=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1]\n",
    "    else:\n",
    "        return array[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
