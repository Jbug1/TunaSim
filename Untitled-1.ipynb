{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input = pd.read_pickle('/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist23_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('/Users/jonahpoczobutt/projects/TunaRes/network_results', exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "yoop = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/raw/query/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.DataFrame([[1,2],[3,4]], columns =['a','b'])\n",
    "\n",
    "a[['a',]].to_numpy().astype(tuple)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tuna_1_post_downsample.pkl')['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tuna_1_post_downsample.pkl')['queryID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tuna_0_post_downsample.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppm(base, ppm):\n",
    "    \"\"\"\n",
    "    convert ppm threshold to dalton based on precursor exact mass (base)\n",
    "    \"\"\"\n",
    "\n",
    "    return base * (ppm / 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1]\n",
    "    else:\n",
    "        return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [True]\n",
    "\n",
    "not a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/performance/tuna_agg_performances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/pickled_objects/tuna_0.pkl', 'rb') as handle:\n",
    "    yoop = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_vals = {\n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'add_norm_a' : 0.001,\n",
    "    'add_norm_b' : 1,\n",
    "    'target_intensity_a': 0.1,\n",
    "    'query_intensity_a': 0.1,\n",
    "    'target_intensity_b': 0.1,\n",
    "    'query_intensity_b': 0.1,\n",
    "    }\n",
    "\n",
    "for i in init_vals:\n",
    "\n",
    "    print(i, getattr(yoop, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/performance/tuna_agg_performances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.5, 1]\n",
    "max_leaf_nodes = [31, 40, 80]\n",
    "max_iter = [200, 400]\n",
    "l2_regs = [10, 20, 40, 80]\n",
    "i=1\n",
    "\n",
    "nones = 0\n",
    "ths = 0\n",
    "fs = 0\n",
    "eights = 0\n",
    "\n",
    "for rate in learning_rates:\n",
    "    for leaf in max_leaf_nodes:\n",
    "     for iter in max_iter:\n",
    "          for reg in l2_regs:\n",
    "\n",
    "               print(rate, leaf, iter, reg, round(performance.iloc[i]['train'],3), round(performance.iloc[i]['val'],3))\n",
    "               i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array([[1,2,3],[4,5,6]])\n",
    "a * np.array([2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((2,3))\n",
    "\n",
    "def yoop():\n",
    "\n",
    "    return np.array([1,0,0]), np.array([1,0,0])\n",
    "\n",
    "a[0], a[1] = yoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/pickled_objects/network.pkl', 'rb') as handle:\n",
    "\n",
    "    network = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "top_tunas = pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tunasims_top_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(top_tunas['queryID'])) / len(top_tunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TunaSims import scoreByQuery2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "updated value is Nan for (np.str_('dif_from_next_b'), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan]))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     51\u001b[39m newer_inputs = new_inputs.iloc[good_inds]\n\u001b[32m     53\u001b[39m newer_inputs = newer_inputs.sort_values(by=[\u001b[33m'\u001b[39m\u001b[33mqueryID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpreds\u001b[39m\u001b[33m'\u001b[39m], ascending=[\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m])\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewer_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/TunaSim/funcTrainer.py:95\u001b[39m, in \u001b[36mfuncTrainer.fit\u001b[39m\u001b[34m(self, train_data)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.log.info(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcreated inds dict in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m((time.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart)\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[32m60\u001b[39m,\u001b[32m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m minutes\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     94\u001b[39m start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstoch_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m.log.info(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrained function in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m((time.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart)\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[32m60\u001b[39m,\u001b[32m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m minutes\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/TunaSim/funcTrainer.py:218\u001b[39m, in \u001b[36mfuncTrainer.stoch_descent\u001b[39m\u001b[34m(self, train_data)\u001b[39m\n\u001b[32m    215\u001b[39m label, pred_val = \u001b[38;5;28mself\u001b[39m.get_match_grad_components(sub)\n\u001b[32m    217\u001b[39m \u001b[38;5;66;03m#update with the score of choice and funcOb's loss function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_val\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[32m    220\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/TunaSim/funcTrainer.py:267\u001b[39m, in \u001b[36mfuncTrainer.step\u001b[39m\u001b[34m(self, score, pred_val)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.function, key, \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(bounds[\u001b[32m0\u001b[39m], updated), bounds[\u001b[32m1\u001b[39m]))\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.isnan(updated):\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupdated value is Nan for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey,\u001b[38;5;250m \u001b[39mgrad\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: updated value is Nan for (np.str_('dif_from_next_b'), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan]))"
     ]
    }
   ],
   "source": [
    "from funcTrainer import tunaQueryTrainer\n",
    "import numpy as np\n",
    "\n",
    "init_vals = {'raw_scores_a': 1,\n",
    "            'raw_scores_b': 1,\n",
    "            'dif_from_next_a' : 0,\n",
    "            'dif_from_next_b' : 1,\n",
    "            'dif_from_top_a': 0,\n",
    "            'dif_from_top_b': 1}\n",
    "\n",
    "bounds = {'raw_scores_a': (-2,2),\n",
    "          'raw_scores_b': (0,2),\n",
    "          'dif_from_next_a' : (-2,2),\n",
    "          'dif_from_next_b' : (0,2),\n",
    "          'dif_from_top_a': (-2,2),\n",
    "          'dif_from_top_b': (0,2)}\n",
    "\n",
    "trainer = tunaQueryTrainer(name = '1',\n",
    "                              init_vals = init_vals,\n",
    "                              groupby_column = ['queryID'],\n",
    "                              balance_column = None,\n",
    "                              identity_column = 'inchi_base',\n",
    "                              bounds = bounds,\n",
    "                              max_iter = 10000,\n",
    "                              fixed = ['raw_scores_a', 'raw_scores_b', 'dif_from_top_a', 'dif_from_top_b'])\n",
    "\n",
    "import pandas as pd\n",
    "input_data = pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tunasims_top_train.csv')\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as gbc\n",
    "\n",
    "mod = gbc()\n",
    "mod.fit(input_data.iloc[:,2:-1], input_data.iloc[:,-1])\n",
    "outputs = mod.predict_proba(input_data.iloc[:,2:-1])[:,1]\n",
    "\n",
    "new_inputs = pd.DataFrame({'queryID': input_data['queryID'],\n",
    "                           'inchi_base': input_data['inchi_base'],\n",
    "                           'preds': outputs,\n",
    "                           'score': input_data['score']})\n",
    "\n",
    "groupby_match = new_inputs.groupby('queryID').max()\n",
    "truematch_set = set(groupby_match[groupby_match['score'] == True].index)\n",
    "length_set = set(new_inputs.groupby('queryID').size()[new_inputs.groupby('queryID').size() > 1].index)\n",
    "identity_set = truematch_set.intersection(length_set)\n",
    "\n",
    "good_inds = list()\n",
    "for i, identity in zip(list(range(new_inputs.shape[0])), new_inputs['queryID']):\n",
    "\n",
    "    if identity in identity_set:\n",
    "        good_inds.append(i)\n",
    "\n",
    "newer_inputs = new_inputs.iloc[good_inds]\n",
    "\n",
    "newer_inputs = newer_inputs.sort_values(by=['queryID', 'preds'], ascending=[True, False])\n",
    "\n",
    "trainer.fit(newer_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5 ** -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.function.raw_scores_a = 2\n",
    "trainer.function.dif_from_top_a = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.767993  , 0.72429568, 0.55076537])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.function.predict(np.array([0.8, 0.6, 0.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.function.grad_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_scores_a 1.238230753167166\n",
      "raw_scores_b 0.9004655915008282\n",
      "dif_from_next_a 0.18418098034043365\n",
      "dif_from_next_b 0\n",
      "dif_from_top_a 0\n",
      "dif_from_top_b 1\n"
     ]
    }
   ],
   "source": [
    "for i in trainer.function.grad_names:\n",
    "\n",
    "    print(i, getattr(trainer.function, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067811865476"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5 ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Users/jonahpoczobutt/projects/TunaRes/network_results_speed/intermediate_ouputs/pickled_objects/network.pkl','rb') as handle:\n",
    "\n",
    "    network = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.tunaSim_trainers[0].n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = network.tunaSim_trainers[0].function\n",
    "\n",
    "init_vals = {\n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'add_norm_b' : 1,\n",
    "    'target_intensity_a': 0.1,\n",
    "    'query_intensity_a': 0.1,\n",
    "    'target_intensity_b': 0.1,\n",
    "    'query_intensity_b': 0.1,\n",
    "    }\n",
    "\n",
    "for i in init_vals:\n",
    "    print(i, getattr(func,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array([0]) * np.array([np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(top_tunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2,3],[1,2,3]])\n",
    "np.sum(a, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.power(np.array([0]), -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(top_tunas['tuna_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(yoop.drop(['spectrum','mode'], axis = 1).groupby(['queryID','inchi_base']).min().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Users/jonahpoczobutt/projects/TunaRes/network_results/network.pkl', 'rb') as handle:\n",
    "\n",
    "    yoop = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tunasims_top_train.csv')\n",
    "val = pd.read_csv('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tunasims_top_val_1.csv')\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as gbc\n",
    "\n",
    "model = gbc()\n",
    "model.fit(train.iloc[:,2:3], train.iloc[:,-1])\n",
    "\n",
    "roc_auc_score(train.iloc[:,-1], model.predict_proba(train.iloc[:,2:3])[:,1])\n",
    "roc_auc_score(val.iloc[:,-1], model.predict_proba(val.iloc[:,2:3])[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difs = list()\n",
    "tops = list()\n",
    "seconds = list()\n",
    "anys = list()\n",
    "\n",
    "for query in set(train['queryID']):\n",
    "\n",
    "    sub = train[train['queryID'] == query]\n",
    "    sub.sort_values(by = 'aggregated_preds', ascending = False, inplace = True)\n",
    "\n",
    "    anys.append(True in sub['score'].tolist())\n",
    "    \n",
    "    if len(sub) > 1:\n",
    "        tops.append(sub['aggregated_preds'].iloc[0])\n",
    "        seconds.append(sub['aggregated_preds'].iloc[1])\n",
    "        difs.append(sub['aggregated_preds'].iloc[0] - sub['aggregated_preds'].iloc[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True in sub['score'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(results.iloc[:,-1], model.predict_proba(results.iloc[:,-6:-1])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier as gbc\n",
    "\n",
    "model = gbc()\n",
    "model.fit(results.iloc[:,-6:-1], results.iloc[:,-1])\n",
    "\n",
    "roc_auc_score(results.iloc[:,-1], model.predict_proba(results.iloc[:,-6:-1])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(results['score'], results['tuna_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#yoop = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/matched/test.pkl')\n",
    "\n",
    "from pickle import load\n",
    "with open('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/pickled_objects/tuna_0.pkl', 'rb') as handle:\n",
    "\n",
    "    sim = load(handle)\n",
    "\n",
    "init_vals = {\n",
    "    \n",
    "    'mult_a' : 0.001,\n",
    "    'mult_b': 1,\n",
    "    'dif_a': 0.001,\n",
    "    'dif_b':1,\n",
    "    'add_norm_b' : 1,\n",
    "    'add_norm_int': 0,\n",
    "    'target_intensity_a': 0.1,\n",
    "    'query_intensity_a': 0.1,\n",
    "    'target_intensity_b': 0.1,\n",
    "    'query_intensity_b': 0.1,\n",
    "    }\n",
    "\n",
    "for i in init_vals:\n",
    "    print(i, getattr(sim,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('/Users/jonahpoczobutt/projects/TunaRes/network_results/intermediate_ouputs/tuna_0_post_downsample.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 1, use .apply in predict for dataset\n",
    "sim.predict_for_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2 use zipped query and target\n",
    "import numpy as np\n",
    "res = np.zeros(len(dataset))\n",
    "\n",
    "for index, query, target in zip([i for i in range(dataset.shape[0])], dataset['query'], dataset['target']):\n",
    "\n",
    "    res[index] = sim.predict(query, target)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "\n",
    "    res = pool.starmap(sim.predict, zip(dataset['query'].tolist(), dataset['target'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(q, t, tol):\n",
    "\n",
    "    match_inds = np.zeros(max(q.shape[0], t.shape[0]))\n",
    "\n",
    "    target_pointer = 0\n",
    "\n",
    "    for i in range(len(q)):\n",
    "\n",
    "        search_ind = np.searchsorted(t[target_pointer:], q[i], side=\"left\")\n",
    "\n",
    "        close_left =  q[i] - t[search_ind - 1]\n",
    "        close_right = t[search_ind] - q[i]\n",
    "\n",
    "        #first check if the close left value is within range\n",
    "        if close_left < tol:\n",
    "\n",
    "            if close_right < close_left:\n",
    "\n",
    "                #if the right is closer, then we should check the next value over\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match(a,b,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.searchsorted(b, 2, side = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(1e6)):\n",
    "\n",
    "    joner(a[0], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(1e6)):\n",
    "\n",
    "    joner_2(a[0], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joner(val, arr):\n",
    "\n",
    "    return np.argmin(np.abs(val - arr))\n",
    "\n",
    "def joner_2(val, arr):\n",
    "\n",
    "    return np.searchsorted(arr, val, side=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1]\n",
    "    else:\n",
    "        return array[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
